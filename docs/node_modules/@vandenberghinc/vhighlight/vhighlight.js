/*
 * Author: Daan van den Bergh
 * Copyright: Â© 2023 Daan van den Bergh.
 */
// ---------------------------------------------------------
// Module vhighlight.

const vhighlight = {};

// All languages.
vhighlight.languages = function() {
	if (this._languages === undefined) {
		this._languages = [
			vhighlight.cpp.language,
			vhighlight.md.language,
			vhighlight.js.language,
			vhighlight.json.language,
			vhighlight.python.language,
			vhighlight.css.language,
			vhighlight.html.language,
			vhighlight.bash.language,
		]
	}
	return this._languages;
};

// Get the global tokenizer class or initialize a new class based on a language name.
// - Returns `null` when the language is not supported.
vhighlight.get_tokenizer = function(language) {
	switch (language.toLowerCase()) {
		
		// C.
		case "cpp":
		case "c++":
		case "c":
			return vhighlight.cpp;
		
		// Markdown.
		case "markdown":
		case "md":
			return vhighlight.md;
		
		// JS.
		case "js":
		case "javascript":
		case "nodejs":
			return vhighlight.js;
		
		// JSON.
		case "json":
			return vhighlight.json;
		
		// Python.
		case "python":
		case "py":
			return vhighlight.python;
		
		// CSS.
		case "css":
			return vhighlight.css;
		
		// HTML.
		case "html":
			return vhighlight.html;
		
		// Bash.
		case "bash":
		case "sh":
		case "zsh":
		case "shell":
		case "curl":
		case "cli":
			return vhighlight.bash;

		// Unsupported.
		default:
			return null;
	}
}
vhighlight.init_tokenizer = function(language, args = {}) {
	switch (language.toLowerCase()) {
		
		// C.
		case "cpp":
		case "c++":
		case "c":
			return new vhighlight.CPP(args);
		
		// Markdown.
		case "markdown":
		case "md":
			return new vhighlight.Markdown(args);
		
		// JS.
		case "js":
		case "javascript":
		case "nodejs":
			return new vhighlight.JS(args);
		
		// JSON.
		case "json":
			return new vhighlight.JSON(args);
		
		// Python.
		case "python":
		case "py":
			return new vhighlight.Python(args);
		
		// CSS.
		case "css":
			return new vhighlight.CSS(args);
		
		// HTML.
		case "html":
			return new vhighlight.HTML(args);
		
		// Bash.
		case "bash":
		case "sh":
		case "zsh":
		case "shell":
		case "curl":
		case "cli":
			return new vhighlight.Bash(args);

		// Unsupported.
		default:
			return null;
	}
}

// Get the supported language from a path extension.
vhighlight.language_extensions = {
	"cpp": [".c", ".cp", ".cpp", ".h", ".hp", ".hpp"],
    "js": [".js"], 
    "md": [".md"],
    "python": [".py"],
    "css": [".css"],
    "json": [".json", ".vide", ".vpackage", ".vweb"],
    "shell": [".sh", ".zsh"],
    "html": [".html"],
};
vhighlight.get_tokenizer_by_extension = function(extension) {
	if (extension == null || extension.length === 0) { return null; }
	if (extension.charAt(0) != ".") {
		extension = `.${extension}`;
	}
	return Object.keys(vhighlight.language_extensions).iterate((lang) => {
        if (vhighlight.language_extensions[lang].includes(extension)) {
            return vhighlight.get_tokenizer(lang);
        }
    })
}
vhighlight.init_tokenizer_by_extension = function(extension, args = {}) {
	if (extension == null || extension.length === 0) { return null; }
	if (extension.charAt(0) != ".") {
		extension = `.${extension}`;
	}
	return Object.keys(vhighlight.language_extensions).iterate((lang) => {
        if (vhighlight.language_extensions[lang].includes(extension)) {
            return vhighlight.init_tokenizer(lang, args);
        }
    })
}

// Tokenize code.
// - Returns "null" when the language is not supported.
// - Make sure to replace < with &lt; and > with &gt; before assigning the code to the <code> element.
/*
vhighlight.tokenize = function({
	element = null,			// the html code element.
	code = null,			// when the code is assigned the highlighted code will be returned.
	language = null,		// code language, precedes element attribute "language".
	line_numbers = null,	// show line numbers, precedes element attribute "line_numbers".
	animate = false,		// animate code writing.
	delay = 25,				// animation delay in milliseconds, only used when providing parameter "element".
	// is_func = false,	 	// enable when cpp code is inside a function.
	build_html = false,		// with build_html as `true` this function will build the html and return the html code when parameter `code` is defined, with build_html as `false` it will return the array of tokens.
	tokenizer_args = {},	// special args of the language's tokenizer constructor.
}) {

	// Get language.
	if (language == null && element != null) {
		language = element.getAttribute("language");
	}
	
	// Line numbers.
	if (line_numbers == null && element != null) {
		line_numbers = element.getAttribute('line_numbers') == "true";
	}
	
	// Delay.
	if (delay == null) {
		delay = 25;
	}

	// Get tokenizer.
	const tokenizer = vhighlight.init_tokenizer(language, tokenizer_args);
	if (tokenizer == null) {
		return null;
	}
	
	// When the code is assigned just highlight the code and return the highlighted code/
	if (code != null) {
		return tokenizer.tokenize({code: code, build_html: build_html});
	}

	// When the element is a <pre> just highlight it.
	else if (element.tagName == "PRE") {
		code = element.innerText.replaceAll(">", "&gt;").replaceAll("<", "&lt;");
		element.innerHTML = tokenizer.tokenize({code: code, build_html: true});
		return ;
	}

	// When the element is a <code> more options become available.

	// Stop when no language is defined.
	if (language == "" || language == null) {
		return ;
	}

	// Get the tokens.
	if (element.children.length <= 1) {
		code = element.textContent;
	} else {
		code = element.children[2].textContent;
	}
	const tokens = tokenizer.tokenize({code: code});

	// Build the html.
	const highlighted_code = tokenizer.build_html(tokens);
	
	// Create children.
	// let loader;
	let line_numbers_div;
	let line_numbers_divider;
	let code_pre;
	if (element.children.length <= 1) {
		
		// Set style.
		element.style.display = 'flex';
		element.style.height = "auto";
		if (element.style.fontFamily == "") {
			element.style.fontFamily = "'Menlo', 'Consolas', monospace";
		}
		
		// Reset html.
		element.innerHTML = "";
		
		// Loader.
		// loader = document.createElement("div");
		// loader.style.display = "flex";
		// loader.className = "vhighlight_loader";
		// for (let i = 0; i < 4; i++) {
		// 	let child = document.createElement("div");
		// 	child.style.border = "4px solid " + element.style.color;
		// 	child.style.borderColor = element.style.color + " transparent transparent transparent";
		// 	loader.appendChild(child);
		// }
		// element.appendChild(loader);
		
		// Line numbers.
		line_numbers_div = document.createElement("pre");
		line_numbers_div.style.padding = '0px';
		line_numbers_div.style.margin = '0px';
		if (line_numbers === false) {
			line_numbers_div.style.display = "none";
		}
		element.appendChild(line_numbers_div);
		
		// Line numbers divider.
		line_numbers_divider = document.createElement("div");
		line_numbers_divider.className = "token_line_number_divider";
		line_numbers_divider.style.minWidth = "0.5px";
		line_numbers_divider.style.width = "0.5px";
		line_numbers_divider.style.padding = '0px';
		line_numbers_divider.style.margin = "0px 10px 0px 10px";
		if (line_numbers === false) {
			line_numbers_divider.style.display = "none";
		}
		element.appendChild(line_numbers_divider);
		
		// Code.
		code_pre = document.createElement("pre");
		code_pre.style.padding = "0px";
		code_pre.style.margin = "0px";
		code_pre.style.whiteSpace = "pre";
		code_pre.style.overflowX = "auto";
		code_pre.style.flex = "1 1 0";
		element.appendChild(code_pre);
	}
	
	// Get elements.
	else {
		// loader = element.children[0];
		line_numbers_div = element.children[0];
		line_numbers_divider = element.children[1];
		code_pre = element.children[2];
	}

	// Functions.
	// const old_width = element.style.width;
	// const old_height = element.style.width;
	// function show_loader() {

	// 	// Keep same frame as before.
	// 	// Otherwise the frame might shrink when only the loader is shown.
	// 	const rect = element.getBoundingClientRect();
	// 	element.style.width = rect.width;
	// 	element.style.height = rect.height;

	// 	// Center element.
	// 	element.style.justifyContent = "center";
	// 	element.style.alignItems = "center";

	// 	// Show loader.
	// 	loader.style.display = "flex";

	// 	// Hide content.
	// 	line_numbers_div.style.display = "none";
	// 	line_numbers_divider.style.display = "none";
	// 	code_pre.style.display = "none";
	// }
	// function hide_loader() {

	// 	// Restore old frame.
	// 	element.style.width = old_width;
	// 	element.style.height = old_height;

	// 	// Hide loader.
	// 	loader.style.display = "none";

	// 	// Leading alignment.
	// 	element.style.justifyContent = "start";
	// 	element.style.alignItems = "stretch";

	// 	// Show content.
	// 	// if (line_numbers) {
	// 	// 	line_numbers_div.style.display = "block";
	// 	// 	line_numbers_divider.style.display = "block";
	// 	// }
	// 	code_pre.style.display = "block";
	// }
	function animate_writing(highlighted_code) {
		
		// Reset content.
		code_pre.innerHTML = "";

		// Add char.
		function add_char(index) {
			if (index < highlighted_code.length) {
				
				// Span opening.
				if (highlighted_code[index] == '<') {
					
					// Fins span open, close and code.
					let span_index;
					let span_open = "";
					let span_close = "";
					let span_code = "";
					let open = true;
					let first = true;
					for (span_index = index; span_index < highlighted_code.length; span_index++) {
						const char = highlighted_code[span_index];
						if (char == '<' || open) {
							open = true;
							if (first) {
								span_open += char;
							} else {
								span_close += char;
							}
							if (char == '>') {
								open = false;
								if (first) {
									first = false;
									continue;
								}
									
								// Animate span code writing.
								let before = code_pre.innerHTML;
								let added_span_code = "";
								function add_span_code(index) {
									if (index < span_code.length) {
										added_span_code += span_code[index]
										let add = before;
										add += span_open;
										add += added_span_code;
										add += span_close;
										code_pre.innerHTML = add;
										setTimeout(() => add_span_code(index + 1), delay);
									} else {
										setTimeout(() => add_char(span_index + 1), delay);
									}
								}
								add_span_code(0)
								
								// Stop.
								break;
							}
						}
						
						// Add non span code.
						else {
							span_code += char;
						}
						
					}
				}
				
				// Non span code.
				else {
					code_pre.innerHTML += highlighted_code.charAt(index);
					setTimeout(() => add_char(index + 1), delay);
				}
			}
			
			// Non span code.
			else {
				code_pre.innerHTML = highlighted_code;
			}
			
		}
		
		// Start animation.
		add_char(0);
	}

	// Set the min height otherwise the height expands while scrolling while the writing is animated then this can created unwanted behviour when scrolling up.
	const computed = window.getComputedStyle(element);
	element.style.minHeight = `${parseFloat(computed.paddingTop) + parseFloat(computed.paddingBottom) + parseFloat(computed.lineHeight) * tokens.length}px`;
	
	// Show loader.
	// show_loader();

	// Delay the syntax highlighting process.
	// Otherwise the loader does not show and the unhighlted code is shown instead.
	// setTimeout(() => {

	// Create the animate writing function on the element.
	element.animate_writing = () => {
		code_pre.innerHTML = "";
		animate_writing(highlighted_code)
	};

	// No line numbers.
	// So add code directly.
	if (line_numbers == false) {
		// hide_loader();
		if (animate == true) {
			animate_writing(highlighted_code);
		} else {
			code_pre.innerHTML = highlighted_code;
		}
		return ;
	}
	
	// Set style for line numbers.
	element.style.justifyContent = "start";
	element.style.alignItems = 'stretch';
	if (element.style.height === 'undefined' || element.style.height == "100%") {
		element.style.height = 'auto';
	}
	if (element.style.tabSize === 'undefined') {
		element.style.tabSize = '4';
	}
	if (element.style.lineHeight == "") {
		element.style.lineHeight = '16px'; // must be assigned for the show codelines optoin.
	}

	// Get linecount.
	// Cant be done with split() since that also counts the wrapped lined.
    const pre = document.createElement('pre');
    pre.textContent = code;
    pre.style.whiteSpace = 'pre';
    pre.style.overflow = 'visible';
    pre.style.lineHeight = element.style.lineHeight;

	// Set line numbers.
    line_numbers_div.innerHTML = "";
	for (var i = 0; i < tokens.length; i++) {
		let span = document.createElement("span");
		span.className = "token_line_number";
		span.textContent = (i + 1) + "\n";
		line_numbers_div.appendChild(span);
	}

	// Set code.
	// hide_loader();
	if (animate == true) {
		animate_writing(highlighted_code);
	} else {
		code_pre.innerHTML = highlighted_code;
	}
		
		
	// }, 50);
}
*/// Iterate.
if (Array.prototype.iterate === undefined) {
	Array.prototype.iterate = function(start, end, handler) {
	    if (typeof start === "function") {
	        handler = start;
	        start = null;
	    }
	    if (start == null) {
	        start = 0;
	    }
	    if (end == null) {
	        end = this.length;
	    }
	    for (let i = start; i < end; i++) {    
	        const res = handler(this[i]);
	        if (res != null) {
	            return res;
	        }
	    }
	    return null;
	};
}

// Iterate reversed.
if (Array.prototype.iterate_reversed === undefined) {
	Array.prototype.iterate_reversed = function(start, end, handler) {
	    if (handler == null && start != null) {
	        handler = start;
	        start = null;
	    }
	    if (start == null) {
	        start = 0;
	    }
	    if (end == null) {
	        end = this.length;
	    }
	    for (let i = end - 1; i >= start; i--) {    
	        const res = handler(this[i]);
	        if (res != null) {
	            return res;
	        }
	    }
	    return null;
	};
}

// The tokens class.
vhighlight.Tokens = class Tokens extends Array {

	// Constructor.
	constructor() {
		super();
	}

	// Iterate tokens, the start and the end params are in lines.
	iterate_tokens(start, end, handler) {
	    if (typeof start === "function") {
	        handler = start;
	        start = null;
	    }
	    if (start == null) {
	        start = 0;
	    }
	    if (end == null) {
	        end = this.length;
	    }
	    for (let i = start; i < end; i++) {    
	    	const tokens = this[i];
	    	if (tokens === undefined) { return null; }
	    	for (let i = 0; i < tokens.length; i++) {
	    		const res = handler(tokens[i]);
		        if (res != null) {
		            return res;
		        }
	    	}
	    }
	    return null;
	};

	// Iterate tokens reversed, the start and the end params are in lines
	iterate_tokens_reversed(start, end, handler) {
	    if (handler == null && start != null) {
	        handler = start;
	        start = null;
	    }
	    if (start == null) {
	        start = 0;
	    }
	    if (end == null) {
	        end = this.length;
	    }
	    for (let i = end - 1; i >= start; i--) {    
	    	const tokens = this[i];
	    	for (let i = tokens.length - 1; i >= 0; i--) {
	    		const res = handler(tokens[i]);
		        if (res != null) {
		            return res;
		        }
	    	}
	    }
	    return null;
	};

}

// The tokenizer class.
// - @warning: the `parents`, `pre_modifiers`, `post_modifiers`, `templates` and `requires` attributes on the type def tokens will not be correct when using `partial_tokenize()`.
// - Do not forget to assign attribute "code" after initializing the Tokenizer, used to avoid double copy of the code string.
// - Parsing behaviour depends on that every word is seperated as a token, so each word boundary is a seperate token.
// @todo highlight "@\\s+" patterns outside comments as type.
// @todo add support for each language to get parameters, so that vdocs can use this.
vhighlight.Tokenizer = class Tokenizer {

	// Static variables.
	static alphabet = "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ";
	static uppercase_alphabet = "ABCDEFGHIJKLMNOPQRSTUVWXYZ";
	static numerics = "0123456789";

	// Constructor.
	constructor({
		
		// Attributes for tokenizing.
		keywords = [], 
		type_keywords = [],
		type_def_keywords = [], 
		exclude_type_def_keywords_on_prev = [],
		operators = [],
		special_string_prefixes = [],
		single_line_comment_start = false,
		multi_line_comment_start = false,
		multi_line_comment_end = false,
		allow_strings = true,
		allow_numerics = true,
		allow_preprocessors = false,
		allow_slash_regexes = false,
		allow_comment_keyword = true,
		allow_comment_codeblock = true,
		allow_parameters = true,
		allow_decorators = false,
		allowed_keywords_before_type_defs = [],
		excluded_word_boundary_joinings = [],
		is_indent_language = false,
		is_type_language = false,
		
		// Attributes for partial tokenizing.
		scope_separators = [
			"{", 
			"}", 
			// do not use ; and : etc since they can be used inside a {} scope for cpp, js etc.
		],
		seperate_scope_by_type_def = false,

		// Language.
		language = null,
	}) {

		// Parameter attributes.
		this.code = null;																// the code to tokenize.
		this.keywords = keywords;														// the languages default keywords.
		this.type_keywords = type_keywords;												// the keywords on wich the next token will always be a type.
		this.type_def_keywords = type_def_keywords;										// the keywords on wich the next token will always be a type def.
		this.exclude_type_def_keywords_on_prev = exclude_type_def_keywords_on_prev;		// exclude the type def keywords match when the previous non whitespace was one of these words.
		this.operators = operators;														// language operators.
		this.special_string_prefixes = special_string_prefixes;							// special characters preceding a string to indicate a special string, such as the "f" in python for "f'{}'".
		this.single_line_comment_start = single_line_comment_start;						// the language's single line comment start characters, use "false" when the language does not support this.
		this.multi_line_comment_start = multi_line_comment_start;						// the language's multi line comment start characters, use "false" when the language does not support this.
		this.multi_line_comment_end = multi_line_comment_end;							// the language's multi line comment end characters, use "false" when the language does not support this.
		this.allow_strings = allow_strings;												// if the language supports strings.
		this.allow_numerics = allow_numerics;											// if the language supports numerics.
		this.allow_preprocessors = allow_preprocessors;									// if the language has "#..." based preprocessor statements.
		this.allow_slash_regexes = allow_slash_regexes;									// if the language has "/.../" based regex statements.
		this.allow_comment_keyword = allow_comment_keyword;								// allow comment keywords.
		this.allow_comment_codeblock = allow_comment_codeblock;							// allow comment codeblocks.
		this.allow_parameters = allow_parameters;										// allow parameters.
		this.allow_decorators = allow_decorators;										// allow decorators.
		this.allowed_keywords_before_type_defs = allowed_keywords_before_type_defs; 	// the allowed keywords before the name of a type definition, such as "async" and "static" for js, but they need to be directly before the type def token, so no types in between in for example c++.
		this.is_indent_language = is_indent_language;									// whether the language specifies scope's with indent, such as python.
		this.is_type_language = is_type_language;										// is a type language for instance true for cpp and false for js.
		this.scope_separators = scope_separators;										// scope separators for partial tokenize.
		this.seperate_scope_by_type_def = seperate_scope_by_type_def;					// only seperate a scope by token type def's for example required in cpp.
		this.language = language;

		// Word boundaries.
		this.word_boundaries = [
			' ',
		    '\t',
		    '\n',
		    '\r',
		    '.',
		    ',',
		    '!',
		    '?',
		    ';',
		    ':',
		    '-',
		    // '_', // do NOT add as word boundary since that will break a lot by "this.str_includes_word_boundary()" since it used to check if a word is a word, and a "_" is allowed in a variable name.
		    '/',
		    '\\',
		    '|',
		    '(',
		    ')',
		    '[',
		    ']',
		    '{',
		    '}',
		    '<',
		    '>',
		    '=',
		    '+',
		    '*',
		    '&',
		    '%',
		    '$',
		    '#',
		    '@',
		    '`',
		    '~',
		    '"',
		    "'",
		    '\u2019', // Right single quotation mark
		    '\u2018', // Left single quotation mark
		    '\u201d', // Right double quotation mark
		    '\u201c', // Left double quotation mark
		];

		// Word boundaries that will not be joined to the previous word boundary token.
		this.excluded_word_boundary_joinings = [
			"{", "}", "[", "]", "(", ")", "<", ">", // default scopes, never remove any items from this since a lot of other files / libs depend on this.
			",", "=", // required for parsing parameters.
		]
		.concat(this.scope_separators) // always exclude default {}[]() for vide.
		.concat(excluded_word_boundary_joinings)
		this.excluded_word_boundary_joinings = this.excluded_word_boundary_joinings.reduce((accumulator, val) => { // drop duplicates.
			if (!accumulator.includes(val)) {
				accumulator.push(val);
			}
			return accumulator;
		}, []);

		// The default callback.
		// this.callback = function(char, is_escaped, is_preprocessor) { return false; }

		// The on parenth callback.
		// This callback is called when a parentheses closes and the token before the opening parenth is not a keyword unless it is a keyword that is allowed by the `allowed_keywords_before_type_defs` array.
		// - The on parenth close will not be called when the token before the parenth opening is a keyword.
		// - The on parenth close callback should return the type or type def token when it has assigned one, so the parsed parameters can be assigned to that token.
		// this.on_parenth_close = function({token_before_opening_parenth: token_before_opening_parenth, after_parenth_index: after_parenth_index}) {return token};

		// The on type def keyword callback.
		// This callback is called when a type def token is detected by the "type_def_keywords" array.
		// - @warning When this callback is defined the tokenizer will not add the type def tokens parents to the tokenizer when the event is fired, so the event needs to take care of this.
		// - Will be called if one of the type def keywords is matched.
		// - When on_parenth_close is defined and has not yet called `assigned_parents()` on the returned type token the parents will be added automatically, also when on_parenth_close is not defined / not called.
		// - The parameter token, is the type def token after the matched keyword.
		// this.on_type_def_keyword = function(token) {};

		// The on post type def modifier end callback.
		// This callback is called when you can parse the post modifiers after a type definition, so for example when the "{" is reached after a type def.
		// However this callback is not called for a type def detected by "type_def_keywords", that should be handled with the "on_type_def_keyword" callback.
		// - The parameter token, is the token where the post type def modifier range ended so the token before either a "{" or ";".
		// - The return value of the callback will not be used and may be anything.
		// this.on_post_type_def_modifier_end = (token) => {};
 
		// Init vars that should be reset before each tokenize.
		this.reset();

	}

	// Attributes that should be reset before each tokenize.
	reset() {
		this.tokens = new vhighlight.Tokens();				// use an array with tokens since some tokens need to be edited after they have been appended.
		this.added_tokens = 0;								// the currently added tokens.
		this.index = null;									// the current index in the iteration, so it may be edited in case of forward lookup.
		this.prev_char = null;								// the previous char in the iteration.
		this.next_char = null;								// the next char in the iteration.
		this.batch  = "";									// current batch.
		this.line = 0;										// current line number.
		this.is_comment = false;							// is currently a comment.
		this.is_str = false;								// is currently a string.
		this.is_regex = false;								// is currently a regex string "/hello/".
		this.is_preprocessor = false;						// is currently a preprocessor statement.
		this.is_comment_keyword = false;					// is currently a "@keyword" inside a comment.
		this.is_comment_codeblock = false;					// is currently a "`somefunc()`" codeblock inside a comment.
		this.parenth_depth = 0;								// parentheses depth "( )".
		this.bracket_depth = 0;								// bracket depth "[ ]".
		this.curly_depth = 0;								// curly brackets depth "{ }".
		// this.template_depth = 0;							// template depth "< >".
		this.next_token = null;								// the next token type, defined by the previous token such ass "class" or "extends".
		this.offset = 0;									// the offset of the previously appended tokens.
		this.parents = [];									// array with parents, a parent looks like [<parent-name>, <close-id>] the close id is either the opening curly depth or the opening indent on a indent language. when the close-id is matched the last parent is removed.
															// @warning: The token type def on non indent languages must be assigned before the curly depth increase otherwise it will cause undefined behaviour.
		this.line_indent = 0;								// the indent of the current line, a space and tab both count for 1 indent.
		this.start_of_line = true;							// is at the start of the line, whitespace at the start of the line does not disable the flag.
		this.do_on_type_def_keyword = false;				// do the next on type def keyword callback.
		this.prev_nw_token_data = null;						// the previous non whitespace or linebreak token data.
		this.is_post_type_def_modifier = false;				// is between the closing parentheses and the opening curly or semicolon.
		this.post_type_def_modifier_type_def_token = null;	// the type def token from that for the on post type def modifier end callback.

		this.is_keyword_before_parentheses = false;			// is is keyword before parenth open token used not to highlight types inside parentheses of keywords before parentheses for languages with types.
															// @warning: only assigned when `is_type_language` is `true` and the keyword is not one of the `allowed_keywords_before_type_defs`.
		this.last_non_whiste_space_line_break_token = null;	// the last non whitespace non line break token that was appended.

		// Performance.
		// this.get_prev_token_time = 0;
		// this.append_token_time = 0;
	}

	// Add a parent.
	add_parent(token) {
		if (token.data.length > 0) {
			if (this.is_indent_language) {
				this.parents.push([token, this.line_indent]);
			} else {
				this.parents.push([token, this.curly_depth]);
			}
		}
	}

	// Assign parent to token.
	assign_parents(token) {
		token.parents = [];
		this.parents.iterate((item) => {
			token.parents.push(item[0]);
		})
	}

	// Copy the parents without any reference.
	copy_parents() {
		let copy = [];
		this.parents.iterate((item) => {
			copy.push([item[0], item[1]]);
		})
		return copy;
	}

	// Get the last token.
	// Returns null when there is no last token.
	get_last_token() {
		return this.tokens.iterate_tokens_reversed((token) => {
			return token;
		})
	}

	// Fetch the first non whitespace token going backwards from the specified index.
	// So it also tests the specified index. If the previous token data is excluded it checks one further back.
	get_prev_token(index, exclude = [" ", "\t", "\n"], exclude_comments = false) {
		// const now = Date.now();
		return this.tokens.iterate_tokens_reversed((token) => {
			if (token.index <= index) {
				if (exclude_comments && token.token === "comment") {
					return null;
				}
				if (!exclude.includes(token.data)) {
					return token;
				}
			}
		})
		// this.get_prev_token_time += Date.now() - now;
		// return res;
	}
	
	// Check if a string contains a word boundary character.
	str_includes_word_boundary(str) {
		for (let i = 0; i < this.word_boundaries.length; i++) {
			if (str.includes(this.word_boundaries[i])) {
				return true;
			}
		}
		return false;
	}

	// Check if a char is a whitespace or newline.
	// When the parameter is null it checks against the current batch.
	is_linebreak_whitespace_batch(x = null) {
		if (x !== null) {
			for (let i = 0; i < x.length; i++) {
				const c = x.charAt(i);
				if (c !== " " && c !== "\t" && c !== "\n") {
					return false;
				}
			}
			return true;
		} else {
			for (let i = 0; i < this.batch.length; i++) {
				const c = this.batch.charAt(i);
				if (c !== " " && c !== "\t" && c !== "\n") {
					return false;
				}
			}
			return true;
		}
	}

	// Check if the first chars of the main string equals a substring, optionally with start index.
	eq_first(substr, start_index = 0) {
	    if (start_index + substr.length > this.code.length) {
	        return false;
	    }
	    const end = start_index + substr.length;
	    let y = 0;
	    for (let x = start_index; x < end; x++) {
	        if (this.code.charAt(x) != substr.charAt(y)) {
	            return false;
	        }
	        ++y;
	    }
	    return true;
	}

	// Do a forward lookup by iterating the code from a start index.
	// Supports a single string query or an array with "or" queries.
	lookup({query, index = 0, exclude_str = true, exclude_comment = true, exclude_regex = true, exclude_preprocessor = true, exclude_escaped = true}) {
		if (typeof query === "string") {
			query = [query];
		}
		const info_obj = {index: null};
		const query_match = () => {
			for (let i = 0; i < query.length; i++) {
				if (this.eq_first(query[i], info_obj.index)) {
					return true;
				}
			}
			return false;
		}
		return this.iterate_code(info_obj, index, null, (char, is_str, is_comment, is_multi_line_comment, is_regex, is_escaped, is_preprocessor) => {
			if (
				(exclude_str === false || is_str === false) &&
				(exclude_comment === false || (is_comment === false && is_multi_line_comment === false)) &&
				(exclude_regex === false || is_regex === false) &&
				(exclude_preprocessor === false || is_preprocessor === false) &&
				(exclude_escaped === false || is_escaped === false) &&
				query_match()
			) {
				return info_obj.index;
			}
		});
	}

	// Get the index of the closing parentheses / curly from the opening's index.
	// - This uses the code data, not the tokens.
	// - Parameter `index` should be the index of the closing ">" token.
	// - Returns "null" when it has not been found.
	get_closing_parentheses(index) {
		return this.get_closing_wrapper(index, "(", ")");
	}
	get_closing_curly(index) {
		return this.get_closing_wrapper(index, "{", "}");
	}
	get_closing_bracket(index) {
		return this.get_closing_wrapper(index, "[", "]");
	}
	get_closing_template(index) {
		return this.get_closing_wrapper(index, "<", ">");
	}
	get_closing_wrapper(index, opener, closer) {
		let depth = 0;
		let start_index = index;
		if (this.code.charAt(index) === closer) {
			depth = 1;
			start_index = index + 1;
		}
		const info_obj = {index: null};
		return this.iterate_code(info_obj, start_index, null, (char, is_str, is_comment, is_multi_line_comment, is_regex) => {
			if (!is_str && !is_comment && !is_multi_line_comment && !is_regex) {
				if (char === opener) {
					++depth;
				} else if (char === closer) {
					--depth;
					if (depth === 0) {
						return info_obj.index;
					}
				}
			}
		});
	}

	// Get the token of the opening parentheses / curly / bracket.
	// - The index parameter is the index of the token, not the offset of the token.
	// - The specified token index MUST be the closing token of the scope.
	// - Returns "null" when it has not been found.
	get_opening_parentheses(index) {
		return this.get_opening_wrapper(index, "(", ")");
	}
	get_opening_curly(index) {
		return this.get_opening_wrapper(index, "{", "}");
	}
	get_opening_bracket(index) {
		return this.get_opening_wrapper(index, "[", "]");
	}
	get_opening_template(index) {
		return this.get_opening_wrapper(index, "<", ">");
	}
	get_opening_wrapper = (index, opener, closer) => {
		let depth = 0;
		let start_index = index;
		let result = null;
		this.tokens.iterate_reversed((line_tokens) => {
			if (line_tokens.length > 0) {
				line_tokens.iterate_reversed((token) => {
					if (token.index <= start_index) {
						if (token.data === opener) {
							--depth;
							if (depth === 0) {
								result = token;
								return false;
							}
						} else if (token.data === closer) {
							++depth;
						}
					}
				})
				if (result !== null) {
					return false;
				}
			}
		})
		return result;
	}

	// Get the first non whitespace character from a given index.
	// - Returns the index of the found char.
	// - Returns "null" when the index is "null" to limit the if else statements.
	get_first_non_whitespace(index, include_line_breaks = false) {
		if (index == null) {
			return null;
		}
		let end;
		for (end = index; end < this.code.length; end++) {
			const c = this.code.charAt(end);
			if (c !== " " && c !== "\t" && (include_line_breaks === false || c !== "\n")) {
				return end;
			}
		}
		return null;
	}

	// Get the first whitespace character from a given index.
	// - Returns the index of the found char.
	// - Returns "null" when the index is "null" to limit the if else statements.
	get_first_whitespace(index, include_line_breaks = false, def = null) {
		if (index == null) {
			return def;
		}
		let end;
		for (end = index; end < this.code.length; end++) {
			const c = this.code.charAt(end);
			if (c === " " || c === "\t" || (include_line_breaks && c === "\n")) {
				return end;
			}
		}
		return def;
	}

	// Get first word boundary index.
	get_first_word_boundary(index) {
		if (index == null) {
			return null;
		}
		for (let i = index; i < this.code.length; i++) {
			if (this.word_boundaries.includes(this.code.charAt(i))) {
				return i;
			}
		}
		return this.code.length;
	}

	// Is a whitespace character.
	is_whitespace(char) {
		return char == " " || char == "\t";
	}

	// Is an alphabetical character.
	is_alphabetical(char) {
		return char.length > 0 && Tokenizer.alphabet.includes(char);
	}

	// Is an uppercase alphabetical character.
	is_uppercase(char) {
		return char.length > 0 && Tokenizer.uppercase_alphabet.includes(char);
	}
	is_full_uppercase(str, other_allowed_chars = null) {
		if (str.length === 0) {
			return false;
		}
		for (let i = 0; i < str.length; i++) {
			if (
				Tokenizer.uppercase_alphabet.includes(str.charAt(i)) === false &&
				(other_allowed_chars === null || other_allowed_chars.includes(str.charAt(i)) === false)
			) {
				return false;
			}
		}
		return true;
	}

	// Is a numeric character.
	is_numerical(char) {
		return char.length > 0 && Tokenizer.numerics.includes(char);
	}

	// Check if an a character is escaped by index.
	is_escaped(index, str = null) {
		if (str == null) {
			if (this.code.charAt(index - 1) == "\\") {
				if (this.code.charAt(index - 2) == "\\") {
					return this.is_escaped(index - 2);
				}
				return true;
			}
		} else {
			if (str.charAt(index - 1) == "\\") {
				if (str.charAt(index - 2) == "\\") {
					return this.is_escaped(index - 2, str);
				}
				return true;
			}
		}
		return false;
	}

	// Concat tokens to the end of the current tokens.
	concat_tokens(tokens) {
		tokens.iterate_tokens((token) => {
			token.line = this.line;
			if (token.is_line_break) {
				++this.line;
			}
			token.offset = this.offset;
			this.offset += token.data.length;
			token.index = this.added_tokens;
			++this.added_tokens;
			if (this.tokens[token.line] === undefined) {
				this.tokens[token.line] = [token];
			} else {
				this.tokens[token.line].push(token);
			}
		})
	}

	// Trim an array of (reversed) tokens.
	// Removes the whitespace tokens at the start and the end.
	trim_tokens(tokens, reversed = false) {
		if (tokens.length === 0) { return []; }
		for (let i = tokens.length - 1; i >= 0; i--) {
			const token = tokens[i];
			if (token.is_whitespace === true) {
				--tokens.length;
			} else {
				break;
			}
		}
		let clean = [], first = true;
		for (let i = 0; i < tokens.length; i++) {
			const token = tokens[i];
			if (first && token.is_whitespace === true) {
				continue;
			} else {
				first = false;
				clean.push(token)
			}
		}
		if (reversed) {
			tokens = [];
			clean.iterate_reversed((token) => {
				tokens.push(token)
			})
			return tokens;
		} else {
			return clean;
		}
		return clean;	
	}

	// Append a token.
	// Do not join null tokens since that would clash with the prev batch function lookup and comparing it with data.
	// For example when exlcuding whitespace in the prev token, it can still contain whitespace.
	append_token(token = null, extended = {}) {
		// const now = Date.now();

		// Create default object.
		const obj = {...extended};
		obj.data = this.batch;
		obj.index = this.added_tokens;
		obj.line = this.line;
		obj.offset = this.offset;
		if (token != null) {
			obj.token = token;
		}

		// Set is word boundary.
		if (
			(extended.is_word_boundary === true) ||
			(
				this.batch.length === 1 && 
				(token === null || token === "operator") && // token is null or is token operator in case the language class appends the token as operator without the is_word_boundary param.
				this.word_boundaries.includes(this.batch)
			)
		) {
			obj.is_word_boundary = true;
		}

		// Set is whitespace.
		if (obj.data.length === 1 && (obj.data === " " || obj.data === "\t" || obj.data === "\n")) {
			obj.is_whitespace = true;
		}

		// Set inside comment, string, regex or preprocessor.
		// This should always be set for line breaks, but also for strings when preprocessor are enabled since they can be inside preprocessor and still be a string token.
		// Use if statements since a token can be both a preprocesesor and a string etc.
		if (token === "line" || (this.allow_preprocessors && token === "string")) {
			if (this.is_comment) {
				obj.is_comment = true;
			}
			if (this.is_str) {
				obj.is_str = true;
			}
			if (this.is_regex) {
				obj.is_regex = true;
			}
			if (this.is_preprocessor) {
				obj.is_preprocessor = true;
			}
		}

		// Set parents.
		else if (this.do_on_type_def_keyword !== true && token === "type_def") {
			this.assign_parents(obj);
			this.add_parent(obj);
		}

		// Update offset.
		this.offset += this.batch.length;

		// Set previous non whitespace + line break token data.
		if (obj.is_line_break !== true && this.batch !== " " && this.batch !== "\t" && this.batch !== "\n") {
			this.prev_nw_token_data = obj.data;
		}

		// Concat to previous token.
		// - Do this after the update offset.
		// - The concated tokens must not be excluded and either both be a word boundary or both be whitespace.
		// - Whitespace tokens must remain all whitespace since certain checks require a check if a token is whitespace only.
		// - Never concat tokens when the token is defined, even when the last and current tokens are the same. Since certain checks require a check for a specific operator, such as `parse_pre_func_tokens()` in `vhighlight.cpp`.
		if (token === null && (obj.is_word_boundary === true || obj.is_whitespace === true)) {
			const line_tokens = this.tokens[this.line];
			if (line_tokens !== undefined) {
				const last = line_tokens[line_tokens.length - 1];
				if (
					last !== undefined &&
					last.is_word_boundary === obj.is_word_boundary && 
					last.is_whitespace === obj.is_whitespace && 
					(last.data.length > 1 || !this.excluded_word_boundary_joinings.includes(last.data)) &&
					!this.excluded_word_boundary_joinings.includes(obj.data)
				) {
					last.data += obj.data;
					return null; // STOP.
				}
			}
		}

		// Increment added tokens after concat to previous tokens.
		++this.added_tokens;

		// Set is line break.
		if (token === "line") {
			obj.is_line_break = true;
		}

		// Append token.
		if (this.tokens[this.line] === undefined) {
			this.tokens[this.line] = [obj];
		} else {
			this.tokens[this.line].push(obj);
		}

		// Set the last non whitespace or linebreak token.
		if (obj.is_whitespace !== true && obj.is_line_break !== true) {
			this.last_non_whiste_space_line_break_token = obj;
		}

		// Performance.
		// this.append_time += Date.now() - now;

		// Return the token.
		return obj;
	}
	
	// Append batch.
	// - Batches should only be a single word, unless it is a string or comment
	// - When the token param is false, no spans will be added, when the token ...
	//   Is not null the assigned token will be added as span. And when the token param ...
	//   Is null the batch will be checked against keywords, numerics etc.
	append_batch(token = null, extended = {}) {
		if (this.batch.length == 0) {
			return null;
		}
		let appended_token;

		// Do not parse tokens.
		if (token == false) {
			appended_token = this.append_token(null, extended);
		}
		
		// By assigned token.
		else if (token != null) {
			appended_token = this.append_token(token, extended);
		}
		
		// By next token.
		// Skip whitespace.
		else if (this.next_token != null) {

			// Skip next token but do not reset on whitespace batch.
			if (this.is_linebreak_whitespace_batch()) {
				appended_token = this.append_token(null, extended);
			}

			// Reset next token when the batch is a word boundary for example in "struct { ... } X".
			else if (extended.is_word_boundary === true || this.word_boundaries.includes(this.batch)) {
				appended_token = this.append_token(null, {is_word_boundary: true});
				this.next_token = null;
				this.do_on_type_def_keyword = false;
			}

			// Reset next token when the batch is a keyword for example in "constexpr inline X".
			else if (this.keywords.includes(this.batch)) {
				appended_token = this.append_token("keyword");
				this.next_token = null;
				this.do_on_type_def_keyword = false;
			}

			// Append as next token.
			else {
				appended_token = this.append_token(this.next_token, extended);
				this.next_token = null;
				if (this.do_on_type_def_keyword === true && this.on_type_def_keyword !== undefined) {
					this.on_type_def_keyword(appended_token);
				}
				this.do_on_type_def_keyword = false;
			}
		}
		
		// Parse batch.
		else {
			
			// Keyword.
			if (this.keywords.includes(this.batch)) {
				
				// Set class depth.
				if (
					this.type_def_keywords.includes(this.batch) && 
					(this.prev_nw_token_data == null || this.exclude_type_def_keywords_on_prev.length === 0 || this.exclude_type_def_keywords_on_prev.includes(this.prev_nw_token_data) == false)
				) {

					// Some languages as c++ can also use certain type def keywords such as `struct` to initialize a variable, e.g. `struct passwd pass;`.
					// Therefore it should be checked if the first character after the name of the initialized type def or type starts with an alphabetical character or not.
					// When it is an alphabetical character then it is not a type definition but a type.
					let is_type_def = true;
					if (this.language === "C++" && this.batch === "struct") {
						let first, second, third;
						if (
							(first = this.get_first_non_whitespace(this.index, true)) != null &&
							(second = this.get_first_whitespace(first, true)) != null &&
							(third = this.get_first_non_whitespace(second, true)) != null &&
							this.is_alphabetical(this.code.charAt(third))
						) {
							is_type_def = false;
						}
					}

					// Add as type def.
					if (is_type_def) {
						this.next_token = "type_def"
						this.do_on_type_def_keyword = this.on_type_def_keyword !== undefined;
					} 

					// Add as type.
					else {
						this.next_token = "type"
					}
				}
				
				// Next tokens.
				else if (this.type_keywords.includes(this.batch)) {
					this.next_token = "type";
				}
				
				// Append.
				appended_token = this.append_token("keyword");
			}
			
			// Operator.
			else if (
				this.operators.includes(this.batch) &&
				(this.language !== "Bash" || this.batch !== "/" || (this.is_alphabetical(this.next_char) === false && this.is_alphabetical(this.prev_char) === false)) // skip operators where the next char is alphabetical for example the slashes in "/path/to/"
			) {
				appended_token = this.append_token("operator", {is_word_boundary: true});
			}
			
			// Numeric.
			else if (this.allow_numerics && /^-?\d+(\.\d+)?$/.test(this.batch)) {
				appended_token = this.append_token("numeric");
			}
			
			// Just a code batch without highlighting.
			else {
				appended_token = this.append_token(null, extended);
			}
			
		}
		
		// Reset batch.
		this.batch = "";

		// Return the appended token.
		return appended_token;		
	}

	// Append lookup token.
	// This function must be used when appending new tokens by a forward lookup.
	// Since every line break should be a seperate line break token for VIDE.
	append_forward_lookup_batch(token, data, extended = {}) {

		// Vars.
		let appended_token, appended_tokens = [];

		// Add current batch.
		if (this.batch.length > 0) {
			appended_token = this.append_batch();
			if (appended_token != null) {
				appended_tokens.push(appended_token);
			}
		}
		this.batch = "";

		// Reset the next token attribute since this will not be reset by the current append batch behaviour.
		this.next_token = null;

		// Seperate the line tokens.
		for (let i = 0; i < data.length; i++) {
			let c = data.charAt(i);
			if (c == "\n" && !this.is_escaped(i, data)) {
				appended_token = this.append_batch(token, extended);
				if (appended_token != null) {
					appended_tokens.push(appended_token);
				}
				this.batch = "\n";
				const appended_line_token = this.append_batch("line", extended);
				if (appended_token != null) {
					appended_tokens.push(appended_token);
				}
				++this.line;
			} else {
				this.batch += c;
			}
		}

		// Last batch.
		appended_token = this.append_batch(token, extended);
		if (appended_token != null) {
			appended_tokens.push(appended_token);
		}

		// Handler.
		return appended_tokens;
	}

	// Resume the iteration at a certain index.
	// So do not assign directly to this.index but use this function instead.
	// Otherwise the line numbers may be counted incorrectly.
	resume_on_index(index) {
		
		// Increment line count.
		// Became obsolete by "append_forward_lookup_batch()".
		// const info_obj = {index: null, prev_char: null, next_char: null};
		// this.iterate_code(info_obj, this.index, index + 1, (char, is_str, is_comment, is_multi_line_comment, is_regex, is_escaped) => {
		// 	if (!is_escaped && char == "\n") {
		// 		++this.line;
		// 	}
		// })

		// Set index.
		this.index = index;
	}

	// Iterate code function.
	// The callback can take params (index, char, is_str, is_comment, is_multi_line_comment, is_regex, is_escaped).
	// When the callback returns a non null value the iteration will stop and that value will be returned.
	iterate_code(info_obj = {index: 0, prev_char: null, next_char: null}, start = null, end = null, callback) {
		//
		// DO NOT ASSIGN ANY "this" ATTRIBUTES IN THIS FUNC SINCE IT IS ALSO CALLED BY OTHER FUNCS THAN "tokenize()".
		//
		
		// Default start and end.
		if (start == null) {
			start = 0;
		}
		if (end == null) {
			end = this.code.length;
		}

		// Vars.
		let is_comment = false;
		let is_multi_line_comment = false;
		let string_char = null;
		let is_regex = false; 									// only used for langauges that can define a regex as /hello/ such as js.
		let is_preprocessor = false; 							// only used for languages that have preprocessor statements such as cpp.
		let prev_non_whitespace_char = null; 					// the previous non whitespace character, EXCLUDING newlines, used to check at start of line.
		let multi_line_comment_check_close_from_index = null;	// the start index of the multi line comment because when a user does something like /*// my comment */ the comment would originally immediately terminate because of the /*/.
		let inside_template_string_code = null;					// is inside the ${} code of a js template string, the value will be assigned to the opening string char.
		let inside_template_curly_depth = 0;

		// Iterate.
		for (info_obj.index = start; info_obj.index < end; info_obj.index++) {
			//
			// DO NOT ASSIGN ANY "this" ATTRIBUTES IN THIS FUNC SINCE IT IS ALSO CALLED BY OTHER FUNCS THAN "tokenize()".
			//

			// Get char.
			const char = this.code.charAt(info_obj.index);

			// Set next and previous.
			info_obj.prev_char = this.code.charAt(info_obj.index - 1);
			info_obj.next_char = this.code.charAt(info_obj.index + 1);

			// Set prev non whitespace char.
			if (info_obj.prev_char != " " && info_obj.prev_char != "\t") {
				prev_non_whitespace_char = info_obj.prev_char;
			}

			// Set is escaped.
			const is_escaped = this.is_escaped(info_obj.index);

			// Start of preprocessors.
			if (
				this.allow_preprocessors && 
				!is_preprocessor && 
				(prev_non_whitespace_char == "\n" || info_obj.index === 0) && 
				char == "#"
			) {
				is_preprocessor = true;
				const res = callback(char, false, is_comment, is_multi_line_comment, is_regex, is_escaped, is_preprocessor);
				if (res != null) { return res; }
				continue;
			}

			// End of preprocessors.
			else if (
				is_preprocessor && 
				(char == "\n" && prev_non_whitespace_char != "\\") 
			) {
				is_preprocessor = false;
				const res = callback(char, false, is_comment, is_multi_line_comment, is_regex, is_escaped, is_preprocessor);
				if (res != null) { return res; }
				continue;
			}
			
			// Open strings.
			if (
				this.allow_strings &&
				!is_escaped &&
				!is_comment &&
				!is_multi_line_comment &&
				!is_regex &&
				string_char == null &&
				(
					char == '"' || 
					char == "'" || 
					char == '`'
				)
			) {
				string_char = char;
				const res = callback(char, true, is_comment, is_multi_line_comment, is_regex, is_escaped, is_preprocessor);
				if (res != null) { return res; }
				continue;
			}

			// Close strings.
			else if (
				!is_escaped &&
				string_char != null &&
				char == string_char
			) {
				string_char = null;
				const res = callback(char, true, is_comment, is_multi_line_comment, is_regex, is_escaped, is_preprocessor);
				if (res != null) { return res; }
				continue;
			}

			// Inside strings.
			else if (string_char != null) {

				// Close string by js ${} template string.
				if (this.language === "JS" && char === "$" && info_obj.next_char === "{") {
					inside_template_string_code = string_char;
					inside_template_curly_depth = 0;
					string_char = null;
					const res = callback(char, false, is_comment, is_multi_line_comment, is_regex, is_escaped, is_preprocessor);
					if (res != null) { return res; }
					continue;
				}

				// Inside string.
				const res = callback(char, true, is_comment, is_multi_line_comment, is_regex, is_escaped, is_preprocessor);
				if (res != null) { return res; }
				continue;
			}

			// The end of js ${} code inside a template string.
			if (inside_template_string_code !== null) {
				if (string_char == null && char === "{") {
					++inside_template_curly_depth;
				} else if (string_char == null && char === "}") {
					--inside_template_curly_depth;

					// Re-open the string.
					if (inside_template_curly_depth === 0) {
						string_char = inside_template_string_code;
						inside_template_string_code = null;
						const res = callback(char, false, is_comment, is_multi_line_comment, is_regex, is_escaped, is_preprocessor);
						if (res != null) { return res; }
						continue;			
					}
				}
			}
			
			// Open comments.
			if (
				!is_escaped &&
				!is_comment &&
				!is_multi_line_comment &&
				!is_regex
				// && string_char == null
			) {
				
				// Single line comments.
				if (
					this.single_line_comment_start !== false && 
					(
						(this.single_line_comment_start.length === 1 && char === this.single_line_comment_start) ||
						(this.single_line_comment_start.length !== 1 && this.eq_first(this.single_line_comment_start, info_obj.index))
					)
				) {
					is_preprocessor = false; // a single line comment in the preprocessor line terminates the preprocessor statement.
					is_comment = true;
					const res = callback(char, false, is_comment, is_multi_line_comment, is_regex, is_escaped, is_preprocessor);
					if (res != null) { return res; }
					continue;
				}
				
				
				// Multi line comments.
				if (
					this.multi_line_comment_start !== false &&
					(
						(this.multi_line_comment_start.length === 1 && char === this.multi_line_comment_start) ||
						(this.multi_line_comment_start.length !== 1 && this.eq_first(this.multi_line_comment_start, info_obj.index))
					)
				) {
					multi_line_comment_check_close_from_index = info_obj.index + this.multi_line_comment_start.length + this.multi_line_comment_end.length; // also add mlcomment end length since the mlc close looks backwards.
					is_multi_line_comment = true;
					const res = callback(char, false, is_comment, is_multi_line_comment, is_regex, is_escaped, is_preprocessor);
					if (res != null) { return res; }
					continue;
				}
				
			}
			
			// End single line comments.
			else if (
				is_comment &&
				!is_escaped && char == "\n"
			) {
				is_comment = false;
				const res = callback(char, false, is_comment, is_multi_line_comment, is_regex, is_escaped, is_preprocessor);
				if (res != null) { return res; }
				continue;
			}
			
			// End multi line comments.
			else if (
				is_multi_line_comment &&
				!is_escaped &&
				info_obj.index >= multi_line_comment_check_close_from_index &&
				(
					(this.multi_line_comment_end.length === 1 && char == this.multi_line_comment_end) ||
					(this.multi_line_comment_end.length !== 1 && this.eq_first(this.multi_line_comment_end, info_obj.index - (this.multi_line_comment_end.length - 1)))
				)
			) {
				is_multi_line_comment = false;
				const res = callback(char, false, is_comment, true, is_regex, is_escaped, is_preprocessor);
				if (res != null) { return res; }
				continue;
			}
			
			// Inside comments.
			else if (is_comment || is_multi_line_comment) {
				const res = callback(char, false, is_comment, is_multi_line_comment, is_regex, is_escaped, is_preprocessor);
				if (res != null) { return res; }
				continue;
			}
			
			// Statements should reuse the "if" not "else if" after the start of the comment check.
			// Since that does not always match in the first if statement.
			// End of comment checks can still use "else if".
			
			// Check the start of a regex definition "/hello/", must check the previous char.
			if (this.allow_slash_regexes && !is_escaped && !is_regex && char == "/") {
				let prev = null;
				for (let p = info_obj.index - 1; p >= 0; p--) {
					const c = this.code.charAt(p);
					if (c != " " && c != "\t") {
						prev = c;
						break;
					}
				}
				if (
					prev != null &&
					(
						prev == "\n" || prev == "," || prev == "(" ||
						prev == "[" || prev == "{" || prev == ":" ||
						this.operators.includes(prev)
					)
				) {
					is_regex = true;
					const res = callback(char, false, is_comment, is_multi_line_comment, is_regex, is_escaped, is_preprocessor);
					if (res != null) { return res; }
					continue;
				}
			}
			
			// Inside / end of regex.
			else if (is_regex) {
				if (char == '/' && !is_escaped) {
					is_regex = false;
				}
				const res = callback(char, false, is_comment, is_multi_line_comment, true, is_escaped, is_preprocessor); // always use true for is_regex to make sure the closing / is still treated as a regex.
				if (res != null) { return res; }
				continue;
			}
			
			// Statements should reuse the "if" not "else if" after the start of the regex check.
			// Since that does not always match in the first if statement.
			// End of regex checks can still use "else if".
			
			// No string, comment or regex.
			const res = callback(char, false, is_comment, is_multi_line_comment, is_regex, is_escaped, is_preprocessor);
			if (res != null) { return res; }
			
			
		}
		return null;
	};

	// Start the tokenizing.
	// - The comment, strings and regexes are already handled so the callback is only called on code characters.
	// - The "this.callback" should return "true" to indicate the character has been appended to the batch, and "false" if not.
	// - Each word boundary seperates a token. The callback is required to respect this, since this ignoring this behaviour may cause undefined behaviour.
	// - When performing a forward lookup and editing this.index afterwards, dont forget to incrrement the this.line var on line breaks.
	tokenize({
		code = null,
		stop_callback = undefined,
		build_html = false,
		is_insert_tokens = false,
	} = {}) {

		// Reset.
		this.reset();

		// Derived reset.
		if (this.derived_reset !== undefined) {
			this.derived_reset();
		}

		// Assign code when not already assigned.
		if (code !== null) {
			this.code = code;
		}

		// Check seperate batch append token comment codeblock for the first " * " in languages with /* */ multi line comment style
		const append_comment_codeblock_batch = () => {
			if (this.multi_line_comment_start === "/*") {
				let i, separate = false;
				for (i = 0; i < this.batch.length; i++) {
					const c = this.batch.charAt(i);
					if (c === "*") {
						separate = true;
						const next = this.batch.charAt(i + 1);
						if (next === " " || next === "\t") {
							i += 2;
						}
						break;
					}
					else if (c === " " || c === "\t") {
						continue;
					}
					else {
						break;
					}
				}
				if (separate) {
					const after = this.batch.substr(i);
					this.batch = this.batch.substr(0, i);
					this.append_batch("comment", {is_comment: true});
					this.batch = after;
				}
			}
			this.append_batch("comment_codeblock", {is_comment: true});
		}

		// Append previous batch when switching comment, string, regex, to something else.
		const auto_append_batch_switch = (default_append = true) => {
			if (this.is_comment_keyword) {
				this.append_batch("comment_keyword", {is_comment: true});
			} else if (this.is_comment_codeblock) {
				append_comment_codeblock_batch();
			} else if (this.is_comment) {
				this.append_batch("comment", {is_comment: true});
			} else if (this.is_str) {
				this.append_batch("string");
			} else if (this.is_regex) {
				this.append_batch("string");
			} else if (this.is_preprocessor) {
				this.append_batch("preprocessor");
			} else {
				if (default_append) {
					this.append_batch();
				} else {
					return false;
				}
			}
			return true;
		}

		// Iterate code.
		let shebang_allowed = true;
		let disable_start_of_line = false;
		let start_of_line_last_line = null;
		const stopped = this.iterate_code(this, null, null, (char, local_is_str, local_is_comment, is_multi_line_comment, local_is_regex, is_escaped, is_preprocessor) => {

			// Start of line.
			// Set start of line flag and line indent for parent closings on indent languages.
			// The start of line flag must still be true for the first non whitespace character.
			if (disable_start_of_line === false && (this.start_of_line || start_of_line_last_line != this.line)) {

				// Allow whitespace at the line start.
				if (char === " " || char === "\t") {
					++this.line_indent;
				}

				// Set the last line disabling the start_of_line flag for next characters.
				else {

					// Close parent, exclude whitespace only lines.
					if (this.is_indent_language === true && char !== "\n") {
						while (this.parents.length > 0 && this.parents[this.parents.length - 1][1] === this.line_indent) {
							--this.parents.length;
						}
					}

					// Set disable start of line flag for the next char.
					disable_start_of_line = true;
					start_of_line_last_line = this.line;
				}
			} else if (disable_start_of_line) {
				this.start_of_line = false;
			}

			//
			// Resume with if after "Start of line".
			//

			// Shebang.
			if (this.line === 0 && this.start_of_line && char === "#" && this.next_char === "!") {

				// Append previous batch.
				this.append_batch();

				// Do a lookup for the shebang.
				let shebang = "";
				let resume_index;
				for (resume_index = this.index; resume_index < this.code.length; resume_index++) {
					const c = this.code.charAt(resume_index);
					if (c === "\n") {
						break;
					}
					shebang += c;
				}

				// Get the last word boundary for the interpreter.
				let last_word_boundary;
				for (last_word_boundary = shebang.length - 1; last_word_boundary > 0; last_word_boundary--) {
					if (this.word_boundaries.includes(shebang.charAt(last_word_boundary))) {
						break;
					}
				}

				// Append tokens.
				if (last_word_boundary === 0) {
					this.batch = shebang;
					this.append_batch("comment");
				} else {
					++last_word_boundary;
					this.batch = shebang.substr(0, last_word_boundary);
					this.append_batch("comment");
					this.batch = shebang.substr(last_word_boundary); // interpreter.
					this.append_batch("keyword");
				}

				// Set resume on index.
				this.resume_on_index(resume_index - 1);
				return null;
			}

			// New line.
			else if (!is_escaped && char == "\n") {

				// Append previous batch, but snce newlines may be present in regexes, strings and comments, handle them correctly.
				auto_append_batch_switch();
				
				// Append line token.
				// this.batch += char;
				// this.append_batch("line");

				// Terminate preprocessor, comments, and strings when active.
				// This must happen after appending the line break batch since `append_token()` still uses the comment string etc flags for the line token.
				if (!local_is_str) {
					this.is_str = false;
				}
				if (!local_is_comment && !is_multi_line_comment) {
					this.is_comment = false;
					this.is_comment_keyword = false;
					// this.is_comment_codeblock = false; // may be multi line.
				}
				if (!local_is_regex) {
					this.is_regex = false;
				}
				if (this.is_preprocessor && !is_preprocessor) {
					this.is_preprocessor = false;
					this.is_str = false; // also disable string in case of an unterminated < inside the #include preprocessor, since the flag is turned on inside the is preprocessor check.
				}

				// Append line token.
				// Testing with after disabling the flags otherwise the newlines after a multi line comment will still count as a comment which it is not.
				this.batch += char;
				this.append_batch("line");

				// Check if a stop callback is defined for the partial tokenize.
				if (stop_callback !== undefined) {
					const stop = stop_callback(this.line, this.tokens[this.line]);
					if (stop) {
						return true;
					}
				}

				// Update vars.
				this.start_of_line = true;
				this.line_indent = 0;
				++this.line;
			}
			
			// Start of and during comment.
			else if (local_is_comment || is_multi_line_comment) {

				// Start of comment.
				if (!this.is_comment) {
					auto_append_batch_switch();
					this.is_comment = true;
					this.batch += char;
				}

				// During comment.
				else {

					// End of comment codeblock.
					if (this.is_comment_codeblock && char === "`" && this.next_char !== "`") {
						this.batch += char;
						auto_append_batch_switch();
						this.is_comment_codeblock = false;
					}

					// Start of comment codeblock.
					else if (this.allow_comment_codeblock && !this.is_comment_codeblock && char === "`") {
						auto_append_batch_switch();
						this.is_comment_codeblock = true;
						this.batch += char;
					}

					// Check for @ keywords.
					else if (this.allow_comment_keyword && !this.is_comment_codeblock && char === "@" && !is_escaped) {
						auto_append_batch_switch();
						this.is_comment_keyword = true;
						this.batch += char;
					}

					// Check for end of @ keywords.
					// Some word boundaries are allowed inside comment keywords, such as "-", "_", "/". This is required for Libris and it also makes sense.
					else if (this.is_comment_keyword && (char !== "-" && char !== "_" && char !== "/" && this.word_boundaries.includes(char))) {
						auto_append_batch_switch();
						this.is_comment_keyword = false;	
						this.batch += char;
					}

					// Append to batch.
					else {
						this.batch += char;
					}
				}
			}
			
			// Start of and during string.
			else if (local_is_str) {
				if (!this.is_str) {

					// Check for special prefix chars.
					if (auto_append_batch_switch(false) === false) {
						if (this.special_string_prefixes.includes(this.batch)) {
							this.append_batch("keyword");
						} else {
							this.append_batch();
						}
					}
					this.is_str = true;
				}
				this.batch += char;
			}
			
			// Start of and during regex.
			else if (local_is_regex) {
				if (!this.is_regex) {
					auto_append_batch_switch();
					this.is_regex = true;
				}
				this.batch += char;
			}

			// Start of and during preprocessor.
			else if (is_preprocessor) {

				// Append previous batch.
				if (!this.is_preprocessor) {
					auto_append_batch_switch();
					this.is_preprocessor = true;
				}

				// Encountered a < > inside a preprocessor.
				if (char == "<" && this.batch.replaceAll(" ", "").replaceAll("\t", "") == "#include") {
					auto_append_batch_switch();
					this.is_str = true;
					this.batch += char;
				} else if (char == ">" && this.is_str) {
					this.batch += char;
					auto_append_batch_switch();
					this.is_str = false;
				}

				// Append to batch when no < > match.
				else {
					this.batch += char;
				}
			}
			
			// Is code.
			else {

				// Bracket depth.
				if (char == "[") {
					++this.bracket_depth;
				} else if (char == "]") {
					--this.bracket_depth;
				}

				// Curly depth.
				if (char == "{") {
					++this.curly_depth;

					// Disable the is post type def modifier and call the callback when defined.
					if (this.is_post_type_def_modifier) {
						this.is_post_type_def_modifier = false;
						if (this.on_post_type_def_modifier_end !== undefined) {
							const last_token = this.get_last_token();
							if (last_token != null) {
								this.on_post_type_def_modifier_end(this.post_type_def_modifier_type_def_token, last_token);
							}
						}
					}

				} else if (char == "}") {
					--this.curly_depth;

					// Remove parent.
					if (this.is_indent_language === false) {
						while (this.parents.length > 0 && this.parents[this.parents.length - 1][1] === this.curly_depth) {
							--this.parents.length;
						}
					}
				}
				
				// Parentheses depth.
				if (char == "(") {
					++this.parenth_depth;

					// Set the is keyword before parenth open token so it can be identifier by "callback()" in order not to highlight types inside parentheses of keywords before parentheses.
					if (this.is_type_language) {

						// Enable flag.
						if (
							this.last_non_whiste_space_line_break_token !== null && 
							this.last_non_whiste_space_line_break_token.token === "keyword" && 
							this.allowed_keywords_before_type_defs.includes(this.last_non_whiste_space_line_break_token.data) === false
						) {
							this.is_keyword_before_parentheses = true;
						}
							
						// Disable flag.
						else {
							this.is_keyword_before_parentheses = false;
						}
					}

					//
					// @todo when an indent languages does not always define type def tokens with a keyword then the opening parenth indent should be set here but for now it is not required.
					//

				} else if (char == ")") {
					--this.parenth_depth;
				}

				// Template depth.
				// Cant be used since "x < y" is allowed.
				// if (char == "<") {
				// 	++this.template_depth;
				// } else if (char == ">") {
				// 	--this.template_depth;
				// }

				// Disable the is post type def modifier and call the callback when defined.
				// But only when the char is ';' of a type definition header, the type defs that include a body will be catched by the opening "{"
				if (this.is_post_type_def_modifier && char === ";") {
					this.is_post_type_def_modifier = false;
					if (this.on_post_type_def_modifier_end !== undefined) {
						const last_token = this.get_last_token();
						if (last_token != null) {
							this.on_post_type_def_modifier_end(this.post_type_def_modifier_type_def_token, last_token);
						}
					}
				}
				
				// End of comment.
				// Should proceed with the callback since the next character needs to be parsed.
				if (this.is_comment_keyword) {
					this.append_batch("comment_keyword", {is_comment: true});
					this.is_comment_keyword = false;
				}
				else if (this.is_comment_codeblock) {
					append_comment_codeblock_batch();
					this.is_comment_codeblock = false;
				}
				else if (this.is_comment) {
					this.append_batch("comment", {is_comment: true});
					this.is_comment = false;
					this.is_comment_keyword = false;
					this.is_comment_codeblock = false;
				}
				
				// End of string.
				// Should proceed with the callback since the next character needs to be parsed.
				else if (this.is_str) {
					this.append_batch("string");
					this.is_str = false;
				}
				
				// End of regex.
				// Should proceed with the callback since the next character needs to be parsed.
				else if (this.is_regex) {
					this.append_batch("string");
					this.is_regex = false;
				}

				// End of preprocessor.
				// Should proceed with the callback since the next character needs to be parsed.
				else if (this.is_preprocessor) {
					this.append_batch("preprocessor");
					this.is_preprocessor = false;
				}

				//
				// Stop the else if loop after here since the end of string / comment should be parsed as a new char.
				// Also `auto_append_batch()` is no longer required after here.
				//

				// Parse decorators.
				if (this.allow_decorators && char === "@") {

					// Append previous batch.
					this.append_batch();

					// Do a forward lookup to find the first word boundary.
					let batch = "@";
					for (let i = this.index + 1; i < this.code.length; i++) {
						const c = this.code.charAt(i);
						if (this.word_boundaries.includes(c)) {
							break;
						}
						batch += c;
					}

					// When there is at least one char used in the decorator then parse it as a decorator.
					if (batch.length > 1) {
						this.batch = batch;
						this.append_batch("type", {is_decorator: true, parameters: []});
						this.index += batch.length - 1;
						return null;
					}

					// fallthrough.
				}

				// Highlight parameters.
				// @todo check if there are any post keywords between the ")" and "{" for c like langauges. Assign them to the type def token as "post_modifiers".
				// @todo check if there are any pre keywords between before the "funcname(", ofc exclude "function" etc, cant rely on the type def tokens. Assign them to the type def token as "pre_modifiers".
				// @todo when using a lot of tuple like functions `(() => {})()` which are often used in typescript, this becomes waaaaayy to slow.
				else if (this.allow_parameters && char === ")") {

					// ---------------------------------------------------------

					// Append batch by word boundary.
					this.append_batch();

					// Vars.
					let opening_parenth_token;
					let after_parenth_index;

					// Append word boundary.
					const finalize = () => {
						this.batch += char;
						this.append_batch(null, {is_word_boundary: true}); // do not use "false" as parameter "token" since the word boundary may be an operator.
						return null;
					}

					// ---------------------------------------------------------
					// Get the opening parentheses.

					// Check character after closing parentheses.
					after_parenth_index = this.get_first_non_whitespace(this.index + 1, true);

					// Get the tokens inside the parentheses at the correct pareth depth and skip all word boundaries except ",".
					let parenth_depth = 0, curly_depth = 0, bracket_depth = 0, parenth_tokens = [];
					let is_assignment_parameters = false, first_token = true;
					const found = this.tokens.iterate_tokens_reversed((token) => {

						// Set depths.
						if (token.token === undefined && token.data.length === 1) {
							if (token.data === ")") {
								++parenth_depth;
							} else if (token.data === "(") {
								if (parenth_depth === 0) {
									opening_parenth_token = token;
									return true;
								}
								--parenth_depth;
							} else if (token.data === "}") {
								++curly_depth;
							} else if (token.data === "{") {
								--curly_depth;
							} else if (token.data === "]") {
								++bracket_depth;
							} else if (token.data === "[") {
								--bracket_depth;
							}
						}

						// Check if are js assignment params defined like `myfunc({param = ...})`.
						if (first_token && (token.data.length > 1 || (token.data != " " && token.data != "\t" && token.data != "\n"))) {
							is_assignment_parameters = token.data.length === 1 && token.data === "}";
							first_token = false;
						}

						// Append token.
						token.at_correct_depth = parenth_depth === 0 && bracket_depth === 0 && ((is_assignment_parameters && curly_depth <= 1) || curly_depth <= 0);
						parenth_tokens.push(token);
					});

					// Opening parenth not found.
					if (opening_parenth_token == null) {
						parenth_tokens.iterate_reversed((token) => { delete token.at_correct_depth; });
						return finalize();
					}

					// Get the token offset of the last } when it are assignment parameters.
					let closing_assignment_parameter_curly_offset = -1;
					if (is_assignment_parameters) {
						closing_assignment_parameter_curly_offset = parenth_tokens.iterate((token) => {
							if (token.data.length === 1 && token.data === "}") {
								return token.offset;
							}
						})
					}

					// ---------------------------------------------------------
					// Parse the paramaters.


					// The target type token to which the parameters will be assigned to.
					let type_token;

					// Get token before the opening parenth.
					const token_before_opening_parenth = this.get_prev_token(opening_parenth_token.index - 1, [" ", "\t", "\n"]);
					if (token_before_opening_parenth == null) {
						parenth_tokens.iterate_reversed((token) => { delete token.at_correct_depth; });
						return finalize();
					}

					// Do not continue when the token before the parent is a keyword, for statements like "if ()".
					// Since that will never be a type or type def so also do not highlight the params etc.
					// Except for certain keywords that are allowed in some languages.
					const is_keyword = token_before_opening_parenth.token === "keyword";
					if (is_keyword && this.allowed_keywords_before_type_defs.includes(token_before_opening_parenth.data) === false) {
						parenth_tokens.iterate_reversed((token) => { delete token.at_correct_depth; });
						return finalize();
					}

					// When the token before the opening parenth token already is a decorator, type or type_def there is no need to call on parenth close.
					// When type def keywords are used this is possible, and with decorators ofcourse.
					if (
						token_before_opening_parenth != null && 
						(
							token_before_opening_parenth.is_decorator === true ||
							(token_before_opening_parenth.token === "type" && this.language !== "C++") || // except for c++ since type_keywords such as constexpr combined with a constructor can make the constructor name a type, since the constructor does not have a type.
							token_before_opening_parenth.token === "type_def"
						)
					) {
						type_token = token_before_opening_parenth;
					}
					
					// Call the on parenth close.
					else if (this.on_parenth_close !== undefined) {
						type_token = this.on_parenth_close({
							token_before_opening_parenth: token_before_opening_parenth,
							after_parenth_index: after_parenth_index,
						})
					}

					// Set flags for type def tokens.
					if (type_token != null && type_token.token === "type_def") {

						// Enable the is post type def modifier flag.
						this.is_post_type_def_modifier = true;
						this.post_type_def_modifier_type_def_token = type_token;

						// Assign parents to the type token.
						// But only when the callback has not already assigned parents.
						if (type_token.parents === undefined && type_token.is_decorator !== true && (this.parents.length === 0 || this.parents[this.parents.length - 1][0] !== type_token)) {
							this.assign_parents(type_token)	;
						}

					}

					// Create the array with parameters and assign the token_param to the tokens.
					let mode = 1; // 1 for key 2 for value.
					const params = [];

					// Initialize a parameter object.
					const init_param = () => {
						return {
							name: null, 	// the parameter name.
							index: null, 	// the parameter index.
							value: [], 		// the default value tokens.
							type: [], 		// the type tokens.
						};
					}

					// Append a parameter object.
					const append_param = (param) => {
						if (param !== undefined) {
							param.type = this.trim_tokens(param.type);
							param.value = this.trim_tokens(param.value);
							param.index = params.length;
							if (param.name != null) {
								params.push(param);
							}
						};
					}

					// Check if the next parenth token is a assignment operator.
					// Returns `null` when the there is no next assignment operator directly after the provided index.
					const get_next_assignment_operator = (parenth_index) => {
						let next_i = parenth_index - 1, next;
						while ((next = parenth_tokens[next_i]) != null) {
							if (next.data.length === 1 && next.data === "=") {
								if (parenth_tokens[next_i - 1] != null && parenth_tokens[next_i - 1].token === "operator") {
									return null;
								}
								return next;
							} else if (next.data.length !== 1 || (next.data !== " " && next.data !== "\t" && next.data === "\n")) {
								return null;
							}
							--next_i;
						}
						return null;
					}

					// Iterate the parenth tokens.
					const is_type_def = type_token != null && type_token.token === "type_def";
					const is_decorator = type_token != null && type_token.is_decorator === true;

					let param;
					let is_type = true;
					let i = parenth_tokens.length;
					parenth_tokens.iterate_reversed((token) => {
						--i;
						const at_correct_depth = token.at_correct_depth;
						delete token.at_correct_depth;

						// Set key and value flags.
						if (at_correct_depth && token.is_word_boundary === true && token.data === ",") {
							append_param(param);
							param = init_param();
							mode = 1;
							is_type = true;
						}
						else if (at_correct_depth && token.is_word_boundary === true && token.data === "=") {
							mode = 2;
						}

						// When key.
						else if (mode === 1) {

							// Init param.
							if (param === undefined) {
								param = init_param();
							}

							// Skip tokens.
							if (
								at_correct_depth === false
							) {
								return null;
							}

							// Assign to parameter.
							if (is_type && (token.token === "keyword" || token.token === "type" || token.is_whitespace === true || token.token === "operator" || token.data.includes("."))) {
								param.type.push(token);
							} else {
								is_type = false;
								const allow_assignment = token.token === "type_def" || (token.token === undefined && token.data !== "{" && token.data !== "}" && token.data !== "(" && token.data !== ")" && token.data !== "[" && token.data !== "]");

								// On a type definition always assign to parameter.
								// Check for token undefined since decorators should still assign the param.value when it is not an assignment operator.
								// Also allow type def token null to assign params since this can be the case in annoumys js funcs like `iterate((item) => {})`;
								if ((is_type_def || (this.language === "JS" && type_token === null)) && allow_assignment) {
									if (token.is_whitespace === true || token.is_word_boundary === true) {
										return null; // skip inside here since word boundaries and whitespace are allowed inside decorator values.
									}
									param.name = token.data.trim();
									token.token = "parameter";
								}

								// When the token is a type there must be a "=" after this tokens.
								// Check for token undefined since decorators should still assign the param.value when it is not an assignment operator.
								else if (!is_type_def) {
									const next = get_next_assignment_operator(i);
									if (next !== null && allow_assignment) {
										if (token.is_whitespace === true || token.is_word_boundary === true) {
											return null; // skip inside here since word boundaries and whitespace are allowed inside decorator values.
										}
										param.name = token.data.trim();
										token.token = "parameter";
									}
									else if (next === null && is_decorator && closing_assignment_parameter_curly_offset !== token.offset) {
										param.value.push(token);
									}
								}
							}
						}

						// When value.
						else if (
							mode === 2 && 
							(is_type_def || is_decorator) && 
							closing_assignment_parameter_curly_offset !== token.offset
						) {
							param.value.push(token);
						}
					})

					// Add last param.
					append_param(param);

					// Assign params to the type def token.
					if (is_type_def || is_decorator) {
						type_token.parameters = params;
						if (is_assignment_parameters === true) {
							type_token.is_assignment_parameters = true;
						}
						type_token.parameter_tokens = []; // this must always be an array, even if it is empty and the first and last parentheses should not be added into this array, vdocs depends on this behaviour.
						parenth_tokens.iterate_reversed((token) => {
							type_token.parameter_tokens.push(token);
						})
					}
					
					// ---------------------------------------------------------
					// Append to batch.

					// Append word boundary to tokens.
					return finalize();
				}

				// Call the handler.
				// And append the character when not already appended by the handler.
				// Always use if so previous if statements can use a fallthrough.
				if (this.callback === undefined || this.callback(char, is_escaped, this.is_preprocessor) !== true) {

					// Is word boundary.
					// Append old batch and word boundary char.
					if (this.word_boundaries.includes(char)) {
						this.append_batch();
						this.batch += char;
						this.append_batch(null, {is_word_boundary: true}); // do not use "false" as parameter "token" since the word boundary may be an operator.
					}
					
					// Add to batch till a word boundary is reached.
					else {
						this.batch += char;
					}
				}
			}
			return null;
		});

		// Append last batch.
		auto_append_batch_switch();

		// When the last line has no content then append an enmpty line token array since there actually is a line there.
		// But only when no stop callback has been defined.
		const last_line = this.tokens[this.tokens.length - 1];
		if (
			is_insert_tokens === false &&
			stop_callback == null &&
			(last_line === undefined || (last_line.length > 0 && last_line[last_line.length - 1].is_line_break))
		) {
			this.tokens.push([]);
		}

		// console.log(`append_token time: ${this.append_token_time}ms.`);
		// console.log(`get_prev_token time: ${this.get_prev_token_time}ms.`);

		// Build html.
		if (build_html) {
			return this.build_html();
		}

		// Return tokens.
		else  {
			return this.tokens;
		}
	}

	// Partial tokenize.
	/*	@docs: {
		@title Partial tokenize
		@description: Partially tokenize text based on edited lines.
		@warning: the `parents`, `pre_modifiers`, `post_modifiers`, `templates` and `requires` attributes on the type def tokens will not be correct when using `partial_tokenize()`.
		@parameter: {
			@name: code
			@type: string
			@description: The new code data.
		}
		@parameter: {
			@name: edits_start
			@type: string
			@description: The start line from where the edits took place.
		}
		@parameter: {
			@name: edits_end
			@type: string
			@description: The end line till where the edits took place.
		}
		@parameter: {
			@name: line_additions.
			@type: string
			@description: The number of line additions (positive) or the number of line deletions (negative).
		}
		@parameter: {
			@name: tokens
			@type: array[object]
			@description: The old tokens.
		}
	} */
	partial_tokenize({
		code = null,
		edits_start = null,
		edits_end = null,
		line_additions = 0,
		tokens = [],
		build_html = false,
	}) {

		// Assign code when not assigned.
		// So the user can also assign it to the tokenizer without cause two copies.
		if (code !== null) {
			this.code = code;
		}

		// Reset.
		this.reset();

		// Derived reset.
		if (this.derived_reset !== undefined) {
			this.derived_reset();
		}

		// Args.
		if (line_additions === undefined || isNaN(line_additions)) {
			line_additions = 0;
		}

		// Vars.
		let scope_start = 0; 		// the line where the scope around the new edits starts.
		let scope_start_offset = 0; // the index offset of the scope start from the new code.
		let scope_end = null; 		// the line where the scope around the new edits ends.
		let scope_end_offset = 0;   // the index offset of the scope end from the new code.
		let now;

		// ---------------------------------------------------------
		// Find the scope start.
		// now = Date.now();

		// console.log("code:",this.code);
		// console.log("edits_start:",edits_start);
		// console.log("edits_end:",edits_end);

		// Iterate backwards to find the scope start line.
		// Do not stop if another string, comment, regex or preprocessor has just ended on the line that the start scope has been detected.
		// Start one line before the edits_start since a "{" or "}" may already be on that line which can cause issues when editing a func def.
		if (edits_start != 0) {

			// Find start scope by type def tokens.
			if (this.seperate_scope_by_type_def === true) {
				let parenth_depth = 0, bracket_depth = 0;
				tokens.iterate_reversed(0, edits_start, (line_tokens) => {

					// Skip on empty line tokens.
					if (line_tokens.length === 0) {
						return null;
					}

					// Vars.
					let found_separator = null;

					// Check if the line contains a scope separator.
					line_tokens.iterate_reversed((token) => {

						// Depths.
						if (token.token === undefined && token.data === "(") {
							--parenth_depth;
						}
						else if (token.token === undefined && token.data === ")") {
							++parenth_depth;
						}
						else if (token.token === undefined && token.data === "[") {
							--bracket_depth;
						}
						else if (token.token === undefined && token.data === "]") {
							++bracket_depth;
						}

						// Found type def at zero depth.
						else if (token.token === "type_def" && depth === 0) {
							found_separator = token.line;
							return true;
						}
					})

					// Do not stop when the first token is a comment, string etc because it may resume on the next line.
					const first_token = line_tokens[0];
					if (
						found_separator !== null &&
						first_token.token !== "comment" &&
						first_token.token !== "string" &&
						first_token.token !== "token_regex" &&
						first_token.token !== "preprocessor"
					) {
						scope_start = first_token.line;
						scope_start_offset = first_token.offset;
						return true;
					}
				})
			}

			// Find start scope by scope seperators.
			else {
				let use_curly = false;
				let curly_depth = 0;
				const scope_separators = [];
				this.scope_separators.iterate((item) => {
					if (item == "{" && item == "}") { use_curly = true; }
					else { scope_separators.push(item); }
				})
				tokens.iterate_reversed(0, edits_start, (line_tokens) => {

					// Skip on empty line tokens.
					if (line_tokens.length === 0) {
						return null;
					}

					// Vars.
					let found_separator = null;

					// Check if the line contains a scope separator.
					line_tokens.iterate_reversed((token) => {

						// Opening curly.
						if (use_curly && token.token === undefined && token.data === "{") {
							if (curly_depth === 0) {
								found_separator = token.line;
								return true;
							}
							--curly_depth;
						}

						// Closing curly.
						else if (use_curly && token.token === undefined && token.data === "}") {
							++curly_depth;
						}

						// Any other scope seperators.
						else if (
							(token.token === undefined || token.token === "operator") &&
							token.data.length === 1 &&
							this.scope_separators.includes(token.data)
						) {
							found_separator = token.line;
							return true;
						}
					})

					// Do not stop when the first token is a comment, string etc because it may resume on the next line.
					const first_token = line_tokens[0];
					if (
						found_separator !== null &&
						first_token.token !== "comment" &&
						first_token.token !== "string" &&
						first_token.token !== "token_regex" &&
						first_token.token !== "preprocessor"
					) {
						scope_start = first_token.line;
						scope_start_offset = first_token.offset;
						// console.log(scope_start);
						return true;
					}
				})
			}
		}
		
		// console.log("scope_start_offset:",scope_start_offset);
		// console.log("scope_start:",scope_start);
		// console.log("Find the scope start:", Date.now() - now, "ms.");

		// ---------------------------------------------------------
		// Start the tokenizer with a stop callback
		// now = Date.now();

		// Chech if the line tokens of two lines match for the stop callback.
		const match_lines = (x, y) => {
			if (x.length !== y.length) {
				return false;
			}
			if (x.length <= 1) { // prevent line break lines.
				return false;
			}
			for (let i = 0; i < x.length; i++) {
				const x_token = x[i];
				const y_token = y[i];
				if (
					x_token.token !== y_token.token ||
					x_token.data !== y_token.data 
				) {
					return false;
				}
			}
			return true;
		}

		// The stop callback to check if the just tokenized line is the same as the original line.
		// This works correctly when first typing an unfinished string etc and then later terminating it.
		// Also resume when the original line tokens at the adjusted line does not exist since then multiple new lines have been added.
		let insert_start_line = scope_start;
		let insert_end_line = null;
		let curly_depth = 0, bracket_depth = 0, parenth_depth = 0;
		const stop_callback = (line, line_tokens) => {

			// The bracket, curly and parentheses depth must all be zero to capture the full scope.
			line_tokens.iterate((token) => {
				if (token.token === undefined && token.data.length === 1) {
					if (token.data === "{") { ++curly_depth; }
					else if (token.data === "}") { --curly_depth; }
					else if (token.data === "(") { ++parenth_depth; }
					else if (token.data === ")") { --parenth_depth; }
					else if (token.data === "[") { ++bracket_depth; }
					else if (token.data === "]") { --bracket_depth; }
				}
			})

			// Stop when not all depths are zero.
			if (curly_depth !== 0 || bracket_depth !== 0 || parenth_depth !== 0) {
				return false;
			}

			// Check if the lines match.
			line += scope_start;
			const adjusted_line = line - line_additions;
			if (line > edits_end && tokens[adjusted_line] !== undefined && match_lines(tokens[adjusted_line], line_tokens)) {
				insert_end_line = adjusted_line;
				return true;
			}
			return false;
		};

		// Tokenize.
		this.code = this.code.substr(scope_start_offset, this.code.length - scope_start_offset);
		const insert_tokens = this.tokenize({stop_callback: stop_callback});

		// console.log("SCOPE:", this.code);
		// console.log("Tokenized lines:",insert_tokens.length);
		// console.log("insert_tokens:",insert_tokens)
		// console.log("Highlight the edits:", Date.now() - now, "ms.");

		// ---------------------------------------------------------
		// Insert tokens
		// now = Date.now();

		// console.log("insert_start_line:",insert_start_line);
		// console.log("insert_end_line:",insert_end_line);
		// console.log("line_additions:",line_additions);

		// Initialize combined tokens.
		let combined_tokens = new vhighlight.Tokens();

		// Insert tokens into the current tokens from start line till end line.
		// So the new tokens will old start till end lines will be removed and the new tokens will be inserted in its place.
		// The start line will be removed, and the end line will be removed as well.
		let insert = true;
		let line_count = 0, token_index = 0, offset = 0;;
		for (let line = 0; line < tokens.length; line++) {
			if (insert && line == insert_start_line) {
				insert = false;
				insert_tokens.iterate((line_tokens) => {
					line_tokens.iterate((token) => {
						token.line = line_count;
						token.index = token_index;
						token.offset = offset;
						offset += token.data.length;
						++token_index;
					});
					++line_count;
					combined_tokens.push(line_tokens);
				})
			}
			else if (line < insert_start_line || (insert_end_line !== null && line > insert_end_line)) {
				const line_tokens = tokens[line];
				line_tokens.iterate((token) => {
					token.line = line_count;
					token.index = token_index;
					token.offset = offset;
					offset += token.data.length;
					++token_index;
				});
				++line_count;
				combined_tokens.push(line_tokens);
			}
		}
		
		// When the last line has no content then append an enmpty line token array since there actually is a line there.
		const last_line = combined_tokens[combined_tokens.length - 1];
		if (last_line === undefined || (last_line.length > 0 && last_line[last_line.length - 1].is_line_break)) {
			combined_tokens.push([]);
		}

		// console.log("line_count:",line_count);
		// console.log("combined_tokens:",combined_tokens);
		// console.log("Combine the tokens:", Date.now() - now, "ms.");

		// Assign to tokens.
		this.tokens = combined_tokens;

		// Build html.
		if (build_html) {
			return this.build_html();
		}

		// Return tokens.
		else  {
			return this.tokens;
		}
	}

	// Build the html from tokens.
	build_html({
		tokens = null, 
		token_prefix = "token_", 
		reformat = true, 
		lt = "<", 
		gt = ">",
		trim = false, // remove whitespace including newlines at the start and end.
	} = {}) {

		// Vars.
		if (tokens == null) {
			tokens = this.tokens;
		}
		let html = "";

		// Build a token's html.
		const build_token = (token) => {
			if (token.token === undefined) {
				if (reformat) {
					html += token.data.replaceAll("<", "&lt;").replaceAll(">", "&gt;");
				} else {
					html += token.data;
				}
			} else {
				let class_ = "";
				if (token.token !== undefined) {
					class_ = `class="${token_prefix}${token.token}"`;
				}
				if (reformat) {
					html += `${lt}span ${class_}${gt}${token.data.replaceAll("<", "&lt;").replaceAll(">", "&gt;")}${lt}/span${gt}`
				} else {
					html += `${lt}span ${class_}${gt}${token.data}${lt}/span${gt}`
				}
			}
		}

		// Build tokens.
		const build_tokens = (tokens) => {
			let start = true;
			let end = null;
			if (trim) {
				for (let i = tokens.length - 1; i >= 0; i++) {
					const token = tokens[i];
					if (token.is_whitespace === true || token.is_line_break === true) {
						end = i;
					} else {
						break;
					}
				}
			}
			tokens.iterate(0, end, (token) => {
				if (trim) {
					if (start && (token.is_whitespace === true || token.is_line_break === true)) {
						return null;
					}
					start = false;
				}
				build_token(token);
			});
		}
		
		// Iterate an array with token objects.
		// console.log("TOKENS:", tokens);
		if (tokens.length > 0) {
			let start = true;
			if (Array.isArray(tokens[0])) {
				tokens.iterate(build_tokens);
			} else {
				build_tokens(tokens);
			}
		}
		
		// Handler.
		return html;
	}
}// ---------------------------------------------------------
// Bash highlighter.

vhighlight.Bash = class Bash extends vhighlight.Tokenizer {
	constructor() {

		// Initialize the tokenizer.
		super({
			keywords: [
				"if",
				"then",
				"else",
				"elif",
				"fi",
				"case",
				"esac",
				"while",
				"do",
				"done",
				"for",
				"select",
				"until",
				"function",
				"in",
				"return",
				"continue",
				"break",
				// "shift",
				// "eval",
				// "exec",
				// "set",
				// "unset",
				"readonly",
				"declare",
				"local",
				// "export",
				"typeset",
				// "trap",
				"true",
				"false",
				// "test",
			],
			type_def_keywords: [
				"function",
			], 
			operators: [
				'+', '-', '*', '/', '%', 					// arithmetic operators.
				'=', '!=',             						// string operators.
				'!', '-o', '-a',       						// logical operators.
				'-eq', '-ne', '-lt', '-le', '-gt', '-ge', 	// comparison operators.
				'-e', '-f', '-d', '-s', '-r', '-w', '-x', 	// file test operators.
				'&', '|', '^', '~', '<<', '>>',				// bitwise operators.
				// '$', // dont add $ since it will be catched by the callback.
			],
			single_line_comment_start: "#",

			// Attributes for partial tokenizing.
			scope_separators: [
				"{", 
				"}", 
			],

			// Language, must never be changed it is used by dependents, such as vdocs.
			language: "Bash",
		});

		// Set callback.
		this.callback = (char, is_escaped) => {
			
			// Is whitespace.
			const is_whitespace = this.is_whitespace(char);

			// Start of line excluding whitespace.
			let start_of_line = false;
			if (this.current_line != this.line && !is_whitespace) {
				start_of_line = true;
				this.current_line = this.line;
			}

			// Special operators preceded by a "-" such as "-eq".
			// if (char == "-") {
			// 	let batch = null;
			// 	if (this.operators.includes(char + this.next_char)) {
			// 		batch = char + this.next_char;
			// 	} else if (this.operators.includes(char + this.next_char + this.code.charAt(this.index + 2))) {
			// 		batch = char + this.next_char + this.code.charAt(this.index + 2);
			// 	}
			// 	if (batch != null) {
			// 		this.append_batch();
			// 		this.append_forward_lookup_batch("operator", batch);
			// 		this.resume_on_index(this.index + batch.length - 1);
			// 		return true;
			// 	}
			// }

			// Arguments starting with a "-" or "--".
			if (char == "-" && this.prev_char !== "-") {

				// Get the next whitespace.
				const next_whitespace = this.get_first_whitespace(this.index, true, this.code.length);

				// Get the full argument.
				const arg = this.code.substr(this.index, next_whitespace - this.index);

				// Append arg.
				this.append_batch();
				this.append_forward_lookup_batch("parameter", arg);
				this.resume_on_index(this.index + arg.length - 1);
				return true;
			}

			// Special keywords preceded by a "$" such as "$1".
			else if (char == "$" && (this.is_numerical(this.next_char) || this.next_char === "@" || this.next_char === "#" || this.next_char === "?")) {
				let batch = "$";
				let index = this.index + 1;
				while (true) {
					const c = this.code.charAt(index);
					if (c === "@" || c === "#" || c === "?" || this.is_numerical(c)) {
						batch += c;
					} else {
						break;
					}
					++index;
				}
				if (batch.length > 1) {
					this.append_batch();
					this.append_forward_lookup_batch("keyword", batch);
					this.resume_on_index(this.index + batch.length - 1);
					return true;
				}
			}

			// Function / command call.
			else if (start_of_line && char === "$" && (this.next_char === " " || this.next_char === "\t" || this.next_char === "\n")) {

				// Append.
				this.append_batch();
				this.batch += char;
				this.append_batch("keyword");

				// Reset the current line when the char is only $ so the next item will also be highlighted as the first command.
				this.current_line = null;

				// Catched.
				return true;
			}
			else if (start_of_line && (this.is_alphabetical(char))) {
				
				// Do a forward lookup for a "AAA A" pattern, two consecutive words with only whitespace in between.
				let finished = false;
				let passed_whitespace = false;
				let word = "";
				let end_index = null;
				for (let i = this.index; i < this.code.length; i++) {
					const c = this.code.charAt(i);
					if (c == " " || c == "\t") {
						passed_whitespace = true;
					} else if (!passed_whitespace && (this.is_alphabetical(c) || this.is_numerical(c))) {
						word += c;
						end_index = i;
					} else if (passed_whitespace && (char == "\\" || !this.operators.includes(char))) {
						finished = true;
						break;
					} else {
						break;
					}
				}
				if (finished && !this.keywords.includes(word)) {
					this.append_batch();
					this.append_forward_lookup_batch("type", word);
					this.resume_on_index(end_index);
					return true;
				}
			}

			// Multi line comments.
			else if (start_of_line && char == ":") {

				// Do a forward lookup to determine the style.
				let style = null;
				let start_index = null; // the start after the ": <<" or the start after the ": '"
				let end_index = null;
				for (let i = this.index + 1; i < this.code.length; i++) {
					const c = this.code.charAt(i);
					if (c == " " || c == "\t") {
						continue;
					} else if (c == "<") {
						if (this.code.charAt(i + 1) == "<") {
							start_index = i + 2;
							style = 1;
						}
						break;
					} else if (c == "'" || c == '"') {
						start_index = i + 1;
						style = 2;
					} else {
						break;
					}
				}

				// Style 1, ": << X ... X" or ": << 'X' ... X" or ": << "X" ... X".
				if (style == 1) {

					// Vars.
					let close_sequence = "";
					let found_close_sequence = false;

					// Eq first.
					const eq_first = (start_index) => {
						if (start_index + close_sequence.length > this.code.length) {
					        return false;
					    }
					    const end = start_index + close_sequence.length;
					    let y = 0;
					    for (let x = start_index; x < end; x++) {
					        if (this.code.charAt(x) != close_sequence.charAt(y)) {
					            return false;
					        }
					        ++y;
					    }
					    return true;
					}

					// Get the closing sequence.
					for (let i = start_index; i < this.code.length; i++) {
						const c = this.code.charAt(i);
						if (!found_close_sequence) {
							if (this.is_whitespace(c)) {
								continue;
							} else if (
								c == '"' || 
								c == "'" || 
								c == "_" || 
								c == "-" || 
								this.is_numerical(c) || 
								this.is_alphabetical(c)
							) {
								close_sequence += c;
							} else {
								found_close_sequence = true;
								if (close_sequence != '"' && close_sequence != '""' && close_sequence != "'" && close_sequence != "''") {
									const start_char = close_sequence.charAt(0);
									if (start_char == "'" || start_char == '"') {
										close_sequence = close_sequence.substr(1);
									}
									const end_char = close_sequence.charAt(close_sequence.length - 1);
									if (end_char == "'" || end_char == '"') {
										close_sequence = close_sequence.substr(0, close_sequence.length - 1);
									}
								}
							}
						} else {
							if (eq_first(i)) {
								end_index = i + close_sequence.length - 1;
								break;
							}
						}
					}
				}


				// Style 2, ": ' ' " or ': " " '.
				else if (style == 2) {
					const closing_char = this.code.charAt(start_index - 1);
					for (let i = start_index; i < this.code.length; i++) {
						const c = this.code.charAt(i);
						if (!is_escaped && c == closing_char) {
							end_index = i;
							break;
						}
					}
				}

				// Append tokens.
				if (end_index != null) {
					this.append_batch();
					this.append_forward_lookup_batch("comment", this.code.substr(this.index, end_index - this.index + 1));
					this.resume_on_index(end_index);
					return true;
				}
			}

			// Nothing done.
			return false;
		}

		// Set on parenth close.
		this.on_parenth_close = ({
			token_before_opening_parenth = token_before_opening_parenth,
			after_parenth_index = after_parenth_index,
		}) => {
			if (after_parenth_index != null && this.code.charAt(after_parenth_index) === "{") {
				token_before_opening_parenth.token = "type_def";
				return token_before_opening_parenth;
			}
		}
	}

	// Reset attributes that should be reset before each tokenize.
	derived_reset() {
		this.current_line = null; // curent line to detect start of the line.
	}
}

// Initialize.
vhighlight.bash = new vhighlight.Bash();// ---------------------------------------------------------
// C++ highlighter.

vhighlight.CPP = class CPP extends vhighlight.Tokenizer {
	constructor({
		allow_header_type_defs = true, // allow header type definitions like `void myfunc();` to be highlighted as a type def, when disabled it will not be highlighted, therefore is is a variable name of a constuctor initialization with parentheses.
	} = {}) {

		// Initialize the tokenizer.
		super({
			keywords: [
				"alignas",
				"alignof",
				"and",
				"and_eq",
				"asm",
				"atomic_cancel",
				"atomic_commit",
				"atomic_noexcept",
				"auto",
				"bitand",
				"bitor",
				"bool",
				"break",
				"case",
				"catch",
				"char",
				"char8_t",
				"char16_t",
				"char32_t",
				"class",
				"compl",
				"concept",
				"const",
				"consteval",
				"constexpr",
				"constinit",
				"const_cast",
				"continue",
				"co_await",
				"co_return",
				"co_yield",
				"decltype",
				"default",
				"delete",
				"do",
				"double",
				"dynamic_cast",
				"else",
				"enum",
				"explicit",
				"export",
				"extern",
				"false",
				"float",
				"for",
				"friend",
				"goto",
				"if",
				"inline",
				"int",
				"long",
				"mutable",
				"namespace",
				"new",
				"noexcept",
				"not",
				"not_eq",
				"nullptr",
				"operator",
				"or",
				"or_eq",
				"private",
				"protected",
				"public",
				"reflexpr",
				"register",
				"reinterpret_cast",
				"requires",
				"return",
				"short",
				"signed",
				"sizeof",
				"static",
				"static_assert",
				"static_cast",
				"struct",
				"switch",
				"synchronized",
				"template",
				"this",
				"thread_local",
				"throw",
				"true",
				"try",
				"typedef",
				"typeid",
				"typename",
				"union",
				"unsigned",
				"using",
				"virtual",
				"void",
				"volatile",
				"wchar_t",
				"while",
				"xor",
				"xor_eq",
			],
			type_def_keywords: [
				"namespace",
				"struct",
				"class",
				"enum",
				"union",
			],
			exclude_type_def_keywords_on_prev: [
				"using",
			],
			allowed_keywords_before_type_defs: [
				"operator", // since the operator keyword before a func like `operator []()` will be made a type def token, vdocs also depends on this.
			],
			type_keywords: [
				"const",
				"constexpr",
				"static",
				"volatile",
				"mutable",
				"namespace", // for the exclude_type_def_keywords_on_prev so that the using namespace xxx will make xxx as a type. 
			],
			operators: [
				"&&", "||", "!", "==", "!=", ">", "<", ">=", "<=", "+", "-", "*", "/", "%",
				"=", "+=", "-=", "*=", "/=", "%=", "++", "--", "<<", ">>", "&", "|", "^", "~",
				"?",
			],
			special_string_prefixes: [
				"L",
				"u",
				"U",
				"R",
				"u8",
			],
			single_line_comment_start: "//",
			multi_line_comment_start: "/*",
			multi_line_comment_end: "*/",
			allow_preprocessors: true,
			excluded_word_boundary_joinings: ["."],
			is_type_language: true,

			// Attributes for partial tokenizing.
			scope_separators: [
				"{", 
				"}", 
			],
			seperate_scope_by_type_def: true,

			// Language, must never be changed it is used by dependents, such as vdocs.
			language: "C++",
		});

		// Parameters.
		this.allow_header_type_defs = allow_header_type_defs;

		// ---------------------------------------------------------
		// On default callback.

		this.callback = (char) => {
			
			// Close is func.
			if (
				this.inside_func && 
				char === "}" && // since the opening curly can be encoutered before assinging `this.inside_func_closing_curly`.
				this.curly_depth <= this.inside_func_closing_curly
				// this.index > this.inside_func_closing_curly
			) {
				this.inside_func = false;
			}

			// Detect types by the first x words on the line preceded by whitespace and another alphabetical character.
			// Must be first since other if statements in this func check if the token before x is not a type.
			if (
				(this.last_line_type != this.line && char != " " && char != "\t") || // types are allowed at the start of the line.
				(this.is_keyword_before_parentheses !== true && this.prev_char == "(" || (this.parenth_depth > 0 && this.prev_char == ",")) // types are allowed inside parentheses.
			) {
				this.last_line_type = this.line;

				// Append the batch because of the lookup.
				this.append_batch();

				// Do a lookup to check if there are two consecutive words without any word boundaries except for whitespace.
				let is_type = false;
				let hit_template = 0;
				let word = "";
				let words = 0;
				let append_to_batch = [];
				let last_index, last_append_index;
				for (let index = this.index; index < this.code.length; index++) {
					const c = this.code.charAt(index);

					// Hit template, treat different.
					// Iterate till end of template and then check if there is only whitespace and then a char.
					if (hit_template == 2) {

						// Allowed chars.
						if (c == " " || c == "\t" || c == "*" || c == "&" || c == "\n") {
							continue;
						}

						// Stop at first word char.
						else if (this.is_alphabetical(c)) {
							if (words == 1) {
								is_type = true;
								break;
							}
							break;
						}

						// Non allowed chars.
						else {
							break;
						}
					}
					else if (hit_template == 1) {
						if (c == ">") {
							hit_template = 2;
						}
					}

					// Did not hit any template.
					else {

						// Allowed separator characters.
						if (c == " " || c == "\t" || c == ":" || c == "*" || c == "&" || (words == 0 && c == "<")) {
							if (c == "<") {
								hit_template = 1;
							}
							if (word.length > 0) {
								if (this.keywords.includes(word)) { // do not increment words on a keyword.
									// Stop when a type def keyword was encoutered.
									if (this.type_def_keywords.includes(word)) {
										return false;
									}
									append_to_batch.push(["keyword", word]);
								} else {
									if (c != ":" || this.code.charAt(index + 1) != ":") { // do not increment on colons like "vlib::String" since they should count as one word.
										++words;
									}
									append_to_batch.push(["type", word]);
								}
								last_index = index;
								last_append_index = append_to_batch.length - 1;
								word = "";
							}
							if (c == "*" || c == "&") {
								append_to_batch.push(["operator", c]);
							} else {
								append_to_batch.push([null, c]); // @todo changed jerre [false, c] to [null, c] still have to check but it should still highlight numerics in append_token called by append_forward_lookup_token
							}
						}

						// Allowed word chars.
						else if (this.is_alphabetical(c) || (word.length > 0 && this.is_numerical(c))) {
							if (words == 1) {
								is_type = true;
								break;
							}
							word += c;
						}

						// Non allowed chars.
						else {
							break;
						}
					}
				}

				// Add the batches when it is a type.
				if (is_type) {
					for (let i = 0; i <= last_append_index; i++) {
						this.append_forward_lookup_batch(append_to_batch[i][0], append_to_batch[i][1]);
					}
					this.resume_on_index(last_index - 1);
					return true;
				}

			}

			// Braced initialiatons, depends on a ">" from a template on not being an operator.
			else if (char == "{") {

				// Append current batch by word boundary separator.
				this.append_batch();

				// Edit the previous token when the token is not already assigned and when the data is not "(" for a func or "if", and skip operators etc.
				// Skip where the token before the previous is already type for example "String x {}".
				// Also skip the tokens between < and > when the initial prev and the prev prev token is a ">".
				let prev = this.get_prev_token(this.added_tokens - 1, [" ", "\t", "\n", "&", "*"]);
				if (prev == null) { return false; }
				let prev_prev = this.get_prev_token(prev.index - 1, [" ", "\t", "\n", "*", "&"]);
				if (prev.data === ">" && (prev_prev == null || prev_prev.data !== "-")) {
					const token = this.get_opening_template(prev.index);
					if (token != null) {
						prev = this.get_prev_token(token.index - 1, []);
					}
				}
				prev_prev = this.get_prev_token(prev.index - 1, [" ", "\t", "\n", "&", "*"]);
				if (prev_prev != null && prev_prev.data == ">") {
					let prev_prev_prev = this.get_prev_token(prev.index - 1, [" ", "\t", "\n", "*", "&"]);
					if (prev_prev == null || prev_prev.data !== "-") {
						const token = this.get_opening_template(prev_prev.index);
						if (token != null) {
							prev_prev = this.get_prev_token(token.index - 1, []);
						}
					}
				}
				if (
					(prev_prev == null || prev_prev.token != "type") && 
					prev.token === undefined && prev.is_word_boundary !== true
				) {
					prev.token = "type";
				}
			}

			// Types inside templates not only the keyword template but also for type or function templates.
			else if (char == "<") {

				// Append the batch because of the lookup.
				this.append_batch();

				// Do a forward lookup till the closing >, if there are any unallowed characters stop the lookup.
				// Since lines like "x < y;" are allowed, so not everything is a template.
				let is_template = false;
				let depth = 1;
				let parenth_depth = 0;
				let word = "";
				let append_to_batch = [[false, char]];
				let index;
				let next_is_type = true;
				let c;
				const add_word = (is_word_boundary = false, set_seperator = false) => {
					if (word.length > 0) {
						if (word === "typename") {
							append_to_batch.push(["keyword", word]);
							next_is_type = true;
						}
						else if (this.keywords.includes(word)) {
							append_to_batch.push(["keyword", word]);
						}
						else if (next_is_type) {
							append_to_batch.push(["type", word]);
							next_is_type = false;
						}
						else {
							append_to_batch.push([false, word]);
						}
						word = "";
						if (set_seperator) {
							// if (c == " ") {
							// 	next_is_type = false;
							// } else
							if (c == ",") {
								next_is_type = true;
							} else if (c == "(") {
								next_is_type = true;
							}
						}
					}
				}
				for (index = this.index + 1; index < this.code.length; index++) {
					c = this.code.charAt(index);

					// Closing template.
					if (c == "<") {
						next_is_type = true;
						add_word();
						append_to_batch.push([false, c]);
						++depth;
					} else if (c == ">") {
						next_is_type = true;
						add_word();
						append_to_batch.push([false, c]);
						--depth;
						if (depth == 0) {
							is_template = true;
							break;
						}
					}

					// Allowed separator characters.
					else if (c === "(") {
						++parenth_depth;
						next_is_type = true;
						add_word(true);
						append_to_batch.push([false, c]);
					}
					else if (c === ")") {
						if (parenth_depth === 0) {
							break; // stop, there must be an opening parenth first otherwise it can also be an if statement like "if(... < ...)"
						}
						--parenth_depth;
						next_is_type = true;
						add_word(true);
						append_to_batch.push([false, c]);
					}
					else if (c === "{" || c === "}") {
						if (parenth_depth === 0) {
							break; // stop, there must be an opening parenth first otherwise it can also be an if statement like "auto& operator <() {"
						}
						add_word(true);
						append_to_batch.push([false, c]);
					}
					else if (c === "=") {
						add_word(true);
						append_to_batch.push(["operator", c]);
						next_is_type = true;
					}
					else if (this.operators.includes(c)) {
						add_word(true);
						append_to_batch.push(["operator", c]);
					}

					// Allowed colon word boundary and on double colon next is type.
					else if (c === ":") {
						add_word(true);
						append_to_batch.push([false, c]);
						if (this.code.charAt(index - 1) === ":") {
							next_is_type = true;
						}
					}

					// Allowed word boundaries.
					else if (this.is_whitespace(c) || c == "," || c == ":" || c == "\n" || c == "[" || c == "]" || c == "_") {
						add_word(true);
						append_to_batch.push([false, c]);
					}

					// Allowed alpha and numeric
					else if (this.is_alphabetical(c) || this.is_numerical(c)) {
						word += c;
					}

					// Non allowed characters.
					else {
						break;
					}
				}

				// Add the batches when it is a template.
				if (is_template) {
					for (let i = 0; i < append_to_batch.length; i++) {
						this.append_forward_lookup_batch(append_to_batch[i][0], append_to_batch[i][1], {is_template: true});
					}
					this.resume_on_index(index);
					return true;
				}
			}

			// Double colon.
			else if (char == ":" && this.prev_char == ":") {

				// Append batch by separator.
				this.append_batch();

				// Append to new batch.
				this.batch += char;
				this.append_batch(false);

				// Set next token.
				this.next_token = "type";

				// Set prev token.
				// Skip the tokens between < and > when the initial prev token is a ">".
				let prev = this.get_prev_token(this.added_tokens - 1, ["::"]);
				if (prev == null) {
					return true;
				}
				let prev_prev = this.get_prev_token(prev.index - 1, [" ", "\t", "\n", "*", "&"]);
				if (prev.data === ">" && (prev_prev == null || prev_prev.data !== "-")) {
					prev = this.get_opening_template(prev.index);
					if (prev !== null) {
						prev = this.get_prev_token(prev.index - 1, [])
					}
				}
				if (prev == null) {
					return true;
				}
				if (
					(prev.token === undefined || prev.token == "type_def") && // when token is null or prev token from like "using namespace a::b::c;"
					!this.str_includes_word_boundary(prev.data)
				) {
					prev.token = "type";
				}
				return true;
			}

			// Set the inherited classes when the flag is enabled.
			else if (char === "{" && this.capture_inherit_start_token !== undefined) {

				// Append current batch by word boundary separator.
				this.append_batch();

				// Vars.
				const start_token = this.capture_inherit_start_token;
				let success = false;
				let inherited_types = [];
				let inherit_privacy_type = null;
				let post_colon = false;

				// Iterate backwards till the extends token is found, capture the types found in between.
				this.tokens.iterate_tokens(start_token.line, null, (token) => {
					if (token.index > start_token.index) {
						if (post_colon) {
							if (token.token === "keyword") {
								inherit_privacy_type = token.data;
							} else if (inherit_privacy_type != null) {
								if (token.is_whitespace) {
									return null;
								}
								else if (token.is_word_boundary) {
									inherit_privacy_type = null;
								} else {
									token.token = "type";
									inherited_types.push({
										type: inherit_privacy_type,
										token: token,
									})
								}
							}
						}
						else if (token.token === undefined && token.data === ":") {
							post_colon = true;
						}
					}
				})

				// Assign the inherited types to the token.
				if (inherited_types.length > 0) {
					start_token.inherited = inherited_types;
				}

				// Reset the inherited class check flag.
				this.capture_inherit_start_token = undefined;
			}

			// Not appended.
			return false;
		}

		// ---------------------------------------------------------
		// Parsing type definitions, functions, function modifiers, function requires clause, function templates clause and function types.

		// Function modifiers.
		this.all_function_modifiers = ["static", "virtual", "volatile", "inline", "friend", "extern", "explicit", "noexcept", "const", "constexpr", "mutable", "decltype", "override", "final", "requires", "template"];
		this.post_function_modifiers = ["static", "virtual", "volatile", "inline", "friend", "extern", "explicit", "noexcept", "const", "constexpr", "mutable", "decltype", "override", "final", "requires", "template"];
		this.pre_function_modifiers = ["static", "virtual", "volatile", "inline", "friend", "extern", "explicit", "noexcept", "constexpr", "mutable", "decltype", "override", "final", "requires", "template"];

		// Check if a character matches the first char of one of the function modifiers.
		const first_char_matches_function_modifier = (char) => {
			for (let i = 0; i < this.all_function_modifiers.length; i++) {
				if (this.all_function_modifiers[i].charAt(0) === char) {
					return true;
				}
			}
			return false;
		}

		// Parse the pre modifiers, requires clause, template clause and the function type on a type def token match from inside the `on_parent_close()` callback.
		const parse_pre_type_def_modifiers = (first_type_def_token, type_def_token, type_defs_from_colon = []) => {

			// Vars.
			let type_tokens = []; 							// function's type tokens.
			let templates_tokens = [];						// function's template clause tokens.
			let requires_tokens = []; 						// function's requires clause tokens.
			let modifier_tokens = [];						// the modifier tokens.
			let first_type_keyword = true;					// the first keyword is still a type when the post_type flag is false.
			let post_type = false;							// tokens in the iteration are before the type tokens.
			let is_template = false;						// if the previous post type token was a (inside) template.
			let parenth_depth = 0;	 						// parenth depth when the post_type flag is true.
			let check_reset_requires_tokens = false;		// check a reset of the requires tokens on the next token.
			let on_lower_than_index = first_type_def_token.index; // only check tokens with a lower index than this index.
			let lookback_requires_tokens = [];				// the lookback potential requires clause token for `check_end_of_modifiers()`.
			let template_closed = false;					// flag for when the templates are already parsed and closed.
			let requires_closed = false;					// flag for when the requires clause is already parsed and closed.

			// Check the end of modiers.
			// However since the requires clause is not required to be in parentheses there must be a lookback ...
			// For either the keyword "requires" to resume the iteration, or a iteration termination by an unallowed word boundary.
			const check_end_of_modifiers = (token) => {

				// Requires tokens are already defined so always stop.
				if (requires_tokens.length > 0) {
					return false; // STOP ITERATION.
				}

				// Do a lookback.
				let ends_with_requires = false;
				let lookback_parenth_depth = 0;
				let lookback_curly_depth = 0;
				this.tokens.iterate_tokens_reversed(0, token.line + 1, (lookback) => {
					if (lookback.index <= token.index) {

						// Set depths.
						if (lookback.token === undefined && lookback.data.length === 1) {
							if (lookback.data === "{") { 
								--lookback_curly_depth;
								if (lookback_curly_depth === 0) {
									lookback_requires_tokens.push(lookback);
									return null; // prevent fallthrough since this token is also a word boundary which would terminate the loop otherwise.
								}
							}
							else if (lookback.data === "}") { ++lookback_curly_depth; }
							else if (lookback.data === "(") { 
								--lookback_parenth_depth;
								if (lookback_parenth_depth === 0) {
									lookback_requires_tokens.push(lookback);
									return null; // prevent fallthrough since this token is also a word boundary which would terminate the loop otherwise.
								}
							}
							else if (lookback.data === ")") { ++lookback_parenth_depth; }
						}

						//
						// Resume with if after "Set depths" since the depth incremental tokens still need to be parsed.
						//

						// Whitespace is allowed.
						if (lookback.is_whitespace === true) {
							lookback_requires_tokens.push(lookback);
						}

						// Inside curly depth but not inside parenth depth is not allowed.
						// Since direct curly not encapsulated by parentheses are not allowed inside the pre modifiers.
						// Otherwise it could catch the closing curly of the previous func definition and include every token till a requires token is reached.
						else if (lookback_curly_depth > 0 && lookback_parenth_depth === 0) {
							return false; // STOP ITERATION.
						}

						// Inside parenth or curly depth is allowed.
						else if (lookback_curly_depth !== 0 || lookback_parenth_depth !== 0) {
							lookback_requires_tokens.push(lookback);
						}

						// Inisde a template is allowed.
						else if (lookback.is_template === true) {
							lookback_requires_tokens.push(lookback);
						}

						// Check termination by the lookback is the "requires" keyword.
						else if (lookback.token === "keyword" && lookback.data === "requires") {
							ends_with_requires = true;
							modifier_tokens.push(lookback)
							on_lower_than_index = lookback.token; // set the on lower than index to this token's index for the parent iteration.
							return false;
						}

						// Operators are allowed.
						else if (lookback.token === "operator") {
							lookback_requires_tokens.push(lookback);	
						}

						// Stop termination by a word boundary that is not an operator or a single/double colon or closing template.
						else if (lookback.is_word_boundary === true && lookback.data !== ":" && lookback.data !== "::" && lookback.data !== ">") {
							return false; // STOP ITERATION.
						}

						// Still allowed.
						else {
							lookback_requires_tokens.push(lookback);
						}
					}
				});
				if (ends_with_requires) {
					requires_tokens = lookback_requires_tokens;
					return null;
				} else {
					return false; // STOP ITERATION.
				}
			}

			// Iterate the previous tokens reversed from the type def token.
			this.tokens.iterate_tokens_reversed(0, first_type_def_token.line + 1, (token) => {
				if (token.index < on_lower_than_index) {

					// First go back to the token before the type definition.
					// This means also skipping tokens with `is_template === true` and colon ":" tokens since these are allowed as part of the type.
					// Also the first keyword that appears when the func_type is undefined counts as a type.
					if (post_type === false) {

						// Inside a template.
						if (token.is_template === true) {
							type_tokens.push(token);
							return null; // prevent fallthrough to "Check modifiers".
						}

						// Whitespace.
						// Must be after "Inside a template" to allow whitespace in templates.
						else if (token.is_whitespace === true) {
							type_tokens.push(token);
							return null; // prevent fallthrough to "Check modifiers".	
						}

						// Is a type token.
						else if (token.token === "type") {
							type_tokens.push(token);
							return null; // prevent fallthrough to "Check modifiers".
						}

						// End of types by a keyword.
						// Must be after the inside template check, cause keywords are allowed inside templates.
						// @todo keywords are also allowed for require clauses.
						else if (first_type_keyword && token.token === "keyword" && this.pre_function_modifiers.includes(token.data) === false) {
							type_tokens.push(token);
							post_type = true;
							first_type_keyword = false;
							return null; // prevent fallthrough to "Check modifiers".
						}

						// Resume on colons keep in mind that they might be joined together instead of a single token with ":" as data.
						else if (token.token === undefined && token.data.indexOf(":") !== -1) {
							type_tokens.push(token);
							return null; // prevent fallthrough to "Check modifiers".
						}

						// Allowed operators.
						else if (token.token === "operator" && (token.data === "&" || token.data === "*")) {
							type_tokens.push(token);
							return null; // prevent fallthrough to "Check modifiers".
						}

						// Enable post_type flag.
						post_type = true;

						// fallthrough to "Check modifiers".
					}

					// Check modifiers.
					if (post_type === true) {

						// Set check reset requires flag.
						if (check_reset_requires_tokens === 1) {
							check_reset_requires_tokens = true;
						} else {
							check_reset_requires_tokens = false; // must reset to false since the "Reset the requires tokens..." is not always matched and otherwise the templates wont be parsed.
						}

						// Skip whitespace.
						// @edit white space should also be included in the pre modifiers for example for in vdocs.
						// if (token.is_whitespace === true) {
						// 	if (template_closed === false && is_template && parenth_depth === 0) {
						// 		templates_tokens.push(token);
						// 	}
						// 	return null;
						// }

						// Set parenth depth.
						// Do not set when inside templates since this would cause the templates not to be parsed.
						if (is_template === false) {
							if (token.token === undefined && token.data == "(") {
								if (parenth_depth === 0) {
									return false; // STOP ITERATION.
								}
								--parenth_depth;
								if (requires_closed === false && parenth_depth === 0) {
									requires_tokens.push(token);
									check_reset_requires_tokens = 1;
									return null;
								}
							} else if (token.token === undefined && token.data == ")") {
								++parenth_depth;
							}
						}

						//
						// Resume with if statements after the set parenth depth statement.
						//

						// Reset the templates when the token before the the opening template is not "template".
						// Also when the template is not reset there must be checked for a end of modifiers 1) since it was potentially part of a requires clause without parenth or it was the actual close.
						if (template_closed === false && is_template && parenth_depth === 0 && token.is_template !== true && token.is_whitespace !== true && (token.token !== "keyword" || token.data !== "template")) {
							lookback_requires_tokens = templates_tokens;
							templates_tokens = [];
							is_template = false;
							return check_end_of_modifiers(token);
						}

						// End of template.
						else if (template_closed === false && is_template && parenth_depth === 0 && token.is_template !== true && token.token === "keyword" && token.data === "template") {
							modifier_tokens.push(token);
							return check_end_of_modifiers(token);
						}

						// Rest the requires tokens when the token before the opening parenth is not "requires".
						else if (requires_closed === false && check_reset_requires_tokens === true && is_template === false && token.is_whitespace !== true && (token.token !== "keyword" || token.data !== "requires")) {
							lookback_requires_tokens = requires_tokens;
							requires_tokens = [];
							check_reset_requires_tokens = false;
							return check_end_of_modifiers(token);
						}

						// End of requires clause.
						else if (requires_closed === false && check_reset_requires_tokens === true && is_template === false && token.token === "keyword" && token.data === "requires") {
							modifier_tokens.push(token);
							requires_closed = true;
							return check_end_of_modifiers(token);
						}

						// Is inside a parenth.
						// Must be before the "Inside templates" templates.
						else if (requires_closed === false && is_template === false && parenth_depth !== 0) {
							requires_tokens.push(token);
						}

						// Inside templates.
						// But not inside a template since then it should be appended to the template tokens.
						else if (template_closed === false && parenth_depth === 0 && token.is_template === true) {
							templates_tokens.push(token);
							is_template = true;
						}

						// Is a modifier.
						else if ((token.token === undefined || token.token === "keyword") && this.pre_function_modifiers.includes(token.data)) {
							modifier_tokens.push(token);
						}

						// All capital token without an assigned token, assume it is a preprocessor variable.
						// Otherwise the pre modifiers would be terminated too soon when a user uses a preprocesor variable in the pre tokens.
						// And since there can not be a valid token without a ";" or another scope seperator this is probably safe.
						else if (token.is_whitespace !== true && token.is_line_break !== true && this.is_full_uppercase(token.data, ["_", "1", "2", "3", "4", "5", "6", "7", "8", "9"])) { 
							token.token = "type";
							modifier_tokens.push(token);
						}

						// Check the end of modiers.
						else if (token.is_whitespace !== true && token.is_line_break !== true){
							lookback_requires_tokens = [];
							return check_end_of_modifiers(token);
						}

					}
				}
			})

			// Unable to determine the type.
			// So just assume this is actually a function call instead of a type/function definition.
			// This can for example happen when a user highlights code that is actually within a function without passing the function headers in the code data.
			if (type_tokens.length === 0) {

				// Set to type.
				if (first_type_def_token.token === "type_def") {
					first_type_def_token.token = "type";
				}
				if (type_def_token.token === "type_def") {
					type_def_token.token = "type";
				}
				type_defs_from_colon.iterate((token) => {
					if (token.token === "type_def") {
						token.token = "type";
					}	
				})

				// Set inside func to make small correction but only when not already set otherwise it would overwrite the closing curly.
				if (this.inside_func !== true) {
					this.inside_func = true;
					this.inside_func_closing_curly = this.curly_depth;
				}

				// Stop.
				return null;

				// Deprecated: throw error.
				// throw Error(`Unable to determine the function type of function "${type_def_token.data}()" line ${type_def_token.line+1}.`);
			}

			// Assign the type, remove whitespace at the start and end and then concat the tokens to a type.
			else {
				type_def_token.type = this.trim_tokens(type_tokens, true);	
			}

			// Assign the template tokens.
			templates_tokens = this.trim_tokens(templates_tokens, true);
			if (templates_tokens.length > 0) {

				// Initialize a template object.
				const init_template = () => {
					template = {
						name: null, 	// the parameter name.
						index: null, 	// the parameter index.
						value: [], 		// the default value tokens.
						type: [], 		// the type tokens.
					};
				}

				// Append a template.
				const append_template = () => {
					if (template !== null) {
						template.type = this.trim_tokens(template.type);
						if (template.name != null) {
							template.name = template.name.trim();
						}
						template.value = this.trim_tokens(template.value);
						template.index = templates.length;
						templates.push(template);
						template = null;
					};
				}

				// Parse the templates into objects.
				// Create the array with parameters and assign the token_param to the tokens.
				let mode = 1; // 1 for type 2 for value.
				const templates = [];
				let template = null;
				let template_depth = 0, curly_depth = 0, parenth_depth = 0, bracket_depth = 0;
				let post_assignment = false;

				// Iterate the templates but skip the first < and last >.
				templates_tokens.iterate(1, templates_tokens.length - 1, (token) => {

					// Set depths.
					if ((token.token === undefined || token.token === "operator") && token.data.length === 1) {
						if (token.data === "<") { ++template_depth; }
						else if (token.data === ">") { --template_depth; }
						else if (token.data === "(") { ++parenth_depth; }
						else if (token.data === ")") { --parenth_depth; }
						else if (token.data === "[") { ++bracket_depth; }
						else if (token.data === "]") { --bracket_depth; }
						else if (token.data === "{") { ++curly_depth; }
						else if (token.data === "}") { --curly_depth; }
					}

					// Seperator.
					if (template_depth === 0 && parenth_depth === 0 && curly_depth === 0 && bracket_depth === 0 && token.data === ",") {
						append_template();
						mode = 1;
					}

					// Add to type / name.
					else if (mode === 1) {
						if (template === null) {
							init_template();
						}

						// Add to name.
						if (token.token !== "keyword" && token.is_whitespace !== true) {
							template.name = token.data;
							mode = 2;
							post_assignment = false;
						}

						// Add to type.
						else {
							template.type.push(token);
						}
					}

					// Add to value.
					else if (mode === 2) {
						if (post_assignment) {
							template.value.push(token);
						} else if (token.token === "operator" && token.data === "=") {
							post_assignment = true;
						}
					}
				})
				append_template();

				// Assign templates.
				type_def_token.templates = templates;
				type_def_token.template_tokens = templates_tokens;
			}

			// Assign the requires tokens.
			requires_tokens = this.trim_tokens(requires_tokens, true);
			if (requires_tokens.length > 0) {
				type_def_token.requires_tokens = requires_tokens;
			}

			// Assign modifier tokens.
			if (modifier_tokens.length > 0) {
				type_def_token.pre_modifiers = [];
				modifier_tokens.iterate_reversed((item) => {
					type_def_token.pre_modifiers.push(item);
				})
			}
		}

		// Set on parenth close callback.
		this.on_parenth_close = ({
			token_before_opening_parenth,
			after_parenth_index,
		}) => {
			
			// Get the closing parentheses.
			const closing = this.index;
			if (after_parenth_index != null) {

				// Get previous token.
				let prev = this.get_prev_token(token_before_opening_parenth.index, [" ", "\t", "\n"]); // "*", "&"
				if (prev == null) {
					return null;
				}

				// Check exceptions.
				// When the previous token is a ">", "*" or "&" then it can not be a function declaration.
				// It likely is a function call not catched inside a function because the user specified code that was inside a function without passing the function header.
				if (prev.data === ">" || prev.data === "*" || prev.data === "&" || prev.data === "&&") {
					if (prev.data === "*") {
						prev.token = "operator";
					} else if (prev.token !== undefined) {
						delete prev.token;
					}

					// Check if the prev token is a template closing.
					// Except when used on pointers with "->"
					let prev_prev = this.get_prev_token(prev.index - 1, [" ", "\t", "\n", "*", "&"]);
					if (prev.data === ">" && (prev_prev == null || prev_prev.data !== "-")) {
						const token = this.get_opening_template(prev.index);
						if (token != null) {
							prev = this.get_prev_token(token.index - 1, [" ", "\t", "\n"]);
						}
					}

					// Assign type.
					prev_prev = this.get_prev_token(prev.index - 1, [" ", "\t", "\n", "*", "&"]);
					if (prev_prev == null || prev_prev.token != "type") {
						prev.token = "type";
					}

					// Set inside func to make small correction but only when not already set otherwise it would overwrite the closing curly.
					if (this.inside_func !== true) {
						this.inside_func = true;
						this.inside_func_closing_curly = this.curly_depth;
					}

					// Stop.
					return null;
				}

				// Catch structurized initializations of attributes on constructors.
				// When the previous token is a ":" but not a "::" then it is not a function declaration but likely a constructor structurized initialization like `CLI() : m_attr(0) {}`
				// The ":" word boundaries are joined into "::" since it is not an operator.
				// These need to be catched separately since the attribute initialization can be followed by a "{".
				let prev_prev = this.get_prev_token(prev.index - 1, [" ", "\t", "\n"]); // "*", "&"
				if (prev_prev != null && prev_prev.data === ":") {
					prev.token = "type";

					// Set inside func to make small correction but only when not already set otherwise it would overwrite the closing curly.
					if (this.inside_func !== true) {
						this.inside_func = true;
						this.inside_func_closing_curly = this.curly_depth;
					}

					// Stop.
					return null;
				}

				// Set default type def token so it can be edited by "Catch operator function" and optional future others.
				let type_def_token = prev;

				// Catch operator overload function with operator names, for instance `operator =()`.
				// However the type cast operator funcs will not be catched by this, for instance `operator const Type*()` will not be catched.
				let is_operator_overload = false;
				let overloaded_operator_tokens = [];
				if (
					type_def_token.token === "operator" ||
					type_def_token.data === "[" || type_def_token.data === "]" || // subscript operator overload.
					type_def_token.data === "(" || type_def_token.data === ")" // function call operator.
				) {
					let operator_keyword = type_def_token;
					while (true) {
						if (operator_keyword.token === "keyword" && operator_keyword.data === "operator") {
							type_def_token = operator_keyword;
							type_def_token.overloaded_operators = [];
							overloaded_operator_tokens.iterate_reversed((token) => {
								type_def_token.overloaded_operators.push(token);
							});
							is_operator_overload = true;
							break;
						} else if (
							operator_keyword.is_whitespace !== true &&
							operator_keyword.token !== "operator" && 
							operator_keyword.data !== "[" && operator_keyword.data !== "]" && // subscript operator overload.
							operator_keyword.data !== "(" && operator_keyword.data !== ")" // function call operator.
						) {
							break;
						} else {
							overloaded_operator_tokens.push(operator_keyword);
						}
						operator_keyword = this.get_prev_token(operator_keyword.index - 1, ["\n"]); // must be as last so the first token will also be added to the `overloaded_operator_tokens`.
					}
				}

				// Edit the previous token when the token is not already assigned, for example skip the keywords in "if () {".
				// And skip lambda functions with a "]" before the "(".
				// @todo also need to catch functions like `operator const Type*(){}` and `auto& operator=(){}`.
				if (
					is_operator_overload ||
					(type_def_token.token === undefined && type_def_token.data !== "]") || // when no token is specified and exclude lambda funcs.
					(type_def_token.token === "type") // when the previous token is a type.
				) {

					// When the first character after the closing parentheses is a "{", the previous non word boundary token is a type def.
					// Unless the previous non word boundary token is a keyword such as "if () {".
					const lookup = this.code.charAt(after_parenth_index); 
					if (
						(this.allow_header_type_defs && lookup === ";" && !this.inside_func) || // from semicolon when not inside a function body.
						lookup === "{" || // from opening curly.
						lookup === ":" || // from a colon of structured initialization from constructors.
						first_char_matches_function_modifier(lookup) // from function modifier.
					) {
						type_def_token.token = "type_def";
						let token_for_parse_pre_type_def_modifiers = type_def_token;

						// When the token before the type def token a colon then also set the type_def token on the name tokens.
						// So the entire "mylib::mychapter::myfunc() {}" will be a token type def, not just "myfunc" but also "mylib" and "mychapter".
						const colon_token = this.get_prev_token(type_def_token.index - 1, []);
						const parents = [];
						if (colon_token.data === "::") { // lookup === "}" && 

							// Parse parents.
							let parent = colon_token;
							while (true) {
								parent = this.get_prev_token(parent.index - 1, []);
								if (parent == null) {
									break;
								}
								else if (parent.data === "::") {
									continue;
								}
								else if (this.str_includes_word_boundary(parent.data)) { // must be after dot check since dot is a word boundary ofc.
									break;
								}
								parent.token = "type_def";
								parent.is_duplicate = true; // indicate it is a duplicate, vdocs also depends on this.
								token_for_parse_pre_type_def_modifiers = parent; // since the `parse_pre_type_def_modifiers()` func needs the first type def token, so `mylib` in `mylib::mychapter::myfunc`.
								parents.push(parent);
							}
						}

						// Check before.
						// When the token before the type def token (or first token of column name tokens) is an operator such as "=" or a dot "." from something like "cli.myfunc();.
						// Then it is not a type definition but a function call in a scope where type defitions are also allowed.
						if (lookup === ";") {
							const check_before = this.get_prev_token(token_for_parse_pre_type_def_modifiers.index - 1, [" ", "\t", "\n"]);
							if (
								check_before != null && 
								(
									(check_before.token === undefined && check_before.data === ".") ||
									(check_before.token === "operator" && check_before.data !== "*" && check_before.data !== "&")
								)
							) {
								type_def_token.token = "type";
								parents.iterate_reversed((parent) => {
									parent.token = "type";
								})
								return null;
							}
						}

						// Add the parents to the tokenizer so that when the user does something like `vweb.utils.myclass = class myclass{}` the functions from the class will also have the parent.
						// But after the "check before" check.
						// Must check if new parents length is higher than 0 otherwise it overwrites the function's parents and the parents will be empty, instead of filled where it was filled.
						if (parents.length > 0) {
							type_def_token.parents = [];
							parents.iterate_reversed((parent) => {
								type_def_token.parents.push(parent);
								this.add_parent(parent);
							})
						}

						// Set the inside func flag.
						// It is being set a little too early but that doesnt matter since ...
						// Semicolons (for header func detection) should not be used in the context between here and the opening curly.
						// Unless the func is a header definition, but then the forward lookup loop stops.
						if (this.inside_func !== true) {
							let opening = null;
							for (let i = closing; i < this.code.length; i++) {
								const c = this.code.charAt(i);
								if (c == ";") {
									break;
								}
								else if (c == "{") {
									opening = i;
									break;
								}
							}
							if (opening != null) {
								this.inside_func = true;
								this.inside_func_closing_curly = this.curly_depth;
								// this.inside_func_closing_curly = this.get_closing_curly(opening);
							}
						}

						// Parse the type def pre modifiers.
						parse_pre_type_def_modifiers(token_for_parse_pre_type_def_modifiers, type_def_token, parents)

						// Return the set token.
						return type_def_token;
					}

					// When the first character after the closing parentheses is not a "{" then the previous token is a "type".
					// Unless the token before the previous token is already a type, such as "String x()".
					else {

						// Skip when the `allow_header_type_defs` flag is disabled and the lookup is `;` because then it should be a variable name of a constructor instead of a func call.
						// But still a check is required for the token before it, it must either be a ">", "*", "&" or a type otherwise the default function calls will also not be highlighted.
						if (this.allow_header_type_defs === false && lookup === ";") {
							let prev_prev = this.get_prev_token(type_def_token.index - 1, [" ", "\t", "\n"]);
							if (
								prev_prev !== null && 
								(
									prev_prev.token === "type" ||
									prev_prev.data === ">" ||
									prev_prev.data === "*" ||
									prev_prev.data === "&"
								)
							) {
								return null;
							}
						}

						// Check if the type_def_token token is a template closing.
						let prev_prev = this.get_prev_token(type_def_token.index - 1, [" ", "\t", "\n", "*", "&"]);
						if (type_def_token.data === ">" && (prev_prev == null || prev_prev.data !== "-")) {
							const token = this.get_opening_template(type_def_token.index);
							if (token != null) {
								type_def_token = this.get_prev_token(token.index - 1, [" ", "\t", "\n"]);
							}
						}

						// Small fix sometimes the ">" inside a `x->get();` does not get highlighted as an operator, use `prev_prev` because `type_def_token` is `get` in the example.
						else if (prev_prev != null && prev_prev.data === ">" && prev_prev.token !== "operator") {
							prev_prev.token = "operator"
						}

						// Assign type.
						prev_prev = this.get_prev_token(type_def_token.index - 1, [" ", "\t", "\n", "*", "&"]);
						if (prev_prev == null || (prev_prev.token != "type")) {
							type_def_token.token = "type";
						}

						// Set inside func to make small correction but only when not already set otherwise it would overwrite the closing curly.
						if (this.inside_func !== true) {
							this.inside_func = true;
							this.inside_func_closing_curly = this.curly_depth;
						}
					}
				}
			}
		}

		// The on post type def modifier callback.
		this.on_post_type_def_modifier_end = (type_def_token, last_token) => {

			// Vars.
			let parenth_depth = 0;			// the parenth depth.
			let closing_parenth_token;		// the token of the function's parameters closing parentheses.
			let templates_tokens = [];		// the templates clause tokens, even though it is not allowed still parse them.
			let requires_tokens = [];		// the requires clause tokens.
			let modifier_tokens = [];		// the modifier tokens.
			let is_requires = false; 		// tokens are inside a requires clause.
			let is_template = false; 		// tokens are inside a templates clause.

			// Iterate backwards to find the start token.
			this.tokens.iterate_tokens(type_def_token.line, null, (token) => {
				if (token.index === last_token.index) {
					if (token.token === undefined && token.data === ")") {
						--parenth_depth;
						if (parenth_depth === 0) {
							closing_parenth_token = token;
							return false;
						}
					}
					return false; // err.
				}

				// Set parenth depth and detect end.
				else if (token.index > type_def_token.index && token.token === undefined && token.data.length === 1) {
					if (token.data === "(") {
						++parenth_depth;
					} else if (token.data === ")") {
						--parenth_depth;
						if (parenth_depth === 0) {
							closing_parenth_token = token;
							return false;
						}
					}
				}
			})
			if (closing_parenth_token === undefined) {
				// return null;
				throw Error(`Unable to find the closing paremeter parentheses of function "${type_def_token.data}()" line ${type_def_token.line+1}.`);
			}

			// Iterate post modifier tokens forward.
			this.tokens.iterate_tokens(closing_parenth_token.line, last_token.line + 1, (token) => {
				if (token.index > closing_parenth_token.index && token.index <= last_token.index) {
					const is_keyword = token.token === "keyword";

					// Disable is template flag.
					// Skip whitespace since there may be whitespace between `template` and the first `<` where the `is_template` flag will be enabled.
					if (is_template && token.is_template !== true && token.is_whitespace !== true) {
						is_template = false;
					}

					// Resume with if statements after "Disable is template flag".
					
					// Is inside a template.
					if (is_template) {
						is_template = true;
						templates_tokens.push(token);
					}

					// Template modifier.
					else if (is_keyword && token.data === "template") {
						is_template = true;
						modifier_tokens.push(token);
					}

					// Requires modifier.
					else if (is_keyword && token.data === "requires") {
						is_requires = true;
						modifier_tokens.push(token);
					}

					// Is a modifier.
					// Also terminates the requires clause.
					else if (is_keyword && this.post_function_modifiers.includes(token.data)) {
						is_requires = false;
						modifier_tokens.push(token);
					}

					// Is inside a requires clause.
					// Must be after the "Is a modifier" statement.
					else if (is_requires) {
						requires_tokens.push(token);
					}
				}
			})
			
			// Assign the requires tokens.
			requires_tokens = this.trim_tokens(requires_tokens);
			if (requires_tokens.length > 0) {
				type_def_token.requires_tokens = requires_tokens
			}

			// Assign modifier tokens.
			if (modifier_tokens.length > 0) {
				type_def_token.post_modifiers = [];
				modifier_tokens.iterate((item) => {
					type_def_token.post_modifiers.push(item);
				})
			}
		}

		// Set the on type def keyword callback.
		// The parents always need to be set, but when a class is defined like "mylib.MyClass = class MyClass {}" the tokenizer will not add mylib as a parent.
		// Do not forget to set and update the parents since the tokenizer will not do this automatically when this callback is defined.
		this.on_type_def_keyword = (token) => {

			// Get the previous non whitespace token.
			const prev = this.get_prev_token(token.index - 1, [" ", "\t", "\n"]);

			// Set the is namespace flag for vdocs, vdocs depends on this behaviour.
			// Must be done before `add_parents()`.
			if (prev !== null && prev.token === "keyword" && prev.data === "namespace") {

				token.is_namespace = true;
			}

			// Assign parents.
			this.assign_parents(token);
			this.add_parent(token);

			// Parse the pre type def templates and requires.
			parse_pre_type_def_modifiers(token, token);

			// Set the start token to capture inherited classes when the previous token is either struct or class.
			if (prev !== null && (prev.data === "struct" || prev.data === "class")) {
				this.capture_inherit_start_token = token;
			}
		}
	}

	// Reset attributes that should be reset before each tokenize.
	derived_reset() {
		
		// The last line to detect types.
		this.last_line_type = null;

		// Whether the iteration is inside a function.
		// Used to distinct a function header definition from a constructor, so it wont work when ...
		// The user defines a function definition header inside a function but that is fine.
		this.inside_func = false;
		this.inside_func_closing_curly = null;

		// Used to detect type def inheritance.
		this.capture_inherit_start_token = undefined;
	}
}

// Initialize.
vhighlight.cpp = new vhighlight.CPP();// ---------------------------------------------------------
// CSS highlighter.

vhighlight.CSS = class CSS extends vhighlight.Tokenizer {
	constructor() {

		// Initialize the tokenizer .
		super({
			keywords: [
				// Transition Timing Functions
				'ease',
				'ease-in',
				'ease-out',
				'ease-in-out',
				'linear',
				'step-start',
				'step-end',

				// Animation Timing Functions
				'ease-in-quad',
				'ease-in-cubic',
				'ease-in-quart',
				'ease-in-quint',
				'ease-in-sine',
				'ease-in-expo',
				'ease-in-circ',
				'ease-in-back',
				'ease-out-quad',
				'ease-out-cubic',
				'ease-out-quart',
				'ease-out-quint',
				'ease-out-sine',
				'ease-out-expo',
				'ease-out-circ',
				'ease-out-back',
				'ease-in-out-quad',
				'ease-in-out-cubic',
				'ease-in-out-quart',
				'ease-in-out-quint',
				'ease-in-out-sine',
				'ease-in-out-expo',
				'ease-in-out-circ',
				'ease-in-out-back',

				// Animation Fill Modes
				'none',
				'forwards',
				'backwards',
				'both',

				// Animation Play State
				'paused',
				'running',

				// CSS Gradient Types
				'linear-gradient',
				'radial-gradient',
				'conic-gradient',

				// CSS Function Notations
				'rgb',
				'rgba',
				'hsl',
				'hsla',
				'url',

				// CSS Keyframe Properties
				'from',
				'to',

				// CSS Animations Properties
				'infinite',
				'alternate',
				'alternate-reverse',

				// Style keywords.
				// Not reliable, using manual implementation.
				// 'auto',
				// 'normal',
				// 'none',
				// 'hidden',
				// 'visible',
				// 'solid',
				// 'dotted',
				// 'dashed',
				// 'double',
				// 'groove',
				// 'ridge',
				// 'inset',
				// 'outset',
				// 'inherit',
				// 'initial',
				// 'unset',
				// 'center',
				// 'move',
				// 'pointer',
				// 'not-allowed',
				// 'crosshair',
				// 'grab',
				// 'grabbing',
				// 'zoom-in',
				// 'zoom-out',
				// 'text',
				// 'all-scroll',
				// 'col-resize',
				// 'row-resize',
				// 'n-resize',
				// 's-resize',
				// 'e-resize',
				// 'w-resize',
				// 'ne-resize',
				// 'nw-resize',
				// 'se-resize',
				// 'sw-resize',
				// 'ew-resize',
				// 'ns-resize',
				// 'nwse-resize',
				// 'nesw-resize',
				// 'start',
				// 'end',
				// 'italic',
				// 'bold',
				// 'underline',
				// 'overline',
				// 'line-through',
				// 'solid',
				// 'dotted',
				// 'dashed',
				// 'double',
				// 'groove',
				// 'ridge',
				// 'inset',
				// 'outset',
				// 'capitalize',
				// 'uppercase',
				// 'lowercase',
				// 'break-all',
				// 'break-word',
				// 'nowrap',
				// 'pre',
				// 'pre-line',
				// 'pre-wrap',
				// 'normal',
				// 'bold',
				// 'bolder',
				// 'lighter',
				// 'initial',
				// 'inherit',
				// 'unset',

				// Measurement keywords.
				// Not possible since the numerics are append to them so neither the numerics or the suffixes will match, so manual implementation is required.
				// 'px',
				// 'em',
				// 'rem',
				// 'ex',
				// 'ch',
				// 'vw',
				// 'vh',
				// 'vmin',
				// 'vmax',
				// '%',
				// 'in',
				// 'cm',
				// 'mm',
				// 'pt',
				// 'pc',
				// 'fr',
				// 'deg',
				// 'grad',
				// 'rad',
				// 'turn',
				// 'ms',
				// 's',
				// 'Hz',
				// 'kHz',
				// 'dpi',
				// 'dpcm',
				// 'dppx',
				// 'x',

				// Pseudo keywords.
				// Not usable because of the including word boundary ":".
				// '::after',
				// '::before',
				// '::first-letter',
				// '::first-line',
				// '::selection',
				// '::backdrop',
				// '::placeholder',
				// '::marker',
				// '::spelling-error',
				// '::grammar-error',
				// ':active',
				// ':checked',
				// ':default',
				// ':dir',
				// ':disabled',
				// ':empty',
				// ':enabled',
				// ':first',
				// ':first-child',
				// ':first-of-type',
				// ':focus',
				// ':focus-within',
				// ':fullscreen',
				// ':hover',
				// ':indeterminate',
				// ':in-range',
				// ':invalid',
				// ':last-child',
				// ':last-of-type',
				// ':left',
				// ':link',
				// ':not',
				// ':nth-child',
				// ':nth-last-child',
				// ':nth-last-of-type',
				// ':nth-of-type',
				// ':only-child',
				// ':only-of-type',
				// ':optional',
				// ':out-of-range',
				// ':read-only',
				// ':read-write',
				// ':required',
				// ':right',
				// ':root',
				// ':scope',
				// ':target',
				// ':valid',
				// ':visited',
			],
			multi_line_comment_start: "/*",
			multi_line_comment_end: "*/",

			// Attributes for partial tokenizing.
			scope_separators: [
				"{", 
				"}", 
			],

			// Language, must never be changed it is used by dependents, such as vdocs.
			language: "CSS",
		});

		// Numerics regex.
		const numeric_suffixes = [
			'px',
			'em',
			'rem',
			'ex',
			'ch',
			'vw',
			'vh',
			'vmin',
			'vmax',
			'%',
			'in',
			'cm',
			'mm',
			'pt',
			'pc',
			'fr',
			'deg',
			'grad',
			'rad',
			'turn',
			'ms',
			's',
			'Hz',
			'kHz',
			'dpi',
			'dpcm',
			'dppx',
			'x'
		].join("|");
		this.numeric_regex = new RegExp(`^-?\\d+(\\.\\d+)?(${numeric_suffixes})*$`);

		// Set callback.
		this.callback = (char, is_escaped) => {
			
			// At keywords such as "@keyframes".
			if (char == "@") {
				const end = this.get_first_word_boundary(this.index + 1);
				this.append_batch();
				this.append_forward_lookup_batch("keyword", this.code.substr(this.index, end - this.index));
				this.resume_on_index(end - 1);
				return true;
			}

			// Hex colors.
			if (this.batch == "" && char == "#") {
				const end = this.get_first_word_boundary(this.index + 1);
				this.append_batch();
				this.append_forward_lookup_batch("string", this.code.substr(this.index, end - this.index));
				this.resume_on_index(end - 1);
				return true;
			}

			// Css class definitions.
			else if (char == "{") {
				this.append_batch();
				let index = this.added_tokens - 1;
				while (true) {
					const prev = this.get_prev_token(index, [" ", ",", "\t", ":"]);
					if (prev == null || prev.data == "\n") {
						break;
					}
					else if (
						(prev.token == "string") || // for "#myid" which will otherwise be treated as hex strings.
						(prev.token == "keyword" && prev.data.charAt(0) != "@") ||
						(prev.token === undefined && 
							(
								prev.data == "#" || 
								prev.data == "." || 
								prev.data == "*" || 
								prev.data == "-" || 
								this.is_alphabetical(prev.data.charAt(0))
							)
						)
					) {
						const pprev = this.tokens[prev.index - 1];
						if (pprev != null && pprev.data == ":") {
							prev.token = "keyword";
							// pprev.token = "keyword";
							// const ppprev = this.tokens[pprev.index - 1];
							// if (ppprev != null && ppprev.data == ":") {
							// 	ppprev.token = "keyword";
							// }
						} else {
							prev.token = "type_def";
						}
					}
					index = prev.index - 1;
				}
			}

			// CSS style attribute, curly depth is higher then 1 with pattern "^\s*XXX:" or ";\s*XXX:".
			else if (this.curly_depth > 0 && char == ":") {
				this.append_batch();
				let index = this.added_tokens - 1;
				let edits = [];
				let finished = false;
				while (true) {
					const prev = this.get_prev_token(index, [" ", "\t"]);
					if (prev == null) {
						break;
					}
					else if (prev.data == "\n" || prev.data == ";") {
						finished = true;
						break;
					}
					else if (prev.token === undefined/* || prev.data == "-"*/) {
						edits.push(prev);
					}
					index = prev.index - 1;
					// console.log(edits);
				}
				if (finished) {
					for (let i = 0; i < edits.length; i++) {
						edits[i].token = "keyword";
					}
					
					// Set style start and end.
					this.style_start = this.index;
					for (let i = this.index + 1; i < this.code.length; i++) {
						const c = this.code.charAt(i);
						if (c == "\n") {
							this.style_start = null;
							break;
						} else if (c == ";") {
							this.style_end = i;
							break;
						}
					}
				}
			}

			// Numerics.
			else if (char == "%" && this.numeric_regex.test(this.batch + char)) {
				this.batch += char;
				this.append_batch("numeric");
				return true;
			}
			else if (this.word_boundaries.includes(char) && this.numeric_regex.test(this.batch)) {
				this.append_batch("numeric");
			}

			// Style attribute value keywords.
			// Basically every token that does not have an assigned token and does not contain a word boundary except for "-" between the style start and end.
			// Must be after numerics.
			else if (this.style_end != null && this.index >= this.style_end) {
				this.append_batch();
				let index = this.added_tokens - 1;
				let finished = false;
				const edits = [];
				while (true) {
					const prev = this.get_prev_token(index, [" ", "\t"]);
					if (prev == null || prev == "\n") {
						break;
					}
					else if (prev.data == ":") {
						finished = true;
						break;
					}
					else if (prev.token === undefined && !this.str_includes_word_boundary(prev.data)) {
						edits.push(prev);
					}
					index = prev.index - 1;
				}
				if (finished) {
					for (let i = 0; i < edits.length; i++) {
						edits[i].token = "keyword";
					}
				}
				this.style_end = null;
			}

			// Nothing done.
			return false;
		}

		// Set on parenth close.
		this.on_parenth_close = ({
			token_before_opening_parenth = token_before_opening_parenth,
			after_parenth_index = after_parenth_index,
		}) => {
			if (token_before_opening_parenth != null && token_before_opening_parenth.token === undefined) {
				token_before_opening_parenth.token = "type";
				return token_before_opening_parenth;
			}
		}
	}

	// Reset attributes that should be reset before each tokenize.
	derived_reset() {

		// Start and end of css style attribute index, start begins after the ":" and the end is at the ";".
		this.style_start = null;
		this.style_end = null;
	}
}

// Initialize.
vhighlight.css = new vhighlight.CSS();// ---------------------------------------------------------
// Python highlighter.

vhighlight.HTML = class HTML extends vhighlight.Tokenizer {

	// Static attributes.
	static language_tags = [
		"script",
		"style",
	];
	static verbatim_tags = [
		'textarea',
		'pre',
		'xmp',
		'plaintext',
		'listing',
	];

	// Constructor.
	constructor({
		allow_entities = true, // when allow_entities is true an entity like &gt; will not be converted to &amp;gt;
	} = {}) {

		// Initialize the tokenizer.
		super({
			multi_line_comment_start: "<!--",
			multi_line_comment_end: "-->",
			allow_parameters: false,

			// Attributes for partial tokenizing.
			// @todo does not work yet since < and > are different because of <> and the scope_seperators currently supports only a single char per item.
			scope_separators: [
				"<div>", "</div>",
				"<body>", "</body>",
				"<script>", "</script>",
				"<head>", "</head>",
			],

			// Language, must never be changed it is used by dependents, such as vdocs.
			language: "HTML",
		});

		// Params.
		this.allow_entities = allow_entities;

		// Set callback.
		this.callback = (char) => {

			// Highlight entities.
			if (char === "&") {

				// Append batch by word boundary.
				this.append_batch();

				// Do a forward lookup to check if the entity ends with a ';' without encountering a space or tab or newline.
				let batch;
				if (this.allow_entities) {
					batch = "&";
				} else {
					batch = "&amp;";
				}
				let success = false;
				let index = 0;
				for (index = this.index + 1; index < this.code.length; index++) {
					const c = this.code.charAt(index);
					batch += c;
					if (c === " " || c === "\t" || c === "\n") {
						break;
					} else if (c === ";") {
						batch = batch.substr(0, batch.length - 1) + "\;"
						success = true;
						break;
					}
				}

				// On success.
				if (success) {
					this.batch = batch;
					this.append_batch("keyword");
					this.resume_on_index(index);
					return true;
				}
			}

			// Tag opener / closer.
			else if (char === "<") {

				// Lookup result.
				const lookup_tokens = [];
				let resume_on_index = null;

				// Get tag indexes.
				let tag_name_start = this.get_first_non_whitespace(this.index + 1, true);
				if (tag_name_start === null) { return false; }
				const is_tag_closer = this.code.charAt(tag_name_start) === "/";
				const tag_end_index = this.lookup({query: ">", index: this.index});
				if (tag_end_index === null) { return false; }

				// Append < token.
				lookup_tokens.push(["operator", "<"]);

				// Append whitespace tokens.
				const whitespace = tag_name_start - (this.index + 1);
				if (whitespace > 0) {
					lookup_tokens.push([false, this.code.substr(this.index + 1, whitespace)]);
				}

				// Add / or ! tokens at the tag name start.
				let skip = ["/", "!"];
				while (skip.includes(this.code.charAt(tag_name_start))) {

					lookup_tokens.push(["operator", this.code.charAt(tag_name_start)]);
					
					// Get real start of tag name.
					const real_tag_name_start = this.get_first_non_whitespace(tag_name_start + 1, true);
					if (real_tag_name_start === null) { return false; }

					// Append whitespace tokens.
					const whitespace = real_tag_name_start - (tag_name_start + 1);
					if (whitespace > 0) {
						lookup_tokens.push([false, this.code.substr(tag_name_start + 1, whitespace)]);
					}

					// Update tag name start.
					tag_name_start = real_tag_name_start;
				}

				// Append the tag name as keyword.
				const tag_name_end = this.get_first_word_boundary(tag_name_start);
				if (tag_name_end === null) { return false; }
				const tag_name = this.code.substr(tag_name_start, tag_name_end - tag_name_start);
				lookup_tokens.push(["keyword", tag_name]);

				// Parse the attributes.
				const info = {index: null};
				let was_str = false, str_start = 0;
				let was_comment = false, comment_start = 0;
				let last_index = tag_end_index - 1;
				let is_attr_type = false, attr_type = null;
				const err = this.iterate_code(info, tag_name_end, tag_end_index, (char, is_str, _, is_comment) => {
					const is_last_index = info.index === last_index;

					// String end.
					if (was_str && (is_str === false || is_last_index)) {
						let end;
						if (last_index === info.index) { end = info.index + 1; }
						else { end = info.index; }
						const data = this.code.substr(str_start, end - str_start);
						lookup_tokens.push(["string", data]);
						if (is_attr_type) {
							if ((data.startsWith('"') && data.endsWith('"')) || (data.startsWith("'") && data.endsWith("'"))) {
								attr_type = data.slice(1, -1);
							} else {
								attr_type = data;
							}
						}
						was_str = false;
					}

					// Comment end.
					else if (was_comment && (is_comment === false || is_last_index)) {
						let end;
						if (last_index === info.index) { end = info.index + 1; }
						else { end = info.index; }
						lookup_tokens.push(["comment", this.code.substr(comment_start, end - comment_start)]);
						was_comment = false;
					}

					//
					// Resume with if after here.
					//

					// String start.
					if (was_str === false && is_str) {
						was_str = true;
						str_start = info.index;
					}

					// Inside string.
					else if (was_str) {}

					// Comment start.
					else if (was_comment === false && is_comment) {
						was_comment = true;
						comment_start = info.index;
					}

					// Inside comment.
					else if (was_comment) {}

					// Whitespace.
					else if (char === " " || char === "\t" || char === "\n") {
						lookup_tokens.push([null, char]);
					}

					// Assignment operator.
					else if (char === "=") {
						lookup_tokens.push(["operator", char]);
					}

					// Attribute keyword.
					else {
						const end = this.get_first_word_boundary(info.index);
						if (end === info.index) { // current char is word boundary, prevent infinite loop.
							lookup_tokens.push([null, char]);
							return null;
						}
						if (end > tag_end_index) { return true; }
						const data = this.code.substr(info.index, end - info.index);
						lookup_tokens.push(["keyword", data]);
						info.index = end - 1;
						is_attr_type = data === "type";
					}
				});
				if (err === true) {
					return false;
				}

				// Add the closing > token.
				lookup_tokens.push(["operator", ">"]);

				// Set default resume on index.
				resume_on_index = tag_end_index;

				// Append the lookup tokens.
				for (let i = 0; i < lookup_tokens.length; i++) {
					this.append_forward_lookup_batch(lookup_tokens[i][0], lookup_tokens[i][1]);
				}
				this.resume_on_index(resume_on_index);

				// Parse the entire tag till closing tag on certain tags.
				let verbatim_tag = false;
				if (
					is_tag_closer === false && 
					(
						(verbatim_tag = vhighlight.HTML.verbatim_tags.includes(tag_name)) === true || 
						vhighlight.HTML.language_tags.includes(tag_name)
					)
				) {

					// Vars.
					const content_start = tag_end_index + 1;

					// Find the closing tag.
					const info = {index: null};
					let close_tag_start_index = null, close_tag_end_index = null;
					let close_tag = `/${tag_name}>`;
					this.iterate_code(info, tag_end_index, null, (char, is_str, _, is_comment) => {
						if (is_str === false && is_comment === false && char === "<") {
							close_tag_start_index = info.index;
							let tag_i = 0;
							for (let i = info.index + 1; i < this.code.length; i++) {
								const c = this.code.charAt(i);
								if (c === " " || c === "\t" || c === "\n") {
									continue;
								} else if (c !== close_tag.charAt(tag_i)) {
									break;
								}
								++tag_i;
								if (tag_i >= close_tag.length) {
									close_tag_end_index = info.index;
									return false;
								}
							}
						}
					})

					// When the close tag is not found then skip everything afterwards.
					if (close_tag_end_index === null) {
						this.append_forward_lookup_batch(false, this.code.substr(content_start));
						this.resume_on_index(this.code.length);
					}


					// For certain tags the highlighting needs to be skipped until the tag closes.
					else if (verbatim_tag) {
						this.append_forward_lookup_batch(false, this.code.substr(content_start, close_tag_start_index - content_start));
						this.resume_on_index(close_tag_start_index - 1);
					}

					// Parse css.
					else if (tag_name === "style") {
						const tokens = vhighlight.css.tokenize({code: this.code.substr(content_start, close_tag_start_index - content_start), is_insert_tokens: true})
						this.concat_tokens(tokens);
						this.resume_on_index(close_tag_start_index - 1);
					}

					// Parse javascript.
					else if (tag_name === "script" && (attr_type == null || attr_type === "text/javascript" || attr_type === "application/javascript")) {
						const tokens = vhighlight.js.tokenize({code: this.code.substr(content_start, close_tag_start_index - content_start), is_insert_tokens: true})
						this.concat_tokens(tokens);
						this.resume_on_index(close_tag_start_index - 1);
					}

					// Uncaucht so add as plain text.
					else {
						this.append_forward_lookup_batch(false, this.code.substr(content_start, close_tag_start_index - content_start));
						this.resume_on_index(close_tag_start_index - 1);
					}
				
				}

				// Success.
				return true;

			}

			// Not appended.
			return false;
		}
	}
}

// Initialize.
vhighlight.html = new vhighlight.HTML();// ---------------------------------------------------------
// Javascript highlighter.

vhighlight.JS = class JS extends vhighlight.Tokenizer {
	constructor({
		keywords = [
			"break",
			"case",
			"catch",
			"class",
			"const",
			"continue",
			"debugger",
			"default",
			"delete",
			"do",
			"else",
			"export",
			"extends",
			"finally",
			"for",
			"function",
			"if",
			"import",
			"in",
			"instanceof",
			"let",
			"new",
			"of",
			"return",
			"super",
			"switch",
			"this",
			"throw",
			"try",
			"typeof",
			"var",
			"void",
			"while",
			"with",
			"yield",
			"prototype",
			"true",
			"false",
			"null",
			"static",
			"async",
			"await",
			"process",
			"module",
			"exports",
			"get",
			"set",
			"undefined",
			// "enum",
			// "implements",
			// "interface",
			// "package",
			// "private",
			// "protected",
			// "public",
		],
		type_def_keywords = [
			"class"
		], 
		type_keywords = [
			"extends",
		],
		operators = [
			"+", "-", "*", "/", "%", "**", "=", "+=", "-=", "*=", "/=", "%=", "**=",
			"==", "!=", "===", "!==", ">", "<", ">=", "<=", "&&", "||", "!", "&", "|",
			"^", "~", "<<", ">>", ">>>", "++", "--", "?",
		],
		single_line_comment_start = "//",
		multi_line_comment_start = "/*",
		multi_line_comment_end = "*/",
		allow_slash_regexes = true,
		allow_decorators = true,
		allow_preprocessors = false, // for the js compiler.
		allowed_keywords_before_type_defs = ["function", "async", "static", "get", "set", "*"], // also include function otherwise on_parent_close wont fire.
		excluded_word_boundary_joinings = [], // for js compiler.

		// Attributes for partial tokenizing.
		scope_separators = [
			"{", 
			"}", 
		],
	} = {}) {

		// Initialize the tokenizer.
		super({
			keywords: keywords,
			type_def_keywords: type_def_keywords, 
			type_keywords: type_keywords,
			operators: operators,
			single_line_comment_start: single_line_comment_start,
			multi_line_comment_start: multi_line_comment_start,
			multi_line_comment_end: multi_line_comment_end,
			allow_slash_regexes: allow_slash_regexes,
			allow_decorators: allow_decorators,
			allow_preprocessors: allow_preprocessors,
			allowed_keywords_before_type_defs: allowed_keywords_before_type_defs,
			excluded_word_boundary_joinings: excluded_word_boundary_joinings,
			scope_separators: scope_separators,

			// Language, must never be changed it is used by dependents, such as vdocs.
			language: "JS",
		});

		// Function modifiers.
		this.function_modifiers = ["async", "static", "get", "set", "*"];
	}

	// Reset attributes that should be reset before each tokenize.
	derived_reset() {

		// Used to detect type def inheritance.
		this.capture_inherit_start_token = undefined;
	}

	// Set the on type def keyword callback.
	// Do not forget to set and update the parents since the tokenizer will not do this automatically when this callback is defined.
	on_type_def_keyword(token) {

		// Parse the parents from assignment definition, so parse `vweb` and `utils` in `vweb.utils.myclass = class MyClass`.
		const assignment = this.get_prev_token(token.index - 1, [" ", "\t", "\n", "class"]);
		if (assignment != null && assignment.data === "=") {

			// Get the previous token before the assignment.
			// Also assign the token to a type def but indicate it is a duplicate type def of the original.
			const before_assignment = this.get_prev_token(assignment.index - 1, [" ", "\t", "\n"]);
			before_assignment.token = "type_def";
			before_assignment.is_duplicate = true; // indicate it is a duplicate, vdocs also depends on this.
			
			// Parse parents, exclude dots.
			let parents = [];
			let parent = before_assignment;
			while (true) {
				parent = this.get_prev_token(parent.index - 1, []);
				if (parent == null) {
					break;
				}
				else if (parent.data === ".") {
					continue;
				}
				else if (this.str_includes_word_boundary(parent.data)) { // must be after dot check since dot is a word boundary ofc.
					break;
				}
				parents.push(parent);
			}
			
			// Add the parents to the tokenizer so that when the user does something like `vweb.utils.myclass = class myclass{}` the functions from the class will also have the parent.
			token.parents = [];
			parents.iterate_reversed((parent) => {
				token.parents.push(parent);
				this.add_parent(parent);
			})

			// Add the current token also as a parent since it can have child functions.
			this.add_parent(token);
		}

		// Assign parents existing parents and add the current token as a parent.
		else {
			this.assign_parents(token);
			this.add_parent(token);
		}

		// Set the type array of the token, basically always "class" etc.
		token.type = [this.get_prev_token(token.index - 1, [" ", "\t", "\n"])];	

		// Set the start token to capture inherited classes.
		this.capture_inherit_start_token = token;
	}
	

	// Set on parenth close callback.
	on_parenth_close({
		token_before_opening_parenth,
		after_parenth_index,
	}) {

		// Get the function modifiers.
		let type_def_modifiers = [];
		let prev_modifier = this.get_prev_token(token_before_opening_parenth.index - 1, [" ", "\t", "\n"]);
		while (prev_modifier != null && (prev_modifier.token === "keyword" || (prev_modifier.token === "operator" && prev_modifier.data === "*"))) {
			if (this.function_modifiers.includes(prev_modifier.data)) {
				type_def_modifiers.push(prev_modifier);
			}
			prev_modifier = this.get_prev_token(prev_modifier.index - 1, [" ", "\t", "\n"]);
			if (prev_modifier == null) {
				break;
			}
		}

		// Check if the token is a keyword.
		let prev = token_before_opening_parenth;
		if (prev.token === "keyword") {
			if (prev.data !== "function" && this.function_modifiers.includes(prev.data) === false) {
				return null;
			}
		} else if (prev.token !== undefined && prev.token !== "operator") {
			return null;
		}

		// Check character after closing parentheses.
		if (after_parenth_index == null) {
			return null;
		}
		const after_parenth = this.code.charAt(after_parenth_index);

		// Check if the function is an anonymous function like `() => {};`
		const is_anonymous_func = after_parenth === "=" && this.code.charAt(after_parenth_index + 1) === ">";

		// Valid characters for a function declaration.
		// Either a "{" after the closing parentheses or a "=>" after the closing parentheses.
		if (after_parenth === "{" || is_anonymous_func) {

			// Get the previous token.
			let token = prev;
			token = this.get_prev_token(token.index, [" ", "\t", "\n", ":", "function", ...this.function_modifiers]);

			// When the token is assigned.
			let is_assignment_definition = false;
			if (token.data === "=") {
				token = this.get_prev_token(token.index - 1, [" ", "\t", "\n"]);				
				is_assignment_definition = true;
			}

			// Check token.
			if (token == null || this.str_includes_word_boundary(token.data)) {
				return null;
			}

			// Assign type def.
			token.token = "type_def";
			token.pre_modifiers = type_def_modifiers;

			// Parse the parents from assignment definition, so parse `vweb` and `utils` in `vweb.utils.func = () => {}`.
			if (is_assignment_definition) {

				// Parse parents, exclude dots.
				let parents = [];
				let parent = token;
				while (true) {
					parent = this.get_prev_token(parent.index - 1, []);
					if (parent == null) {
						break;
					}
					else if (parent.data === ".") {
						continue;
					}
					else if (this.str_includes_word_boundary(parent.data)) { // must be after dot check since dot is a word boundary ofc.
						break;
					}
					parents.push(parent);
				}
				
				// Add the parents to the tokenizer so that when the user does something like `vweb.utils.myclass = class myclass{}` the functions from the class will also have the parent.
				token.parents = [];
				parents.iterate_reversed((parent) => {
					token.parents.push(parent);
					this.add_parent(parent);
				})
			}

			// Return the token.
			return token;
		}

		// Otherwise it is a function call.
		else if (!this.str_includes_word_boundary(prev.data)) {
			prev.token = "type";
			return prev;
		}
	}

	// Set the default callback.
	callback(char) {

		// Set the inherited classes when the flag is enabled.
		if (char === "}" && this.capture_inherit_start_token !== undefined) {

			// Append current batch by word boundary separator.
			this.append_batch();

			// Vars.
			const start_token = this.capture_inherit_start_token;
			let success = false;
			let inherited_types = [];

			// Iterate backwards till the extends token is found, capture the types found in between.
			this.tokens.iterate_tokens_reversed((token) => {
				if (token.index <= start_token.index) {
					return false;
				}
				else if (token.token === "keyword" && token.data === "extends") {
					success = true;
					return false;
				}
				else if (token.token === "type") {
					inherited_types.push({
						type: "public",
						token: token,
					});
				}
			})

			// Assign the inherited types to the token.
			if (success && inherited_types.length > 0) {
				start_token.inherited = inherited_types;
			}

			// Reset the inherited class check flag.
			this.capture_inherit_start_token = undefined;
		}

		// Check word boundary and uppercase constants.
		// Must be last.
		else if (this.word_boundaries.includes(char)) {

			// Check uppercase constant.
			if (this.batch.length > 0 && char !== ":" && this.is_full_uppercase(this.batch)) {
				this.append_batch("type");
			}

			// Append word boundary.
			this.append_batch();
			this.batch += char;
			this.append_batch(null, {is_word_boundary: true}); // do not use "false" as parameter "token" since the word boundary may be an operator.
			return true;
		}
	}
}

// Initialize.
vhighlight.js = new vhighlight.JS();// ---------------------------------------------------------
// Json highlighter.

vhighlight.JSON = class JSON extends vhighlight.Tokenizer {
	constructor() {

		// Initialize the tokenizer.
		super({
			keywords: [
				"true",
				"false",
				"null",
			],
			single_line_comment_start: "//",
			multi_line_comment_start: "/*",
			multi_line_comment_end: "*/",

			// Attributes for partial tokenizing.
			scope_separators: [
				"{", 
				"}", 
				",",
			],

			// Language, must never be changed it is used by dependents, such as vdocs.
			language: "JSON",
		});
	}
}

// Initialize.
vhighlight.json = new vhighlight.JSON();// ---------------------------------------------------------
// Markdown highlighter.

vhighlight.Markdown = class Markdown extends vhighlight.Tokenizer {
	constructor({
		insert_codeblocks = true, // allow codeblocks to be parsed or put them into a single token.
	} = {}) {

		// Initialize the tokenizer.
		super({
			// multi_line_comment_start: "<!--",
			// multi_line_comment_end: "-->",
			allow_strings: false,
			allow_numerics: false,
			
			// Attributes for partial tokenizing.
			scope_separators: [],

			// Language, must never be changed it is used by dependents, such as vdocs.
			language: "Markdown",
		});

		// Set callback.
		this.callback = (char, a, b, c, d, is_escaped) => {
			
			// Start of line excluding whitespace.
			let start_of_line = false;
			if (this.current_line != this.line && !this.is_whitespace(char)) {
				start_of_line = true;
				this.current_line = this.line;
			}

			// Headings.
			if (start_of_line && char == "#") {

				// Append batch by word boundary.
				this.append_batch();

				// Do a forward lookup.
				const add = [];
				let last_index = null;
				let at_start = true;
				let word = "";
				for (let i = this.index; i < this.code.length; i++) {
					const c = this.code.charAt(i);

					// Stop at linebreak.
					if (c == "\n") {
						if (word.length > 0) {
							add.push(["bold", word]);
							word = "";
						}
						last_index = i - 1;
						break;
					}

					// Add whitespace seperately to not break "at_start".
					else if (c == " " || c == "\t") {
						if (word.length > 0) {
							add.push(["bold", word]);
							word = "";
						}
						add.push([false, c]);
					}

					// Add # as keyword.
					else if (at_start && c == "#") {
						add.push(["keyword", c]);
					}

					// Seperate words by a word boundary.
					else if (this.word_boundaries.includes(c)) {
						at_start = false;
						if (word.length > 0) {
							add.push(["bold", word]);
							word = "";
						}
						add.push([false, c]);
					}

					// Add everything else as bold.
					else {
						at_start = false;
						word += c;
					}

				}
				if (word.length > 0) {
					add.push(["bold", word]);
					word = "";
				}

				// Append.
				if (add.length > 0) {
					if (last_index == null) {
						last_index = this.code.length;
					}
					for (let i = 0; i < add.length; i++) {
						this.append_forward_lookup_batch(add[i][0], add[i][1]);
					}
					this.resume_on_index(last_index);
					return true;
				}
			}

			// Bold text.
			// It may not have whitespace after the "*" or "_" in order to seperate it from an unordered list.
			else if (
				(
					(char == "*" && this.next_char == "*") ||
					(char == "_" && this.next_char == "_")
				) &&
				!this.is_whitespace(this.code.charAt(this.index + 2))
			) {

				// Find closing char.
				let closing_index = null;
				for (let i = this.index + 2; i < this.code.length; i++) {
					const c = this.code.charAt(i);
					if (c == char && !this.is_escaped(i)) {
						closing_index = i;
						break;
					}
				}
				if (closing_index == null) { return false; }

				// Append batch by separator.
				this.append_batch();

				// Add tokens.
				this.append_forward_lookup_batch("keyword", char + char);
				this.append_forward_lookup_batch("bold", this.code.substr(this.index + 2, closing_index - (this.index + 2)));
				this.append_forward_lookup_batch("keyword", char + char);

				// Set resume index.
				this.resume_on_index(closing_index + 1);
				return true;
			}

			// Italic text.
			// It may not have whitespace after the "*" or "_" in order to seperate it from an unordered list.
			else if (
				(char == "*" || char == "_") &&
				!this.is_whitespace(this.next_char)
			) {

				// Find closing char.
				let closing_index = null;
				for (let i = this.index + 1; i < this.code.length; i++) {
					const c = this.code.charAt(i);
					if (c == char && !this.is_escaped(i)) {
						closing_index = i;
						break;
					}
				}
				if (closing_index == null) { return false; }

				// Append batch by separator.
				this.append_batch();

				// Add tokens.
				this.append_forward_lookup_batch("keyword", char);
				this.append_forward_lookup_batch("italic", this.code.substr(this.index + 1, closing_index - (this.index + 1)));
				this.append_forward_lookup_batch("keyword", char);

				// Set resume index.
				this.resume_on_index(closing_index);
				return true;
			}

			// Block quote.
			else if (start_of_line && char == ">") {
				this.append_batch();
				this.batch = char;
				this.append_batch("keyword");
				return true;
			}

			// Unordered list.
			// It must have whitespace after the "*" in order to seperate it from bold or italic text.
			else if (
				start_of_line && 
				(char == "-" || char == "*" || char == "+") && 
				this.is_whitespace(this.next_char)
			) {
				this.append_batch();
				this.batch = char;
				this.append_batch("keyword");
				return true;
			}

			// Ordered list.
			else if (start_of_line && this.is_numerical(char)) {

				// Do a forward lookup to check if there are only numerical chars and then a dot.
				let batch = char;
				let finished = false;
				let last_index = null;
				for (let i = this.index + 1; i < this.code.length; i++) {
					const c = this.code.charAt(i);
					if (c == "\n") {
						break;
					} else if (c == ".") {
						batch += c;
						finished = true;
						last_index = i;
						break;
					} else if (this.is_numerical(c)) {
						batch += c;
					} else {
						break;
					}
				}

				// Check if finished successfully.
				if (finished) {
					this.append_batch();
					this.append_forward_lookup_batch("keyword", batch);
					this.resume_on_index(last_index);
					return true;
				}
			}

			// Link or image.
			else if (char == "[" && !is_escaped) {

				// Append batch by word boundary.
				this.append_batch();

				// Get closing bracket.
				const opening_bracket = this.index;
				const closing_bracket = this.get_closing_bracket(opening_bracket);
				if (closing_bracket == null) { return false; }

				// Get opening and closing parentheses, but no chars except for whitespace may be between the closing barcket and opening parentheses.
				let opening_parentheses = null;
				for (let i = closing_bracket + 1; i < this.code.length; i++) {
					const c = this.code.charAt(i);
					if (c == " " || c == "\t") {
						continue;
					} else if (c == "(") {
						opening_parentheses = i;
						break;
					} else {
						break;
					}
				}
				if (opening_parentheses == null) { return false; }
				const closing_parentheses = this.get_closing_parentheses(opening_parentheses);
				if (closing_parentheses == null) { return false; }

				// Check if it is a link or an image by preceding "!".
				const prev = this.get_prev_token(this.added_tokens - 1, [" ", "\t"]);
				const is_image = prev != null && prev.data == "!";
				if (is_image) {
					prev.token = "keyword";
				}

				// Add text tokens.
				this.append_forward_lookup_batch("keyword", "[");
				this.append_forward_lookup_batch("string", this.code.substr(opening_bracket + 1, (closing_bracket - 1) - (opening_bracket + 1) + 1));
				this.append_forward_lookup_batch("keyword", "]");

				// Add url tokens.
				this.append_forward_lookup_batch("keyword", "(");
				this.append_forward_lookup_batch("string", this.code.substr(opening_parentheses + 1, (closing_parentheses - 1) - (opening_parentheses + 1) + 1));
				this.append_forward_lookup_batch("keyword", ")");

				// Set resume index.
				this.resume_on_index(closing_parentheses);
				return true;
			}

			// Single line code block.
			else if (char == "`" && this.next_char != "`" && this.prev_char != "`") {

				// Do a forward lookup till the next "`".
				let closing_index = null;
				for (let i = this.index + 1; i < this.code.length; i++) {
					const c = this.code.charAt(i);
					if (c == "`") {
						closing_index = i;
						break;
					}
				}
				if (closing_index == null) { return false; }

				// Add token.
				this.append_forward_lookup_batch("codeblock", this.code.substr(this.index, closing_index - this.index + 1));

				// Set resume index.
				this.resume_on_index(closing_index);
				return true;
			}

			// Multi line code block.
			else if (char == "`" && this.next_char == "`" && this.code.charAt(this.index + 2) == "`") {

				// Do a forward lookup till the next "`".
				let closing_index = null;
				let do_language = true;
				let language = "";
				for (let i = this.index + 3; i < this.code.length; i++) {
					const c = this.code.charAt(i);
					const is_whitespace = this.is_whitespace(c);
					if (c == "`" && this.code.charAt(i + 1) == '`' && this.code.charAt(i + 2) == "`") {
						closing_index = i + 2;
						break;
					} else if (do_language && (is_whitespace || c == "\n")) {
						do_language = false;
					} else if (do_language && language.length == 0 && !is_whitespace && !this.is_alphabetical(c)) {
						do_language = false;
					} else if (do_language && !is_whitespace && c != "\n") {
						language += c;
					}
				}
				if (closing_index == null) { return false; }

				// Slice the code.
				const start = this.index + 3 + language.length;
				const code = this.code.substr(start, (closing_index - 3) - start + 1);
				let tokenizer = language == "" ? null : vhighlight.init_tokenizer(language)

				// Insert codeblock tokens.
				if (insert_codeblocks) {

					// Highlight.
					let result = null;
					if (tokenizer != null) {
						tokenizer.code = code;
						result = tokenizer.tokenize({is_insert_tokens: true})
					}

					// Add tokens.
					this.append_forward_lookup_batch("keyword", "```");
					if (result == null) {
						this.append_forward_lookup_batch("codeblock", language + code);
					} else {
						this.append_forward_lookup_batch("keyword", language);
						this.concat_tokens(result);
					}
					this.append_forward_lookup_batch("keyword", "```");
				}

				// Put the codeblock into a single token.
				else {
					this.batch = code;
					this.append_batch("codeblock", {language: tokenizer == null ? null : tokenizer.language});
				}

				// Set resume index.
				this.resume_on_index(closing_index);
				return true;
				
			}


			// Not appended.
			return false;
		}
	}

	// Reset attributes that should be reset before each tokenize.
	derived_reset() {
		this.current_line = null; // curent line to detect start of the line.
	}
}

// Initialize.
vhighlight.md = new vhighlight.Markdown();// ---------------------------------------------------------
// Python highlighter.

vhighlight.Python = class Python extends vhighlight.Tokenizer {
	constructor() {

		// Initialize the tokenizer.
		super({
			keywords: [
				"and",
				"as",
				"assert",
				"break",
				"class",
				"continue",
				"def",
				"del",
				"elif",
				"else",
				"except",
				"finally",
				"for",
				"from",
				"global",
				"if",
				"import",
				"in",
				"is",
				"lambda",
				"not",
				"or",
				"pass",
				"raise",
				"return",
				"try",
				"while",
				"with",
				"yield",
				"self",
				"True",
				"False",
				"None",
				"async",
				"await",
			],
			type_def_keywords: [
				"def",
				"class",
			], 
			type_keywords: [],
			operators: [
				"==", "!=", "<", ">", "<=", ">=", "+", "-", "*", "/", "%", "**", "//", "=", "!", "?", "&", "|",
				"^", "~", "<<", ">>",
			],
			special_string_prefixes: [
				"f",
				"r",
				"u",
				"b",
			],
			single_line_comment_start: "#",
			is_indent_language: true,

			// Attributes for partial tokenizing.
			scope_separators: [
				":", 
			],

			// Language, must never be changed it is used by dependents, such as vdocs.
			language: "Python",
		});

		// Set callback.
		this.callback = (char) => {
			
			// Highlight function calls.
			if (char == "(") {

				// Append batch by word boundary.
				this.append_batch();

				// Do a forward lookup to parse the inherited classes when the `this.capture_inherit_start_token` flag is enanabled.
				// A forward lookup is requires since we can not catch the ")" parenth closed event since that is catched by tokenizer to parse the params.
				// And we also dont want to assign the on_parenth_close callback.
				if (this.capture_inherit_start_token !== undefined) {

					// Vars.
					const start_token = this.capture_inherit_start_token;
					let depth = 0; 						// parenth depth.
					let batch = "";						// the current batch.
					let lookup_tokens = [];				// the lookup token data `[type, token_data]`.
					let resume_on_index;				// resume on index of the closing parentheses, only assigned when the closing parenth is successfully found.

					// Append batch wrapper.
					const append_batch = (token = null) => {
						if (batch.length > 0) {
							if (token != null) {
								lookup_tokens.push([token, batch]);
							} else {
								lookup_tokens.push(["type", batch]);
							}
							batch = "";
						}
					}
					
					// Iterate forwards till the closing parentheses.
					for (let i = this.index; i < this.code.length; i++) {
						const c = this.code.charAt(i);

						// Depth increaser.
						if (c === "(") {
							append_batch();
							batch = c;
							append_batch(false);
							++depth;
						}

						// Depth increaser.
						else if (c === ")") {
							append_batch();
							batch = c;
							append_batch(false);
							--depth;
							if (depth === 0) {
								resume_on_index = i;
								break;
							}
						}

						// Allowed word boundaries.
						else if (c === "," || c === " " || c === "\t" || c === "\n") {
							append_batch();
							batch = c;
							append_batch(false);
						}

						// Non allowed word boundary.
						else if (c !== "." && c !== "_" && this.word_boundaries.includes(c)) {
							break;
						}

						// New batch and char is not alphabetical and not "_" so stop.
						else if (batch.length === 0 && c !== "_" && this.is_alphabetical(c) === false) {
							break;
						}

						// Append to batch.
						else {
							batch += c;
						}
					}

					// Reset capture inherit flag.
					this.capture_inherit_start_token = undefined;

					// Append the lookup tokens.
					// Check the appended tokens from `append_forward_lookup_batch()` and when any of them are type tokens then add them to the inherited types.
					// Since the inerhited array contains the actual tokens the building of the `inherited_types` array cant be done any earlier.
					if (resume_on_index !== undefined) {
						let inherited_types = [];
						for (let i = 0; i < lookup_tokens.length; i++) {
							const appended_tokens = this.append_forward_lookup_batch(lookup_tokens[i][0], lookup_tokens[i][1]);
							appended_tokens.iterate((token) => {
								if (token.token === "type") {
									inherited_types.push({
										type: "public",
										token: token,
									});
								}
							})
						}
						this.resume_on_index(resume_on_index - 1);
						if (inherited_types.length > 0) {
							start_token.inherited = inherited_types;
						}
						return true;
					}
				}

				// Resume as usual, check if it is a function call.
				else {

					// Get prev token.
					// Prev token must be null since "type_def" is already assigned.
					// And also skip tuples by checking if the prev contains a word boundary.
					const prev = this.get_prev_token(this.added_tokens - 1, [" ", "\t", "\n"]);
					if (prev != null && prev.token === undefined && !this.str_includes_word_boundary(prev.data)) {
						prev.token = "type";
					}
				}

			}

			// Not appended.
			return false;
		}

		// Function modifiers.
		this.function_modifiers = ["async"];

		// Set the on type def keyword callback.
		// Used to detect the "async" function modifier.
		// Do not forget to set and update the parents since the tokenizer will not do this automatically when this callback is defined.
		this.on_type_def_keyword = (token) => {

			// Get the assignment token.
			const async_token = this.get_prev_token(token.index - 1, [" ", "\t", "\n", "def"]);
			if (async_token != null && async_token.token === "keyword" && async_token.data === "async") {
				token.pre_modifiers = [async_token];
			}

			// Set the start token to capture inherited classes when the previous token is either struct or class.
			const prev = this.get_prev_token(token.index - 1, [" ", "\t", "\n"]);
			if (prev !== null && prev.data === "class") {
				this.capture_inherit_start_token = token;
				token.type = [prev];	
			}

			// Assign parents.
			this.assign_parents(token);
			this.add_parent(token);
		}
	}

	// Reset attributes that need to reset for each parse.
	derived_reset() {

		// Used to detect type def inheritance.
		this.capture_inherit_start_token = undefined;
	}
}

// Initialize.
vhighlight.python = new vhighlight.Python();// ---------------------------------------------------------
// Javascript parser when in node js.

if (typeof module !== "undefined" && typeof module.exports !== "undefined") {

	// Imports.
	const libfs = require("fs");

	// JS compiler class.
	vhighlight.JSCompiler = class JSCompiler {

		// Constructor.
		/*	@docs: {
			@title JSCompiler constructor.
			@description:
				Bundle or compile javascript files with additinonal syntax options.
				
				Code minimization:
					Minimize code by removing unnecessary characters.
				
				String concatenation:
					A sequence of the matching strings with nothing in between except whitespace (` `, `\t`, `\n`) will automatically be concatenated into one string.

				Numeric procentuals.
					Numerics followed by `%` will automatically be converted into a string.

				Decorators:
					Possible decorators are:
						- @constructor_wrapper(suffix = "Class"): Automatically creates a function wrapper for the class with the same name as the class minus the suffix. The suffix must be present at the end of the class name.
						- @vweb_register: Register the element as a custom HTML element. Requires the vweb client library to be included.

					One or multiple custom decorators can also be defined.
					However this requires the following rules.
					 	- The decorator function must return an anonymous function.
					 	- The decorator function must always contain the `callback` parameter, the callback function can never have any arguments.
					 	- The decorator function must always take assignment parameters `function my_decorator({my_arg = null, callback = () => {}}) {}`.
					 	- When calling the decorator function, any arguments must be passed in a python like keyword assignment way, e.g. `@my_decorator(my_arg = "Hello World!")`.
					 	- The decorator must always be followed by a function or class definition.

			@parameter: {
				@name: line_breaks
				@type: boolean
				@description: Allow single line breaks.
			}
			@parameter: {
				@name: double_line_breaks
				@type: boolean
				@description: Allow double line breaks.
			}
			@parameter: {
				@name: comments
				@type: boolean
				@description: Allow comments.
			}
			@parameter: {
				@name: white_space
				@type: boolean
				@description: Allow optional whitespace.
			}
		} */
		constructor({
			line_breaks = true,
			double_line_breaks = false,
			comments = false,
			white_space = false,
		} = {}) {

			// Parameters.
			this.line_breaks = line_breaks;
			this.double_line_breaks = double_line_breaks;
			this.comments = comments;
			this.white_space = white_space;

			// Attributes.
			this.str_chars = ["\"", "'", "`;"]
			this.tokenizer = new vhighlight.JS({
				allow_preprocessors: true,
				excluded_word_boundary_joinings: [" ", "\t"],
			});
		}
		
		// Bundle.
		/*	@docs: {
			@title Bundle.
			@description: Bundle and parse javascript files into a single file.
			@parameter:
				@name: export_path
				@type: string
				@description: The bundled export path.
			@parameter:
				@name: include
				@type: array[string]
				@description: The array with file paths, when a path is a directory the entire directory will be included.
			@parameter:
				@name: exclude
				@type: array[string]
				@description: The file paths that will be excluded.
			@parameter:
				@name: compile_min
				@type: boolean
				@description: Also compile path's that end with `min.js`.
			@parameter:
				@name: log
				@type: boolean
				@description: Log an exported to string.
		*/
		bundle({
			export_path = null,
			includes = [],
			excludes = [],
			compile_min = false,
			log = false,
		}) {

			// Reset preprocessor definitions.
			this.preprocessor_defs = {};
			this.serialized_preprocessor_defs = {};
			
			// Vars.
			let code = "";

			// Gather all paths.
			const paths = [];
			const include_path = (path) => {

				// Skip excluded.
				if (excludes.includes(path)) {
					return null;
				}

				// Check existance.
				if (!libfs.existsSync(path)) {
					throw Error(`Path "${path}" does not exist.`);
				}

				// When the path is a directory.
				if (libfs.statSync(path).isDirectory()) {
					const files = libfs.readdirSync(path);
					for (let i = 0; i < files.length; i++) {
						include_path(`${path}/${files[i]}`);
					}
				}

				// When the path is a file.
				else if (paths.includes(path) === false) {
					paths.push(path);
				}
			}
			for (let i = 0; i < includes.length; i++) {
				include_path(includes[i]);
			}

			// Compile all paths.
			// const now = Date.now();
			// const times = [];
			for (let i = 0; i < paths.length; i++) {
				const path = paths[i];
				if (compile_min === false && path.length > 7 && path.substr(path.length - 7) === ".min.js") {
					code += libfs.readFileSync(path);
				} else {
					// const l_now = Date.now();
					code += this.compile(path);
					// times.push([path, Date.now() - l_now]);
				}
			}
			// console.log(">>> Performance:", Date.now() - now + "ms.");
			// times.sort((a, b) => b[1] - a[1]);
			// for (let i = 0; i < Math.min(times.length, 10); i++) {
			// 	console.log(times[i][0] + ":", times[i][1] + "ms.")
			// }

			// Export.
			libfs.writeFileSync(export_path, code);

			// Log.
			if (log) {
				console.log(`Bundled into "${export_path}".`);
			}
		}

		// Compile a single file.
		compile(path) {
			return this.compile_code(libfs.readFileSync(path).toString(), path);
		}

		// Compile code data.
		compile_code(code_data, path = "<raw code data>") {

			// ---------------------------------------------------------
			// Tokenize.			

			// Parse tokens.
			this.tokenizer.code = code_data;
			this.tokens = this.tokenizer.tokenize()

			// ---------------------------------------------------------
			// Compile.		

			// Code insertions.
			// { after_token: <number> (insert after this token index), data: <string> (the data to insert) }
			this.code_insertions = [];

			// Other vars
			let code = "";
			let prev_token;						// the direct previous token.
			let prev_nw_token;					// the previous non whitespace token (also counting line breaks).
			let prev_is_whitespace = false;		// if the direct previous token is whitespace (also counting line breaks).
			let prev_is_operator = false;		// if the direct previous token is an operator (also counting line breaks).
			let prev_is_colon = false;			// if the direct previous token ends with a colon.
			let resume_on = 0;					// the token index on which to continue parsing when the token index is lower than resume on, it will be skipped.
			let line_index = -1;
			let token_index = -1;

			// ---------------------------------------------------------
			// Wrapper functions.

			// Get the next token, returns `null` when there is no next token.
			// const get_next_token = (lookup = 1, exclude = [], exclude_count = null) => {
			// 	return this.tokens.iterate_tokens(line_index, null, (token) => {
			// 		const excluded = (exclude_count === null || exclude_count > 0) || exclude.includes(token.data);
			// 		if (token.index >= token_index + lookup && !excluded) {
			// 			return token;
			// 		}
			// 		if (excluded && exclude_count !== null) {
			// 			--exclude_count;
			// 		}
			// 	})
			// }
			const get_next_token = (lookup = 1, exclude = []) => {
				return this.tokens.iterate_tokens(line_index, null, (token) => {
					if (token.index >= token_index + lookup && !exclude.includes(token.data)) {
						return token;
					}
				})
			}

			// Serialize a code variable value in string into a variable format.
			const serialize_str_variable = (value) => {

				// Serialize strings.
				if (
					(value.charAt(0) == "\"" && value.charAt(value.length - 1) == "\"") ||
					(value.charAt(0) == "'" && value.charAt(value.length - 1) == "'") ||
					(value.charAt(0) == "`" && value.charAt(value.length - 1) == "`")
				) {
					value = value.substr(1, value.length - 2);
				}

				// Serialize objects.
				else if (
					(value.charAt(0) == "[" && value.charAt(value.length - 1) == "]") ||
					(value.charAt(0) == "{" && value.charAt(value.length - 1) == "}")
				) {
					value = JSON.parse(value);
				}

				// Serialize boolean.
				else if (value === "true") {
					value = true;
				}
				else if (value === "false") {
					value = false;
				}

				// Serialize null.
				else if (value === "null") {
					value = null;
				}

				// Serialize undefined.
				else if (value === "undefined") {
					value = undefined;
				}
				
				// Serialize numbers.
				else if (/^-?\d+(\.\d+)?$/.test(value)) {
					value = parseFloat(value);
				}

				// Response.
				return value;
			}

			// ---------------------------------------------------------
			// Iterate tokens.

			// Mimize and format code.
			this.tokens.iterate((line_tokens) => {
				++line_index;

				// Iterate tokens.
				let added_tokens = 0;
				let at_line_start = true;
				line_tokens.iterate((token) => {

					// ---------------------------------------------------------
					// Vars.

					++token_index;
					let add_to_code = true;
					const is_whitespace = token.is_word_boundary === true && token.data.length === 1 && (token.data === " " || token.data === "\t");
					const is_operator = token.token === "operator";
					const next_nw_token = get_next_token(1, [" ", "\t", "\n"]);
					const next_token = get_next_token(1);
					const next_is_operator = next_token !== null && next_token.token == "operator";
					const next_is_whitespace = next_token !== null && next_token.is_word_boundary === true && next_token.data.length === 1 && (next_token.data === " " || next_token.data === "\t");
					if (at_line_start && is_whitespace === false) {
						at_line_start = false;
					}

					// ---------------------------------------------------------
					// Apply decorators.

					if (token.is_decorator === true) {

						// Apply.
						resume_on = this.apply_decorator(path, token);

						// Stop.
						return null;
					}

					// ---------------------------------------------------------
					// Skip.
					// But only after applying the decorators.

					if (token.index < resume_on) {
						return null;
					}

					// ---------------------------------------------------------
					// Skip single/double newlines.
					// But insert whitespace when the direct previous token was a keyword.

					if (
						token.is_line_break && 
						(token.is_comment !== true && token.is_str !== true && token.is_regex !== true && token.is_preprocessor !== true) && // always allow line breaks inside comments, strings, regex and preprocessors.
						(prev_token == null || (prev_token.is_comment !== true && prev_token.is_str !== true && prev_token.is_regex !== true && prev_token.is_preprocessor !== true)) && // always allow line breaks after comments, strings, regex and preprocessors.
						(
							this.line_breaks === false ||
							(this.double_line_breaks === false && added_tokens == 0)
						)
					) {
						if (prev_token !== undefined && prev_token.token === "keyword") {
							code += " ";
						}
						return null;
					}

					// ---------------------------------------------------------
					// Skip whitespace.
					// Except a single whitespace after and before keywords.
					if (
						this.white_space === false && 
						is_whitespace &&
						(
							at_line_start || 
							prev_is_operator ||
							prev_is_colon ||
							next_is_whitespace ||
							next_is_operator ||
							(
								(prev_nw_token == null || prev_nw_token.token !== "keyword") &&
								(next_token == null || next_token.token !== "keyword")
							)
						)
					) {
						return null;
					}

					// ---------------------------------------------------------
					// Skip comments.

					if (
						this.comments === false && 
						token.is_comment === true &&
						(token.is_line_break !== true || added_tokens === 0)
					) {
						return null;
					}

					// ---------------------------------------------------------
					// Concatenate strings in a sequence with only whitespace in between.

					if (
						prev_nw_token !== undefined &&
						prev_nw_token.token === "string" &&
						token.token === "string" &&
						this.str_chars.includes(prev_nw_token.data[prev_nw_token.data.length - 1]) &&
						this.str_chars.includes(token.data[0]) &&
						prev_nw_token.data[prev_nw_token.data.length - 1] === token.data[0]
					) {
						
						// Remove all previous chars till (including) the last string closer.
						const closer = prev_nw_token.data[prev_nw_token.data.length - 1];
						let success = false, close_index;
						for (close_index = code.length - 1; close_index >= 0; close_index--) {
							if (code.charAt(close_index) === closer) {
								success = true;
								break;
							}
						}
						if (success) {
							code = code.substr(0, close_index);
							token.data = token.data.substr(1);
						}
					}

					// ---------------------------------------------------------
					// Allow multi line ``` X ``` strings, where the indent of each line will be cleaned, therefore multi line strings can be defined at any indent level.
					// However, all backticks must be escaped inside this multi line backtick string.

					if (token.token === "string" && token.data.startsWith("```")) {

						// Find the indent of the defintion line.
						let remove_indent = "", indent = "";
						this.tokens.iterate_tokens_reversed(0, token.line + 1, (token) => {
							if (token.index <= token_index) {
								if (token.is_line_break) {
									remove_indent = indent;
									return true;
								} else if (token.is_whitespace) {
									indent += token.data;
								} else {
									indent = "";
								}
							}
						})

						// Iterate the tokens forwards to add the code and remove the correct amount of indentation.
						let prev = null;
						this.tokens.iterate_tokens(token.line, null, (token) => {
							if (token.index === token_index) {
								code += "`";
								code += token.data.substr(3);
							}
							else if (token.index >= token_index) {

								// Remove whitespace.
								if (remove_indent.length > 0 && prev.is_line_break === true && token.data.startsWith(remove_indent)) {
									token.data = token.data.substr(remove_indent.length);
								}

								// Check closing.
								if (
									token.token === "string" && token.data.eq_last("```")
								) {
									code += token.data.substr(0, token.data.length - 3);
									code += "`";
									resume_on = token.index + 1;
									return true; // do not add three ```, one has already been added.
								}

								// Add to code
								code += token.data;

							}
							prev = token;
						});
						add_to_code = false;
					}

					// ---------------------------------------------------------
					// Convert numeric tokens followed by a "%", "px", "em", "#" to a string.

					if (token.token === "numeric") {
						if (next_token != null) {
							if (
								next_token.data.length === 1 && 
								(
									next_token.data === "%" ||
									next_token.data === "#" ||
									next_token.data === "px" ||
									next_token.data === "em"
								)
							) {
								code += `"${token.data}${next_token.data}"`;
								resume_on = next_token.index + 1;
								add_to_code = false;
							}
							else if (
								next_token.data.length === 2 && 
								(
									next_token.data === "px" ||
									next_token.data === "em"
								)
							) {
								code += `"${token.data}${next_token.data.substr(0, 2)}"`;
								next_token.data = next_token.data.substr(2);
								add_to_code = false;
							}
							else if (
								next_token.data.length > 1 && 
								(
									next_token.data.charAt(0) === "%" ||
									next_token.data.charAt(0) === "#"
								)
							) {
								code += `"${token.data}${next_token.data.charAt(0)}"`;
								next_token.data = next_token.data.substr(1);
								add_to_code = false;
							}
						}
					}

					// ---------------------------------------------------------
					// Handle preprocessors.

					if (token.token === "preprocessor") {

						// Fetch the complete preprocessor statement, in case it is multi line.
						let preprocessor_data = token.data;
						let lookup = 1;
						while (true) {
							const next = get_next_token(lookup);
							if (next != null && (next.token === "preprocessor" || next.is_preprocessor === true)) {
								++lookup;
								if (token.is_line_break === true) {
									preprocessor_data += " ";
								} else {
									preprocessor_data += next.data;
								}
							} else {
								break;
							}
						}
						resume_on = token_index + lookup;
						preprocessor_data = preprocessor_data.trim();
						add_to_code = false;

						// Definition (#define).
						if (preprocessor_data.startsWith("#define")) {
							const splitted = preprocessor_data.split(" ");
							if (splitted.length >= 3) {

								// Add to raw preprocessor defs.
								let value = splitted.slice(2).join(" ");
								this.preprocessor_defs[splitted[1]] = value;

								// Add to serialized preprocessor defs.
								this.serialized_preprocessor_defs[splitted[1]] = serialize_str_variable(value);
							}
						}

						// If statements (#if, #elif #else #endif).
						else if (preprocessor_data.startsWith("#if")) {

							// Find all the "if" "elif" "else" statements.
							const statement_tokens = [[]];
							const statement_conditions = [preprocessor_data];
							const statement_conditions_tokens = [[]];
							let statement_lookup = lookup;
							let statement = null;
							let statement_index = 0;
							let end_token = null;
							let is_non_statement_preprocessor = false;
							while (true) {
								const next = get_next_token(statement_lookup);

								// New statement.
								if (next.token === "preprocessor" || next.is_preprocessor === true) {
									if (statement == null) {
										if (
											next.data.startsWith("#if") === false && 
											next.data.startsWith("#elif") === false && 
											next.data.startsWith("#else") === false && 
											next.data.startsWith("#endif") === false
										) {
											is_non_statement_preprocessor = true;
											statement_tokens[statement_index].push(next)
										}
									}
									if (is_non_statement_preprocessor !== true) {
										if (statement === null) {
											statement = "";
										}
										if (next.token === "line") {
											statement += " ";
										} else {
											statement += next.data;
										}
										statement_conditions_tokens.push(next);
										if (statement.startsWith("#endif")) {
											end_token = next.index;
											break;
										}
									}
								}

								// Inside statement.
								else {
									is_non_statement_preprocessor = false;

									// Add previous statement.
									if (statement !== null) {
										statement_conditions.push(statement);
										statement_tokens.push([])
										++statement_index;
										statement = null;
									}

									// Add token to statement.
									statement_tokens[statement_index].push(next)
								}
								++statement_lookup;
							}

							// Evaluate which statement is true.
							let evaluated_index = null;
							for (let i = 0; i < statement_conditions.length; i++) {
								let result;
								let statement = statement_conditions[i];

								// Remove the #elif etc text.
								const start = statement.indexOf(" ");
								if (start === -1) {
									result = statement === "#else";
								}
								statement = statement.substr(start + 1).trim()

								// Custom function "path_exists()"
								if (statement.startsWith("path_exists(")) {
									let path = statement.substr(12).trim();
									if (path.charAt(path.length - 1) === ")") {
										path = path.substr(0, path.length - 1);
									}
									path = serialize_str_variable(path);
									try {
										result = libfs.existsSync(path)
									} catch (error) {
										result = false;
									}
								}

								// Evaluate code.
								else if (result !== true) {
									const evaluate = new Function(...Object.keys(this.serialized_preprocessor_defs), `return ${statement};`);
									try {
										result = evaluate(...Object.values(this.serialized_preprocessor_defs));
									} catch (error) {
										throw Error(`Encountered an error while evaluating statement "${statement}": ${error}`);
									}
								}

								// Handle result.
								if (result) {
									evaluated_index = i;
									break;
								}
							}

							// Reset the token data of the non evaluated tokens.
							if (evaluated_index !== null) {
								for (let i = 0; i < statement_conditions.length; i++) {
									if (i !== evaluated_index) {
										statement_tokens[i].iterate((token) => {
											token.data = "";
											token.token = undefined;
										})
									}
								}
								statement_conditions_tokens.iterate((token) => {
									token.data = "";
									token.token = undefined;
								});
							}
						}

						// Not found, throw error.
						else {
							throw Error(`Unknown preprocessor statement "${token.data}"`)
						}
					}

					// Check if the token is a preprocessor definition.
					else if (this.preprocessor_defs !== undefined && this.preprocessor_defs[token.data] != null) {
						const value = this.preprocessor_defs[token.data];
						if (typeof value === "string") { // avoid default functions.
							code += value;
							add_to_code = false;
						}
					}


					// ---------------------------------------------------------
					// Add to code.

					// Append token.
					if (add_to_code) {
						code += token.data;
					}

					// ---------------------------------------------------------
					// Check code insertions.

					if (this.code_insertions.length > 0) {
						const new_code_insertions = [];
						this.code_insertions.iterate((item) => {
							if (item.after_token === token.index) {
								code += item.data;
							} else {
								new_code_insertions.push(item);
							}
						})
						this.code_insertions = new_code_insertions;
					}

					// ---------------------------------------------------------
					// Post edits.

					// Update iteration vars.
					++added_tokens;
					prev_token = token;
					prev_is_whitespace = is_whitespace;
					prev_is_operator = is_operator;
					prev_is_colon = token.token === undefined && token.data.length > 0 && token.data.charAt(token.data.length - 1) === ":";
					if (
						token.is_line_break !== true &&
						(token.data.length > 1 || (token.data != " " && token.data != "\t"))
					) {
						prev_nw_token = token;
					}
				})
			})
	
			// The code must end with a newline otherwise at least firefox may throw an error when the file ends with a }.
			if (code.charAt(code.length - 1) !== "\n") {
				code += "\n";
			}

			// Handler.
			return code;
		}

		// ---------------------------------------------------------
		// Utils.

		// Get the next `type_def` token from a start line and token index.
		// Returns `null` when no token is found.
		get_next_type_def(line, start_index) {
			return this.tokens.iterate_tokens(line, null, (token) => {
				if (token.index >= start_index && token.token === "type_def") {
					return token;
				}
			})
		}

		// Get closing depth token from a start token line and token index.
		// Can only be used for `()`, `[]` and `{}`.
		// The returned attributes will be null when the closing scope was not found.
		// Allow non whitespace only counts when the depth is 0.
		get_closing_token(line, start_index, opener = "(", closer = ")", allow_non_whitespace = true) {
			let depth = 0, open_token = null, close_token = null;
			const res = this.tokens.iterate_tokens(line, null, (token) => {
				if (token.index >= start_index) {
					if (token.token === undefined && token.data.length === 1 && token.data === opener) {
						if (depth === 0) {
							open_token = token;
						}
						++depth;
					} else if (token.token === undefined && token.data.length === 1 && token.data === closer) {
						--depth;
						if (depth === 0) {
							close_token = token;
							return true;
						}
					} else if (
						depth === 0 && 
						allow_non_whitespace === false && 
						(
							token.data.length > 1 ||
							(token.data != " " && token.data != "\t" && token.data != "\n")
						)
					) {
						return false;
					}
				}
			})
			return {close_token, open_token};
		}

		// @todo an async function that uses a decorator still does not work, need to check for async and if so then make the callback also async, not sure about await etc, perhaps do not await but throw error if the decorator is not async and the func is.
		/* 	Apply a decorator token.
		 * 	Returns the resume on token index.
		 * 	A code insertion object looks as follows:
		 * 	{
		 * 		after_token: <number>, // insert after this token index.	
		 * 		data: <string>, // the data to insert.
		 *	}
		 */
		apply_decorator(path, token) {

			// ---------------------------------------------------------
			// Preperation.

			// Vars
			const column = token.offset - this.tokens[token.line][0].offset;
			const decorator = token.data;
			let resume_on;
			const line_break = this.line_breaks ? "" : "\n";

			// Get a decorator parameter value by name (decorators must always use keyword assignment).
			const get_param_value = (name, def = null, unqoute = false) => {
				let value = def;
				token.parameters.iterate((param) => {
					if (param.name === name) {
						if (param.value !== null && param.value.length > 0) {
							value = "";
							param.value.iterate((item) => {
								value += item.data;
							})
						}
						return true;
					}
				})
				if (value === undefined) { value = def; }
				while (value.length >= 2 && this.str_chars.includes(value.charAt(0)) && this.str_chars.includes(value.charAt(value.length - 1))) {
					value = value.substr(1, value.length - 2);
				}
				const str_chars = ["'", '"', "`"];
				if (unqoute && str_chars.includes(value.charAt(0)) && str_chars.includes(value.charAt(value.length - 1))) {
					value = value.substr(1, value.length - 2);
				}
				return value;
			}

			// Check if the previous token is keyword class.
			const check_prev_is_keyword_class = (type_def_token) => {
				const class_keyword = this.tokenizer.get_prev_token(type_def_token.index - 1, [" ", "\t", "\n"]);
				if (class_keyword == null || class_keyword.data !== "class") {
					throw Error(`${path}:${token.line}:${column}: The target type definition "${type_def_token.data}" is not a class (${decorator}).`);
				}
				return class_keyword;
			}

			// Build params as a js string.
			const build_params = (params) => {
				let data = "(";
				let i = 0, last_i = params.lenth - 1;
				params.iterate((param) => {
					if (param.name != null) {
						data += `${param.name}=`;
					}
					data += param.value;
					if (i != last_i) {
						data += ",";
					}
					++i;
				})
				data += ")";
				return data;
			}

			// Get the value to which a type def was assigned to eg "mylib.myfunc = ..." to retrieve "mylib.myfunc".
			// When there was no assignment used then `null` is returned.
			const get_assignment_name = (from_token_index) => {
				const assignment = this.tokenizer.get_prev_token(from_token_index, [" ", "\t", "\n"]);
				let assignment_name = null;
				if (assignment != null && assignment.data === "=") {
					assignment_name = "";
					this.tokens.iterate_tokens_reversed(assignment.line, assignment.line + 1, (token) => {
						if (token.index < assignment.index) {
							if (assignment_name.length === 0 && token.is_word_boundary !== true) {
								assignment_name += token.data;
							} else if (assignment_name.length !== 0) {
								if (token.is_word_boundary && token.data !== ".") {
									return false;
								} else {
									assignment_name = token.data + assignment_name;
								}
							}
						}
					})
					if (assignment_name.length === 0) {
						assignment_name = null;
					}
				}
				return assignment_name;
			}

			// Find the resume token.
			let resume = this.get_closing_token(token.line, token.index + 1, "(", ")", false);
			if (resume.close_token == null) {
				resume_on = token.index + 1;
			} else {
				resume_on = resume.close_token.index + 1;
			}

			// Find the closing "}" token.
			let {open_token, close_token} = this.get_closing_token(token.line, resume_on - 1, "{", "}");
			if (open_token === null || close_token === null) {
				throw Error(`${path}:${token.line}:${column}: Unable to find the scope's open and close tokens (${decorator}).`);
			} else {
				let prev = this.tokenizer.get_prev_token(open_token.index - 1, [" ", "\t", "\n"]);
				if (prev != null && prev.data === "(") {  // when a function call using assignment operators is used to return a derived class.
					const res = this.get_closing_token(token.line, close_token.index + 1, "{", "}");
					open_token = res.open_token;
					close_token = res.close_token;
					if (open_token === null || close_token === null) {
						throw Error(`${path}:${token.line}:${column}: Unable to find the scope's open and close tokens (${decorator}).`);
					}
				}
			}

			// Find the next type def token.
			const type_def_token = this.get_next_type_def(token.line, resume_on - 1);
			if (type_def_token === null || type_def_token.index >= open_token.index) {
				throw Error(`${path}:${token.line}:${column}: There is no type definition before the scope opening (${decorator}).`);
			}

			// ---------------------------------------------------------
			// Constructor wrapper.

			if (decorator === "@constructor_wrapper") {

				// Check if the previous token is "class".
				const class_keyword = check_prev_is_keyword_class(type_def_token);
				
				// Check if the class was assigned to a module with like "mylib.myclass = class MyClass {}".
				const assignment_name = get_assignment_name(class_keyword.index - 1);
				
				// Args.
				let suffix = get_param_value("suffix", "Class", true);

				// Check if the suffix matches the end of the target type.
				if (
					type_def_token.data.length < suffix.length || 
					type_def_token.data.substr(type_def_token.data.length - suffix.length) != suffix
				) {

					// When the suffix is the default "Class" then also check for "Element".
					const old_suffix = suffix;
					suffix = "Element";
					if (
						type_def_token.data.length < suffix.length || 
						type_def_token.data.substr(type_def_token.data.length - suffix.length) != suffix
					) {
						throw Error(`${path}:${token.line}:${column}: The target type definition "${type_def_token.data}" does not contain suffix "${old_suffix}" (${decorator}).`);
					}
				}

				// Create data.
				let data = ";";
				if (assignment_name !== null) {
					data += `${assignment_name}=`;
				}
				data += `${line_break}function ${type_def_token.data.substr(0, type_def_token.data.length - suffix.length)}(...args){return new ${type_def_token.data}(...args)};`;
				
				// Return code insertion.
				this.code_insertions.push({
					after_token: close_token.index,
					data: data,
				});
			}

			// ---------------------------------------------------------
			// Register the elemtent as a custom html element.

			else if (decorator === "@register_element") {

				// Check if the previous token is "class".
				const class_keyword = check_prev_is_keyword_class(type_def_token);

				// Create data.
				const data = `;${line_break}vweb.elements.register(${type_def_token.data});`;
				
				// Return code insertion.
				this.code_insertions.push({
					after_token: close_token.index,
					data: data,
				});
			}

			// ---------------------------------------------------------
			// Custom decorators.

			else {

				// Put the entire function call inside a sub function named callback.
				if (type_def_token.custom_decorators === undefined) {
					this.code_insertions.push({
						after_token: open_token.index,
						data: `${line_break}let callback=()=>{`,
					})
					this.code_insertions.push({
						after_token: close_token.index - 1,
						data: `};${line_break}`,
					})
				}

				// When there are multiple custom decoratos then the decorators that were declared first should be called as last in order to keep the execute order right.
				// So remove this functions custom decorators from the code insertions and then add them in the correct order.
				let old_decorators = [];
				if (type_def_token.custom_decorators !== undefined) {
					const new_insertions = [];
					this.code_insertions.iterate((item) => {
						if (item.decorator !== type_def_token.offset) {
							new_insertions.push(item);
						}
						else if (item.end_decorator !== true) {
							old_decorators.push(item);
						}
					})
					this.code_insertions = new_insertions;
				}

				// Add the decorator.
				let data = `callback=${decorator.substr(1)}({callback:callback`;
				token.parameters.iterate((param) => {
					if (param.name == null) {
						throw Error(`${path}:${token.line}:${column}: Decorator parameters must always use keyword assignment "@decorator(my_param = 0)" (${decorator}).`);
					}
					data += `,${param.name}:${param.value}`
				})
				data += `});${line_break}`
				this.code_insertions.push({
					after_token: close_token.index - 1,
					data: data,
					decorator: type_def_token.offset, // use as id.
				})

				// Add the old decorators.
				old_decorators.iterate((item) => {
					this.code_insertions.push(item);
				})

				// Return the callback.
				this.code_insertions.push({
					after_token: close_token.index - 1,
					data: `return callback();${line_break}`,
					decorator: type_def_token.offset, // use as id.
					end_decorator: true,
				})

				// Assign token's custom decorators.
				if (type_def_token.custom_decorators === undefined) {
					type_def_token.custom_decorators = [decorator];
				} else {
					type_def_token.custom_decorators.push(decorator);
				}

			}

			// ---------------------------------------------------------
			// Finish.

			// Unknown decorator.
			// else {
			// 	throw Error(`${path}:${token.line}: Unknown decorator "${decorator}".`);
			// }

			// Handler.
			return resume_on;

		}
	}
}// Export vhighlight.
if (typeof module !== "undefined" && typeof module.exports !== "undefined") {

    // Set export file paths for web inclusions.
    // Remember this is bundled into vhighlight/vhighlight.js
    vhighlight.web_exports = {
        "css": `${__dirname}/css/vhighlight.css`,
        "js": `${__dirname}/vhighlight.js`,
    }

    // Set version.
    vhighlight.version = require("./.version.js");

    // Export the library.
	module.exports = vhighlight;
}